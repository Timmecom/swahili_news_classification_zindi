{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ab57b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from fastbook import *\n",
    "from fastai.text.all import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d90cb5b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>content</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SW0</td>\n",
       "      <td>SERIKALI imesema haitakuwa tayari kuona amani na utulivu wa nchi inachezewa huku ikisisitiza uwepo wa umoja kati ya wananchi bila kujali tofauti ya imani, kabila au itikadi yoyote.Hayo yalisemwa na Naibu Waziri wa Mambo ya Ndani ya Nchi, Hamad Yussuf Masauni wakati akifungua semina ya siku mbili iliyofanyika jijini Dar es Salaam ikiwahusisha viongozi wa taasisi za Kiislamu, lengo ikiwa ni kuwakumbusha kuhubiri amani katika sehemu zao.Naibu Waziri amesema mwelekeo na malengo ya Serikali ya Awamu ya Tano ni kukuza maendeleo katika sehemu mbalimbali nchini lengo ikiwa kuinua maisha ya wananc...</td>\n",
       "      <td>Kitaifa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id  \\\n",
       "0  SW0   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   content  \\\n",
       "0   SERIKALI imesema haitakuwa tayari kuona amani na utulivu wa nchi inachezewa huku ikisisitiza uwepo wa umoja kati ya wananchi bila kujali tofauti ya imani, kabila au itikadi yoyote.Hayo yalisemwa na Naibu Waziri wa Mambo ya Ndani ya Nchi, Hamad Yussuf Masauni wakati akifungua semina ya siku mbili iliyofanyika jijini Dar es Salaam ikiwahusisha viongozi wa taasisi za Kiislamu, lengo ikiwa ni kuwakumbusha kuhubiri amani katika sehemu zao.Naibu Waziri amesema mwelekeo na malengo ya Serikali ya Awamu ya Tano ni kukuza maendeleo katika sehemu mbalimbali nchini lengo ikiwa kuinua maisha ya wananc...   \n",
       "\n",
       "  category  \n",
       "0  Kitaifa  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('datasets/Train.csv')\n",
    "test = pd.read_csv('datasets/Test.csv')\n",
    "train.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d1b9ea3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Index(['id', 'content', 'category'], dtype='object'),\n",
       " Index(['swahili_id', 'content'], dtype='object'))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns,test.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a84a510",
   "metadata": {},
   "source": [
    "### Read the entire texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bde8fead",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6439"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clean_row(x):\n",
    "    x = ''.join(x.split('\\'')).strip('[]')\n",
    "    return re.sub(r\"[^\\x00-\\x7F]\", ' ', x)\n",
    "    \n",
    "txts = L(\n",
    "    list(train['content'].apply(clean_row).values) + \n",
    "#     list(train.loc[:,'content'].values) + \n",
    "#     list(test.loc[:,'content'].values) \n",
    "    list(test['content'].apply(clean_row).values)\n",
    ")\n",
    "len(txts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d66aa16",
   "metadata": {},
   "source": [
    "### Concatenate into one big stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff10b8f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SERIKALI imesema haitakuwa tayari kuona amani na utulivu wa nchi inachezewa huku ikisisitiza uwepo w'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = ' xbos '.join([l.strip() for l in txts[:200]])\n",
    "text[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a75d38f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['My', 'name', 'is', 'Emma', '.', 'I', 'love', 'coding', '!', 'I', 'have', 'smth', 'to', 'say', ',', 'I', 'will', 'not', 'say', '.', 'Visit', 'my', 'page', '@', 'www', '.', 'emmasc', '.', 'com', '.', 'W', '.', 'H', '.', 'O', '.', ',']\n"
     ]
    }
   ],
   "source": [
    "text2 = 'My name is Emma. I love coding! I have smth to say, I will not say. Visit my page @ www.emmasc.com. W.H.O.,'\n",
    "\n",
    "\n",
    "def text_split(text2):\n",
    "    toks = []\n",
    "    l,r = 0,0\n",
    "\n",
    "    text2 += ' '\n",
    "    while r < len(text2):\n",
    "        L,R = text2[l], text2[r]\n",
    "        if not R.isalnum():\n",
    "            L_R = text2[l:r]\n",
    "            if L == R:\n",
    "                if L.strip():\n",
    "                    toks.append(R)\n",
    "            elif L.strip() and R.strip():\n",
    "                toks.extend([L_R,R])\n",
    "            else:\n",
    "                toks.append(L_R)\n",
    "            l = r + 1\n",
    "    #     print(toks)\n",
    "        r += 1\n",
    "    return toks\n",
    "print(text_split(text2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d312f3aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82737 10340\n",
      "\n",
      "['xbos', 'xupp', 'serikali', 'imesema', 'haitakuwa', 'tayari', 'kuona', 'amani', 'na', 'utulivu', 'wa', 'nchi', 'inachezewa', 'huku', 'ikisisitiza', 'uwepo', 'wa', 'umoja', 'kati', 'ya', 'wananchi', 'bila', 'kujali', 'tofauti', 'ya', 'imani', ',', 'kabila', 'au', 'itikadi', 'yoyote', '.', 'xtit', 'hayo', 'yalisemwa', 'na', 'xtit', 'naibu', 'xtit', 'waziri']\n"
     ]
    }
   ],
   "source": [
    "## Tokenize\n",
    "def get_tokens(text):\n",
    "    toks = text_split(text)\n",
    "    \n",
    "    tokens = ['xbos']\n",
    "    for tok in toks:\n",
    "        if tok.istitle(): tokens.extend(['xtit',tok.lower()])\n",
    "        elif tok.isupper(): tokens.extend(['xupp',tok.lower()])\n",
    "        else: tokens.append(tok)\n",
    "    return tokens\n",
    "\n",
    "tokens = get_tokens(text)\n",
    "\n",
    "print(len(tokens),len(set(tokens)))\n",
    "print()\n",
    "print(tokens[:40])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f1cee3c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#82737) [0,1,2,3,4,5,6,7,8,9...]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## To Numericalize\n",
    "\n",
    "# Generate the vocab with unique tokens\n",
    "vocab = L(*tokens).unique()\n",
    "\n",
    "word2idx = {w:i for i, w in enumerate(vocab)}\n",
    "nums = L(word2idx[w] for w in tokens)\n",
    "nums"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3dcdeff",
   "metadata": {},
   "source": [
    "## Build a language model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc49691c",
   "metadata": {},
   "source": [
    "### Predict each word based on the previous 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e896424e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#27578) [(['xbos', 'xupp', 'serikali'], 'imesema'),(['imesema', 'haitakuwa', 'tayari'], 'kuona'),(['kuona', 'amani', 'na'], 'utulivu'),(['utulivu', 'wa', 'nchi'], 'inachezewa'),(['inachezewa', 'huku', 'ikisisitiza'], 'uwepo'),(['uwepo', 'wa', 'umoja'], 'kati'),(['kati', 'ya', 'wananchi'], 'bila'),(['bila', 'kujali', 'tofauti'], 'ya'),(['ya', 'imani', ','], 'kabila'),(['kabila', 'au', 'itikadi'], 'yoyote')...]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L((tokens[i:i+3],tokens[i+3]) for i in range(0,len(tokens)-4,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca346975",
   "metadata": {},
   "source": [
    "The model can't use the above but the numericalized version of the above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "745c1e8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#27578) [(tensor([0, 1, 2]), 3),(tensor([3, 4, 5]), 6),(tensor([6, 7, 8]), 9),(tensor([ 9, 10, 11]), 12),(tensor([12, 13, 14]), 15),(tensor([15, 10, 16]), 17),(tensor([17, 18, 19]), 20),(tensor([20, 21, 22]), 18),(tensor([18, 23, 24]), 25),(tensor([25, 26, 27]), 28)...]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seqs = L((tensor(nums[i:i+3]),nums[i+3]) for i in range(0,len(nums)-4,3))\n",
    "seqs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91e9604c",
   "metadata": {},
   "source": [
    "### Creating the DataLoader with a `batch_size` of 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e80ddd5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 64\n",
    "cut = int(len(seqs) * 0.8)\n",
    "dls = DataLoaders.from_dsets(seqs[:cut],seqs[cut:],shuffle=False,bs=bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "07ab0549",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([64, 3]), torch.Size([64]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x,y = dls.one_batch()\n",
    "x.shape,y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8defdd61",
   "metadata": {},
   "source": [
    "## Our Language Model in PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fbc2f299",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLLM1(Module):\n",
    "    def __init__(self, vocab_sz, n_hidden):\n",
    "        self.i_h = nn.Embedding(vocab_sz,n_hidden)\n",
    "        self.h_h = nn.Linear(n_hidden,n_hidden)\n",
    "        self.h_o = nn.Linear(n_hidden,vocab_sz)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        h = self.i_h(x[:,0]) # Access the Emb vector for the first column\n",
    "        h = self.h_h(h) # Connect to the first set of Linear NN\n",
    "        h = F.relu(h) # Our Non - liearization\n",
    "        \n",
    "        h = h + self.i_h(x[:,1]) # Add the Emb vector for the second column\n",
    "        h = self.h_h(h) # Pass to the Linear Network\n",
    "        h = F.relu(h) # Again the Non-linearization\n",
    "        \n",
    "        h = h + self.i_h(x[:,2]) # Add the Emb vector for the third column\n",
    "        h = self.h_h(h) # Pass to the Linear Network\n",
    "        h = F.relu(h) # Again the Non-linearization\n",
    "        \n",
    "        h = self.h_o(h) # Pass to the output layer\n",
    "        return h"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27ad6ffe",
   "metadata": {},
   "source": [
    "Rewriting it as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "672d7482",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLLM2(Module):\n",
    "    def __init__(self, vocab_sz, n_hidden):\n",
    "        self.i_h = nn.Embedding(vocab_sz,n_hidden)\n",
    "        self.h_h = nn.Linear(n_hidden,n_hidden)\n",
    "        self.h_o = nn.Linear(n_hidden,vocab_sz)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        h = 0\n",
    "        num_cols = x.shape[1]\n",
    "        for i in range(num_cols):\n",
    "            h = h + self.i_h(x[:,i]) # Access the Emb vector for the respective column\n",
    "            h = self.h_h(h) # Connect to a Linear NN\n",
    "            h = F.relu(h) # Our Non - liearization\n",
    "        h = self.h_o(h) # Pass to the output layer\n",
    "        return h"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f930355a",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "06dc9018",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(30), 'xtit', 0.11856417693981146)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Baseline model of always predicting the mode of the tokens\n",
    "\n",
    "n,counts = 0,torch.zeros(len(vocab))\n",
    "for x,y in dls.valid:\n",
    "    n += y.shape[0]\n",
    "    for i in range_of(vocab): counts[i] += (y==i).long().sum()\n",
    "idx = torch.argmax(counts)\n",
    "idx, vocab[idx.item()], counts[idx].item()/n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7457b6c0",
   "metadata": {},
   "source": [
    "The baseline model of always predicting the `xtit` token gives an accuracy of 11.9%. <br>\n",
    "This seems high but it might be due to the fact that we are dealing with a news dataset which means that there are a lot of names and as such lots of `Titles`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7c64c7ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>6.666971</td>\n",
       "      <td>6.578431</td>\n",
       "      <td>0.126541</td>\n",
       "      <td>00:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>5.596445</td>\n",
       "      <td>6.450187</td>\n",
       "      <td>0.140863</td>\n",
       "      <td>00:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>5.209266</td>\n",
       "      <td>6.522380</td>\n",
       "      <td>0.149384</td>\n",
       "      <td>00:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>5.087563</td>\n",
       "      <td>6.569466</td>\n",
       "      <td>0.147208</td>\n",
       "      <td>00:12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn = Learner(dls, MyLLM2(len(vocab), 64), loss_func=F.cross_entropy, \n",
    "                metrics=accuracy)\n",
    "learn.fit_one_cycle(4, 1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b771f8",
   "metadata": {},
   "source": [
    "This is barely better than the baseline model. Let's try a wider model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c7ac6b52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>6.059157</td>\n",
       "      <td>6.093016</td>\n",
       "      <td>0.177484</td>\n",
       "      <td>01:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.760472</td>\n",
       "      <td>6.491498</td>\n",
       "      <td>0.187999</td>\n",
       "      <td>01:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.488567</td>\n",
       "      <td>7.159233</td>\n",
       "      <td>0.194344</td>\n",
       "      <td>01:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.603580</td>\n",
       "      <td>7.664039</td>\n",
       "      <td>0.195613</td>\n",
       "      <td>02:01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn = Learner(dls, MyLLM2(len(vocab), 1024), loss_func=F.cross_entropy, \n",
    "                metrics=accuracy)\n",
    "learn.fit_one_cycle(4, 1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54c1416f",
   "metadata": {},
   "source": [
    "Significant improvement but still not the what I would be expecting <br>\n",
    "**NOTE:** \n",
    "> The validation loss is actually increasing while the accuracy increases. This means might mean that the corss entropy loss function is not the best metric but might still be a good loss function\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad35834",
   "metadata": {},
   "source": [
    "### Maintaining the state of the RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "06226ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLLM3(Module):\n",
    "    def __init__(self, vocab_sz, n_hidden):\n",
    "        self.i_h = nn.Embedding(vocab_sz,n_hidden)\n",
    "        self.h_h = nn.Linear(n_hidden,n_hidden)\n",
    "        self.h_o = nn.Linear(n_hidden,vocab_sz)\n",
    "        self.h = 0\n",
    "    \n",
    "    def forward(self,x):\n",
    "        num_cols = x.shape[1]\n",
    "        for i in range(num_cols):\n",
    "            self.h = self.h + self.i_h(x[:,i]) # Access the Emb vector for the respective column\n",
    "            self.h = self.h_h(self.h) # Connect to a Linear NN\n",
    "            self.h = F.relu(self.h) # Our Non - liearization\n",
    "        out = self.h_o(self.h) # Pass to the output layer\n",
    "        \n",
    "        self.h = self.h.detach()\n",
    "        return out\n",
    "    \n",
    "    def reset(self):\n",
    "        self.h = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "00543c4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(430, 64, 27578)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = len(seqs)//bs\n",
    "m,bs,len(seqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d69b8f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_chunks(ds, bs):\n",
    "    m = len(ds) // bs\n",
    "    new_ds = L()\n",
    "    for i in range(m): new_ds += L(ds[i + m*j] for j in range(bs))\n",
    "    return new_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3a573f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "cut = int(len(seqs) * 0.8)\n",
    "dls = DataLoaders.from_dsets(\n",
    "    group_chunks(seqs[:cut], bs), \n",
    "    group_chunks(seqs[cut:], bs), \n",
    "    bs=bs, drop_last=True, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c73fe6",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "106bbf5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>5.861144</td>\n",
       "      <td>6.101082</td>\n",
       "      <td>0.180959</td>\n",
       "      <td>01:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.603089</td>\n",
       "      <td>6.591463</td>\n",
       "      <td>0.190589</td>\n",
       "      <td>01:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.298100</td>\n",
       "      <td>7.098480</td>\n",
       "      <td>0.198946</td>\n",
       "      <td>02:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.330018</td>\n",
       "      <td>7.374490</td>\n",
       "      <td>0.201126</td>\n",
       "      <td>02:12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn = Learner(dls, MyLLM3(len(vocab), 1024), loss_func=F.cross_entropy, \n",
    "                metrics=accuracy,cbs=ModelResetter)\n",
    "learn.fit_one_cycle(4, 1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f5da7aa",
   "metadata": {},
   "source": [
    "Just slightly better but not much improvements from the `LLM2` model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "725c605a",
   "metadata": {},
   "source": [
    "### Creating more signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9d0aa72e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sl = 16\n",
    "seqs = L((tensor(nums[i:i+sl]), tensor(nums[i+1:i+sl+1]))\n",
    "         for i in range(0,len(nums)-sl-1,sl))\n",
    "cut = int(len(seqs) * 0.8)\n",
    "dls = DataLoaders.from_dsets(group_chunks(seqs[:cut], bs),\n",
    "                             group_chunks(seqs[cut:], bs),\n",
    "                             bs=bs, drop_last=True, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9194793",
   "metadata": {},
   "source": [
    "Looking at the first element of `seqs`, we can see that it contains two lists of the same size. The second list is the same as the first, but offset by one element:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "70cea374",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLLM4(Module):\n",
    "    def __init__(self, vocab_sz, n_hidden):\n",
    "        self.i_h = nn.Embedding(vocab_sz,n_hidden)\n",
    "        self.h_h = nn.Linear(n_hidden,n_hidden)\n",
    "        self.h_o = nn.Linear(n_hidden,vocab_sz)\n",
    "        self.h = 0\n",
    "    \n",
    "    def forward(self,x):\n",
    "        num_cols = x.shape[1]\n",
    "        outs = []\n",
    "        for i in range(num_cols):\n",
    "            self.h = self.h + self.i_h(x[:,i]) # Access the Emb vector for the respective column\n",
    "            self.h = self.h_h(self.h) # Connect to a Linear NN\n",
    "            self.h = F.relu(self.h) # Our Non - liearization\n",
    "            outs.append(self.h_o(self.h)) # Pass to the output layer\n",
    "        \n",
    "        self.h = self.h.detach()\n",
    "        return torch.stack(outs, dim=1)\n",
    "    \n",
    "    def reset(self):\n",
    "        self.h = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b1fe3d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_func(inp, targ):\n",
    "    return F.cross_entropy(inp.view(-1, len(vocab)), targ.view(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1b977660",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>6.721286</td>\n",
       "      <td>5.996181</td>\n",
       "      <td>0.184937</td>\n",
       "      <td>02:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>5.411833</td>\n",
       "      <td>5.813415</td>\n",
       "      <td>0.213867</td>\n",
       "      <td>01:53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>4.559037</td>\n",
       "      <td>5.838340</td>\n",
       "      <td>0.220093</td>\n",
       "      <td>01:54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4.067402</td>\n",
       "      <td>5.856371</td>\n",
       "      <td>0.225464</td>\n",
       "      <td>01:55</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn = Learner(dls, MyLLM4(len(vocab), 1024), loss_func=loss_func, \n",
    "                metrics=accuracy,cbs=ModelResetter)\n",
    "learn.fit_one_cycle(4, 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2be238e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_pred(length,start=95):\n",
    "    to_pred = nums[start:start+length]\n",
    "    ans = nums[start+1:start+length+1]\n",
    "    \n",
    "    result = learn.predict(tensor([to_pred]))[0].argmax(1)\n",
    "    print(result,ans)\n",
    "\n",
    "    prompt = \"\"\n",
    "    for i in range(len(to_pred)):\n",
    "        prompt += vocab[to_pred[i]] +' '\n",
    "#     print(prompt)\n",
    "    prompt += \" <>  \"\n",
    "\n",
    "    for i in range(len(result)):\n",
    "        prompt += vocab[result[i]] + ' '\n",
    "#     return prompt\n",
    "    print(prompt)\n",
    "    \n",
    "    prompt = ' '.join(prompt.split(' ')[:len(ans)])\n",
    "    prompt += \"  <>  \"\n",
    "\n",
    "    for i in range(len(ans)):\n",
    "        prompt += vocab[ans[i]] + ' '\n",
    "    print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "31fce6c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 317,   53,  371, 3210,   29,   30, 2416,   30,   30,   78]) [513, 74, 1, 10144, 10149, 11, 2554, 24, 89, 78]\n",
      "kutoa dawa kwa xupp waviu unasambaa nchi nzima , ili  <>  huduma za ajili atcl . xtit wanachama xtit xtit kuhakikisha \n",
      "kutoa dawa kwa xupp waviu unasambaa nchi nzima , ili  <>  dawa kwa xupp waviu unasambaa nchi nzima , ili kuhakikisha \n"
     ]
    }
   ],
   "source": [
    "sample_pred(10,80000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d0828a3",
   "metadata": {},
   "source": [
    "I am actually very surprised. Like I am wowed already.\n",
    "\n",
    "The original text is \" of the Government of the Fifth Phase is to promote \"<br>\n",
    "The predicted text is \" of Tanzania's Fifth Phase under promotion \"\n",
    "\n",
    "<b>NB</b>: \n",
    "<li> Translation done via Google Translate </li>\n",
    "<li> This prediction was done on the training set (But it is still remarkable I believe) </li>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d597677",
   "metadata": {},
   "source": [
    "### Multi-Layer RNNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e0d11578",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLLM5(Module):\n",
    "    def __init__(self, vocab_sz, n_hidden,n_layers):\n",
    "        self.i_h = nn.Embedding(vocab_sz,n_hidden)\n",
    "        \n",
    "        self.network = []\n",
    "        for i in range(n_layers):\n",
    "            self.network.append(nn.Linear(n_hidden,n_hidden))\n",
    "            self.network.append(nn.ReLU())\n",
    "        self.h_h = nn.Sequential(\n",
    "            *self.network[:-1]\n",
    "        )\n",
    "#         self.h_h = nn.Linear(n_hidden,n_hidden)\n",
    "        self.h_o = nn.Linear(n_hidden,vocab_sz)\n",
    "        self.h = 0\n",
    "    \n",
    "    def forward(self,x):\n",
    "        num_cols = x.shape[1]\n",
    "        outs = []\n",
    "        for i in range(num_cols):\n",
    "            self.h = self.h + self.i_h(x[:,i]) # Access the Emb vector for the respective column\n",
    "            self.h = self.h_h(self.h) # Connect to a Linear NN\n",
    "            self.h = F.relu(self.h) # Our Non - liearization\n",
    "            outs.append(self.h_o(self.h)) # Pass to the output layer\n",
    "        \n",
    "        self.h = self.h.detach()\n",
    "        return torch.stack(outs, dim=1)\n",
    "    \n",
    "    def reset(self):\n",
    "        self.h = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0b9a576b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>7.322281</td>\n",
       "      <td>6.524433</td>\n",
       "      <td>0.123474</td>\n",
       "      <td>02:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>6.249574</td>\n",
       "      <td>6.138880</td>\n",
       "      <td>0.174561</td>\n",
       "      <td>02:20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>5.706321</td>\n",
       "      <td>6.077151</td>\n",
       "      <td>0.194214</td>\n",
       "      <td>02:20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>5.399840</td>\n",
       "      <td>5.974981</td>\n",
       "      <td>0.206482</td>\n",
       "      <td>02:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5.192619</td>\n",
       "      <td>5.941630</td>\n",
       "      <td>0.208313</td>\n",
       "      <td>02:25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn = Learner(dls, MyLLM5(len(vocab), 1024,4), loss_func=loss_func, \n",
    "                metrics=accuracy,cbs=ModelResetter)\n",
    "learn.fit_one_cycle(5, 1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "223aa913",
   "metadata": {},
   "source": [
    "In other words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "717f29b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLLM6(Module):\n",
    "    def __init__(self, vocab_sz, n_hidden,n_layers):\n",
    "        self.i_h = nn.Embedding(vocab_sz,n_hidden)\n",
    "        self.rnn = nn.RNN(n_hidden,n_hidden, n_layers, batch_first=True)\n",
    "        self.h_o = nn.Linear(n_hidden,vocab_sz)\n",
    "        self.h = torch.zeros(n_layers, bs, n_hidden) # Some changes here\n",
    "    \n",
    "    def forward(self,x):\n",
    "        res,h = self.rnn(self.i_h(x), self.h)\n",
    "        self.h = h.detach()\n",
    "        return self.h_o(res)\n",
    "    \n",
    "    def reset(self):\n",
    "        self.h.zero_ # Some changes here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bb261823",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>9.168292</td>\n",
       "      <td>9.100160</td>\n",
       "      <td>0.000244</td>\n",
       "      <td>00:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>8.904344</td>\n",
       "      <td>8.627542</td>\n",
       "      <td>0.123413</td>\n",
       "      <td>00:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>8.302516</td>\n",
       "      <td>7.801092</td>\n",
       "      <td>0.123413</td>\n",
       "      <td>00:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>7.472072</td>\n",
       "      <td>7.004415</td>\n",
       "      <td>0.123413</td>\n",
       "      <td>00:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>6.802113</td>\n",
       "      <td>6.654023</td>\n",
       "      <td>0.123413</td>\n",
       "      <td>00:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>6.505718</td>\n",
       "      <td>6.649345</td>\n",
       "      <td>0.123413</td>\n",
       "      <td>00:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>6.416265</td>\n",
       "      <td>6.684720</td>\n",
       "      <td>0.123413</td>\n",
       "      <td>00:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>6.392974</td>\n",
       "      <td>6.720998</td>\n",
       "      <td>0.123413</td>\n",
       "      <td>00:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>6.388571</td>\n",
       "      <td>6.754602</td>\n",
       "      <td>0.123413</td>\n",
       "      <td>00:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>6.388556</td>\n",
       "      <td>6.784073</td>\n",
       "      <td>0.123413</td>\n",
       "      <td>00:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>6.388538</td>\n",
       "      <td>6.808982</td>\n",
       "      <td>0.123413</td>\n",
       "      <td>00:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>6.388036</td>\n",
       "      <td>6.828641</td>\n",
       "      <td>0.123413</td>\n",
       "      <td>00:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>6.386859</td>\n",
       "      <td>6.839571</td>\n",
       "      <td>0.123413</td>\n",
       "      <td>00:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>6.385152</td>\n",
       "      <td>6.848008</td>\n",
       "      <td>0.123413</td>\n",
       "      <td>00:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>6.363021</td>\n",
       "      <td>6.710010</td>\n",
       "      <td>0.123413</td>\n",
       "      <td>00:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>6.274632</td>\n",
       "      <td>6.620764</td>\n",
       "      <td>0.124695</td>\n",
       "      <td>00:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>6.173934</td>\n",
       "      <td>6.542818</td>\n",
       "      <td>0.127197</td>\n",
       "      <td>00:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>6.072442</td>\n",
       "      <td>6.478372</td>\n",
       "      <td>0.141785</td>\n",
       "      <td>00:20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>5.974035</td>\n",
       "      <td>6.426777</td>\n",
       "      <td>0.145508</td>\n",
       "      <td>00:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>5.896048</td>\n",
       "      <td>6.386860</td>\n",
       "      <td>0.145874</td>\n",
       "      <td>00:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>5.836226</td>\n",
       "      <td>6.364661</td>\n",
       "      <td>0.146362</td>\n",
       "      <td>00:20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>5.787189</td>\n",
       "      <td>6.347745</td>\n",
       "      <td>0.146973</td>\n",
       "      <td>00:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>5.746952</td>\n",
       "      <td>6.336757</td>\n",
       "      <td>0.148438</td>\n",
       "      <td>00:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>5.711193</td>\n",
       "      <td>6.327896</td>\n",
       "      <td>0.147522</td>\n",
       "      <td>00:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>5.680714</td>\n",
       "      <td>6.325665</td>\n",
       "      <td>0.148987</td>\n",
       "      <td>00:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>5.655386</td>\n",
       "      <td>6.320650</td>\n",
       "      <td>0.148071</td>\n",
       "      <td>00:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>5.630268</td>\n",
       "      <td>6.307567</td>\n",
       "      <td>0.148987</td>\n",
       "      <td>00:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>5.607337</td>\n",
       "      <td>6.304221</td>\n",
       "      <td>0.150208</td>\n",
       "      <td>00:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>5.587847</td>\n",
       "      <td>6.305529</td>\n",
       "      <td>0.151306</td>\n",
       "      <td>00:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>5.570995</td>\n",
       "      <td>6.307346</td>\n",
       "      <td>0.151672</td>\n",
       "      <td>00:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>5.557240</td>\n",
       "      <td>6.296929</td>\n",
       "      <td>0.152466</td>\n",
       "      <td>00:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>5.546421</td>\n",
       "      <td>6.281238</td>\n",
       "      <td>0.154114</td>\n",
       "      <td>00:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>5.535909</td>\n",
       "      <td>6.279964</td>\n",
       "      <td>0.153931</td>\n",
       "      <td>00:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>5.527345</td>\n",
       "      <td>6.278371</td>\n",
       "      <td>0.153809</td>\n",
       "      <td>00:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>5.520557</td>\n",
       "      <td>6.278694</td>\n",
       "      <td>0.153809</td>\n",
       "      <td>00:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>5.515143</td>\n",
       "      <td>6.279878</td>\n",
       "      <td>0.154175</td>\n",
       "      <td>00:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>5.511100</td>\n",
       "      <td>6.278821</td>\n",
       "      <td>0.154175</td>\n",
       "      <td>00:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>5.508552</td>\n",
       "      <td>6.278830</td>\n",
       "      <td>0.154602</td>\n",
       "      <td>00:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>5.506904</td>\n",
       "      <td>6.280068</td>\n",
       "      <td>0.154724</td>\n",
       "      <td>00:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>5.506052</td>\n",
       "      <td>6.280140</td>\n",
       "      <td>0.154724</td>\n",
       "      <td>00:17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn = Learner(dls, MyLLM6(len(vocab), 64,8), loss_func=loss_func, \n",
    "                metrics=accuracy,cbs=ModelResetter)\n",
    "learn.fit_one_cycle(40, 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e32fec5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>7.206618</td>\n",
       "      <td>6.632511</td>\n",
       "      <td>0.123535</td>\n",
       "      <td>01:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>6.505537</td>\n",
       "      <td>6.335779</td>\n",
       "      <td>0.148804</td>\n",
       "      <td>01:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>6.064344</td>\n",
       "      <td>6.258500</td>\n",
       "      <td>0.156311</td>\n",
       "      <td>01:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>5.711269</td>\n",
       "      <td>6.267188</td>\n",
       "      <td>0.179321</td>\n",
       "      <td>01:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5.387817</td>\n",
       "      <td>6.297754</td>\n",
       "      <td>0.187561</td>\n",
       "      <td>01:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>5.103578</td>\n",
       "      <td>6.343325</td>\n",
       "      <td>0.197327</td>\n",
       "      <td>01:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>4.852474</td>\n",
       "      <td>6.378828</td>\n",
       "      <td>0.197449</td>\n",
       "      <td>01:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>4.602668</td>\n",
       "      <td>6.433287</td>\n",
       "      <td>0.197998</td>\n",
       "      <td>01:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>4.435003</td>\n",
       "      <td>6.431808</td>\n",
       "      <td>0.202087</td>\n",
       "      <td>01:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>4.382489</td>\n",
       "      <td>6.385107</td>\n",
       "      <td>0.209961</td>\n",
       "      <td>01:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>4.322196</td>\n",
       "      <td>6.346689</td>\n",
       "      <td>0.209167</td>\n",
       "      <td>01:43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>4.062466</td>\n",
       "      <td>6.346803</td>\n",
       "      <td>0.212341</td>\n",
       "      <td>01:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>3.810648</td>\n",
       "      <td>6.349730</td>\n",
       "      <td>0.213379</td>\n",
       "      <td>01:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>3.634504</td>\n",
       "      <td>6.352702</td>\n",
       "      <td>0.215820</td>\n",
       "      <td>01:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>3.520576</td>\n",
       "      <td>6.338998</td>\n",
       "      <td>0.214783</td>\n",
       "      <td>01:44</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn = Learner(dls, MyLLM6(len(vocab), 1024,4), loss_func=CrossEntropyLossFlat(), # Change in the loss function\n",
    "                metrics=accuracy,cbs=ModelResetter)\n",
    "learn.fit_one_cycle(15, 1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf23319",
   "metadata": {},
   "source": [
    "Due to the problems of exploding or diasappearing activations, We will consider the use of LSTMs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bc41423",
   "metadata": {},
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "01b2fbe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLLM7(Module):\n",
    "    def __init__(self, ni, h):\n",
    "        self.forget_gate = nn.Linear(ni + nh, nh)\n",
    "        self.input_gate = nn.Linear(ni + nh, nh)\n",
    "        self.cell_gate = nn.Linear(ni + nh, nh)\n",
    "        self.output_gate = nn.Linear(ni + nh, nh)\n",
    "    \n",
    "    def forward(self, x, state):\n",
    "        h,c = state\n",
    "        h = torch.cat([h, x], dim=1)\n",
    "        forget = torch.sigmoid(self.forget_gate(h))\n",
    "        c = c * forget\n",
    "        \n",
    "        inputer = torchinput_gateigmoid(self.input_gate(h)) * torch.tanh(self.cell_gate(h))\n",
    "        c = c + inputer\n",
    "        \n",
    "        outputer = torch.sigmoid(self.output_gate(h))\n",
    "        h = torch.tanh(c) * outputer\n",
    "        return h, (h,c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb7f8e39",
   "metadata": {},
   "source": [
    "Refactoring the above for increase in GPU performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fabd7fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLLM8(Module):\n",
    "    def __init__(self, ni, h):\n",
    "        self.ih = nn.Linear(ni,4*nh)\n",
    "        self.hh = nn.Linear(nh,4*nh)\n",
    "    \n",
    "    def forward(self, x, state):\n",
    "        h,c = state\n",
    "        \n",
    "        gates = (self.ih(x) + self.hh(h)).chunk(4,1)\n",
    "        ingate, forgetgate, outgate = map(torch.sigmoid, gates[:3]) ## Note: order does not matter here\n",
    "        cellgate = torch.tanh(gates[3])\n",
    "\n",
    "        c = forgetgate*c + ingate*cellgate\n",
    "        h = outgate * torch.tanh(c)\n",
    "        return h, (h,c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94d6a309",
   "metadata": {},
   "source": [
    "Now the LTSM network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4c206c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLLM9(Module):\n",
    "    def __init__(self, vocab_sz, n_hidden,n_layers):\n",
    "        self.i_h = nn.Embedding(vocab_sz,n_hidden)\n",
    "        self.rnn = nn.LSTM(n_hidden,n_hidden, n_layers, batch_first=True)\n",
    "        self.h_o = nn.Linear(n_hidden,vocab_sz)\n",
    "        self.h = [torch.zeros(n_layers, bs, n_hidden) for _ in range(2)] # Some changes here\n",
    "    \n",
    "    def forward(self,x):\n",
    "        res,h = self.rnn(self.i_h(x), self.h)\n",
    "        self.h = [h_.detach() for h_ in h]\n",
    "        return self.h_o(res)\n",
    "    \n",
    "    def reset(self):\n",
    "        for h in self.h:\n",
    "            h.zero_ # Some changes here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6bc51699",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>8.046610</td>\n",
       "      <td>6.677588</td>\n",
       "      <td>0.123413</td>\n",
       "      <td>03:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>6.866250</td>\n",
       "      <td>6.771533</td>\n",
       "      <td>0.123413</td>\n",
       "      <td>03:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>6.603065</td>\n",
       "      <td>6.793954</td>\n",
       "      <td>0.123413</td>\n",
       "      <td>04:52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>6.404156</td>\n",
       "      <td>6.493436</td>\n",
       "      <td>0.143433</td>\n",
       "      <td>04:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>6.020103</td>\n",
       "      <td>6.270433</td>\n",
       "      <td>0.157898</td>\n",
       "      <td>04:20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>5.679213</td>\n",
       "      <td>6.216846</td>\n",
       "      <td>0.168457</td>\n",
       "      <td>04:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>5.389202</td>\n",
       "      <td>6.256194</td>\n",
       "      <td>0.179688</td>\n",
       "      <td>03:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>5.135345</td>\n",
       "      <td>6.263578</td>\n",
       "      <td>0.177368</td>\n",
       "      <td>03:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>4.894420</td>\n",
       "      <td>6.385754</td>\n",
       "      <td>0.181824</td>\n",
       "      <td>03:23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>4.677739</td>\n",
       "      <td>6.367319</td>\n",
       "      <td>0.183960</td>\n",
       "      <td>03:21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>4.529482</td>\n",
       "      <td>6.403199</td>\n",
       "      <td>0.180603</td>\n",
       "      <td>04:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>4.408565</td>\n",
       "      <td>6.465645</td>\n",
       "      <td>0.178101</td>\n",
       "      <td>04:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>4.286304</td>\n",
       "      <td>6.513074</td>\n",
       "      <td>0.173584</td>\n",
       "      <td>04:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>4.167831</td>\n",
       "      <td>6.553946</td>\n",
       "      <td>0.175842</td>\n",
       "      <td>04:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>4.098881</td>\n",
       "      <td>6.561907</td>\n",
       "      <td>0.175598</td>\n",
       "      <td>04:45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn = Learner(dls, MyLLM9(len(vocab), 1024, 4), \n",
    "                loss_func=CrossEntropyLossFlat(), \n",
    "                metrics=accuracy, cbs=ModelResetter)\n",
    "learn.fit_one_cycle(15, 1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f2b0c21",
   "metadata": {},
   "source": [
    "### Regularizing\n",
    "We will add the following methods as seen in the paper taught by Jeremy;\n",
    "<li> Dropout </li>\n",
    "<li> Activation Regularization (AR) and Temporal Activation Regularization (TAR) </li>\n",
    "<li> Weight Tying </li>\n",
    "\n",
    "The LSTM that uses these techniques are called AWD-LSTM according to the author."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6f88842d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLLM10(Module):\n",
    "    def __init__(self, vocab_sz, n_hidden,n_layers,p):\n",
    "        self.i_h = nn.Embedding(vocab_sz,n_hidden)\n",
    "        self.rnn = nn.LSTM(n_hidden,n_hidden, n_layers, batch_first=True)\n",
    "        self.drop = nn.Dropout(p) # Dropout\n",
    "        self.h_o = nn.Linear(n_hidden,vocab_sz)\n",
    "        self.h_o.weight = self.i_h.weight # Weight Tying\n",
    "        self.h = [torch.zeros(n_layers, bs, n_hidden) for _ in range(2)] # Some changes here\n",
    "        \n",
    "    def forward(self,x):\n",
    "        res,h = self.rnn(self.i_h(x), self.h)\n",
    "        out = self.drop(res)\n",
    "        self.h = [h_.detach() for h_ in h]\n",
    "        return self.h_o(out),res,out\n",
    "    \n",
    "    def reset(self):\n",
    "        for h in self.h:\n",
    "            h.zero_ # Some changes here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4c2798bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>7.547215</td>\n",
       "      <td>7.143775</td>\n",
       "      <td>0.127380</td>\n",
       "      <td>06:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>7.140987</td>\n",
       "      <td>6.830136</td>\n",
       "      <td>0.160583</td>\n",
       "      <td>06:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>6.594021</td>\n",
       "      <td>6.263524</td>\n",
       "      <td>0.202454</td>\n",
       "      <td>06:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>6.053841</td>\n",
       "      <td>6.107059</td>\n",
       "      <td>0.219360</td>\n",
       "      <td>06:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5.474316</td>\n",
       "      <td>6.181339</td>\n",
       "      <td>0.220276</td>\n",
       "      <td>05:51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>4.827559</td>\n",
       "      <td>6.608763</td>\n",
       "      <td>0.217346</td>\n",
       "      <td>05:20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>4.112146</td>\n",
       "      <td>7.035563</td>\n",
       "      <td>0.219360</td>\n",
       "      <td>06:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>3.345952</td>\n",
       "      <td>7.569582</td>\n",
       "      <td>0.214539</td>\n",
       "      <td>06:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>2.581167</td>\n",
       "      <td>8.133468</td>\n",
       "      <td>0.213135</td>\n",
       "      <td>05:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.884978</td>\n",
       "      <td>8.674470</td>\n",
       "      <td>0.213684</td>\n",
       "      <td>04:48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.325588</td>\n",
       "      <td>9.247314</td>\n",
       "      <td>0.212708</td>\n",
       "      <td>04:50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.918959</td>\n",
       "      <td>9.693373</td>\n",
       "      <td>0.212219</td>\n",
       "      <td>04:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.657756</td>\n",
       "      <td>10.136625</td>\n",
       "      <td>0.211914</td>\n",
       "      <td>06:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.501287</td>\n",
       "      <td>10.371964</td>\n",
       "      <td>0.212219</td>\n",
       "      <td>06:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.430036</td>\n",
       "      <td>10.430792</td>\n",
       "      <td>0.212402</td>\n",
       "      <td>06:11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn = Learner(dls, MyLLM10(len(vocab), 1024, 4, 0.5), \n",
    "                loss_func=CrossEntropyLossFlat(), \n",
    "                metrics=accuracy, \n",
    "                cbs=[ModelResetter,RNNRegularizer(alpha=2,beta=1)]\n",
    "               )\n",
    "\n",
    "# OR\n",
    "learn = TextLearner(dls, MyLLM10(len(vocab), 1024, 4, 0.4),\n",
    "                   loss_func = CrossEntropyLossFlat(), metrics=accuracy)\n",
    "\n",
    "learn.fit_one_cycle(15, 1e-3, wd=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3e7e3c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_p_nums = nums[-994:-970]\n",
    "to_p_nums = list(dls.valid.dataset[0][0])# + list(dls.valid.dataset[1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e0b585b5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ya kwa wa operesheni , na mkutano na ccm , lakini yake nafasi na nafasi "
     ]
    }
   ],
   "source": [
    "to_p = tensor([to_p_nums[:-1]]*64)\n",
    "\n",
    "prediction = learn.predict(to_p)#,[58]*64)])\n",
    "for p in prediction[0]:\n",
    "    print(vocab[p],end=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4855cd82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zinazoundwa wakati wa uchaguzi kuwa za maadili ya uchaguzi , kamati ya rufaa , kamati "
     ]
    }
   ],
   "source": [
    "for a in to_p_nums[1:]:\n",
    "    print(vocab[a],end= ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ddfe81",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
