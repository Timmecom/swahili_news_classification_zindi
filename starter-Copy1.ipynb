{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "065e33e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fastbook\n",
    "fastbook.setup_book()\n",
    "\n",
    "from fastbook import *\n",
    "import re\n",
    "from IPython.display import display,HTML\n",
    "\n",
    "from fastai.text.all import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e04528b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>content</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SW0</td>\n",
       "      <td>SERIKALI imesema haitakuwa tayari kuona amani na utulivu wa nchi inachezewa huku ikisisitiza uwepo wa umoja kati ya wananchi bila kujali tofauti ya imani, kabila au itikadi yoyote.Hayo yalisemwa na Naibu Waziri wa Mambo ya Ndani ya Nchi, Hamad Yussuf Masauni wakati akifungua semina ya siku mbili iliyofanyika jijini Dar es Salaam ikiwahusisha viongozi wa taasisi za Kiislamu, lengo ikiwa ni kuwakumbusha kuhubiri amani katika sehemu zao.Naibu Waziri amesema mwelekeo na malengo ya Serikali ya Awamu ya Tano ni kukuza maendeleo katika sehemu mbalimbali nchini lengo ikiwa kuinua maisha ya wananc...</td>\n",
       "      <td>Kitaifa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id  \\\n",
       "0  SW0   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   content  \\\n",
       "0   SERIKALI imesema haitakuwa tayari kuona amani na utulivu wa nchi inachezewa huku ikisisitiza uwepo wa umoja kati ya wananchi bila kujali tofauti ya imani, kabila au itikadi yoyote.Hayo yalisemwa na Naibu Waziri wa Mambo ya Ndani ya Nchi, Hamad Yussuf Masauni wakati akifungua semina ya siku mbili iliyofanyika jijini Dar es Salaam ikiwahusisha viongozi wa taasisi za Kiislamu, lengo ikiwa ni kuwakumbusha kuhubiri amani katika sehemu zao.Naibu Waziri amesema mwelekeo na malengo ya Serikali ya Awamu ya Tano ni kukuza maendeleo katika sehemu mbalimbali nchini lengo ikiwa kuinua maisha ya wananc...   \n",
       "\n",
       "  category  \n",
       "0  Kitaifa  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('datasets/Train.csv')\n",
    "test = pd.read_csv('datasets/Test.csv')\n",
    "train.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83029954",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Index(['id', 'content', 'category'], dtype='object'),\n",
       " Index(['swahili_id', 'content'], dtype='object'))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns,test.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f6e56f",
   "metadata": {},
   "source": [
    "### Read the entire texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "id": "8e1acbc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' SERIKALI imetoa miezi sita kwa taasisi zote za umma ambazo hazitumii mfumo wa GePG katika ukusanyaji wa fedha kufanya hivyo na baada ya hapo itafanya ukaguzi na kuwawajibisha maofi sa masuhuli walioshindwa kutekeleza hilo.Akifungua mkutano wa mwaka wa kwanza wa watumiaji wa mfumo huo jana jijini hapa, Naibu Katibu Mkuu Wizara ya Fedha na Mipango, Dk Hartibu Kazungu alisema ukaguzi huo ambao utaanza kufanyika Juni mwakani baada ya kipindi kilichowekwa kupita ili kuwabaini maofisa wazembe.Alisema, wizara yake itafanya ukaguzi wa ofisi zote za umma ili kubaini kama kuna fedha zinazokusanywa bila kupitia kwenye mfumo wa GePG na kuwa ofisi itakayobainika kutotumia mfumo huo maofisa masuhuli watawajibishwa kwa mujibu wa sheria. Mnifikishie ujumbe wa kuzikumbusha taasisi ambazo hazijaanza kutumia mfumo wa ukusanyaji mapato wa GePG kufanya hivyo, kwani tunataka hadi kufikia Juni 30, mwaka 2019, kusiwe na fedha yoyote kwenye taasisi ya umma ambayo inakusanywa nje ya mfumo huu,  alisema.Hata hivyo, alisisitiza kuwa utaratibu wa malipo kupitia GePG unawapa fursa ya kuwa na njia nyingi za kulipia zikiwa na lengo la kuwapa walipaji wa huduma za serikali utaratibu rafiki na machaguo mengi ya njia za kufanya malipo. Nimepewa taarifa kuwa takribani benki kumi na moja (11) na mitandao sita ya malipo kwa njia ya simu za kiganjani zimeshaunganishwa na GePG.  Hii ni kuthibitisha namna mfumo wa GePG umekuwa na fursa nyingi za ulipaji, hivyo kuweka mazingira kwa umma katika kufanya malipo hivyo kuondoa urasimu na ucheleweshaji usiofaa. Dk Kazungu alisema kuwa mfumo huo ulianzishwa ili kuongeza uwazi na udhibiti wa fedha za umma, kuboresha na kurahisisha namna ya kulipia huduma za umma pamoja na kupunguza gharama zinazoambatana na ukusanyaji wa fedha za umma.Akizungumza na waandishi wa habari baada ya ufunguzi huo Mkurugenzi wa mfumo kutoka wizara hiyo, John Sausi alisema changamoto wanayokuta nayo katika utekelezaji wa mfumo huo uelewa mdogo wa namna ya kutumia.Katika utekelezaji wa mfumo huo tuna changamoto moja kubwa ambayo ni uelewa wa watumiaji wa mfumo kushindwa kutumia vyema mfumo huu vizuri hivyo kulazimika kutumia watu wa operesheni kwa ajili ya kurudia utoaji wa elimu.Alisema changamoto nyingine ni ukosekanaji kwa mtandao katika maeneo ya vijijini hivyo mfumo kushindwa kufanya kazi.  Changamoto ya mtandao tunaangalia namna ya kukabiliana nayo mwaka mzima tangu kuanza kwa mfumo huu, lakini kama wizara tunaamini haiwezi kutusumbua,  alisema. Aidha, Sausi alisema tangu kuanza kutumika kwa mufmo huo hapa nchini hadi sasa taasisi 326 tayari zinatumia mfumo huo katika kutoa huduma.'"
      ]
     },
     "execution_count": 540,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.iloc[2,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "8e9059ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6439"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clean_row(x):\n",
    "    x = ''.join(x.split('\\'')).strip('[]')\n",
    "    return re.sub(r\"[^\\x00-\\x7F]\", ' ', x)\n",
    "    \n",
    "txts = L(\n",
    "    list(train['content'].apply(clean_row).values) + \n",
    "#     list(train.loc[:,'content'].values) + \n",
    "#     list(test.loc[:,'content'].values) \n",
    "    list(test['content'].apply(clean_row).values)\n",
    ")\n",
    "len(txts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2da7780",
   "metadata": {},
   "source": [
    "### Concatenate into one big stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "d8564add",
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy = WordTokenizer()\n",
    "tkn = Tokenizer(spacy)\n",
    "\n",
    "toks200 = txts[:200].map(tkn)\n",
    "\n",
    "num = Numericalize()\n",
    "num.setup(toks200)\n",
    "\n",
    "nums200 = toks200.map(num)\n",
    "\n",
    "dl = LMDataLoader(nums200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "id": "7c89571a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([64, 72]), torch.Size([64, 72]))"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x,y = first(dl)\n",
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "id": "931aef40",
   "metadata": {},
   "outputs": [],
   "source": [
    "TextBlock.from_df??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "id": "1f185a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['content_cleaned'] = train['content'].apply(clean_row)\n",
    "test['content_cleaned'] = test['content'].apply(clean_row)\n",
    "\n",
    "train.to_csv('train/Train.csv')\n",
    "test.to_csv('test/Test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "id": "33108fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in train.index:\n",
    "    filename = f'train/{train.loc[i,\"id\"]}.txt'\n",
    "    with open(filename,'w') as f:\n",
    "        f.write(train.loc[i,'content_cleaned'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "id": "f985b012",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in test.index:\n",
    "    filename = f'test/{test.loc[i,\"swahili_id\"]}.txt'\n",
    "    with open(filename,'w') as f:\n",
    "        f.write(test.loc[i,'content_cleaned'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc291332",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "id": "a6ff59d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#2) [Path('test/Test.csv'),Path('train/Train.csv')]"
      ]
     },
     "execution_count": 381,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_files('',extensions=['.csv'],folders=['train','test',],recurse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "id": "864ffa55",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_text_files??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "id": "bfd0d62a",
   "metadata": {},
   "outputs": [],
   "source": [
    "partial??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "id": "142342ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "TextBlock??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "id": "1c4de79b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<fastai.text.data.TextBlock at 0x280fee20f10>"
      ]
     },
     "execution_count": 407,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TextBlock.from_df('gh',is_lm=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b29e5b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "id": "bf685d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "train[:4].to_csv('train/Train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "948e00f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "id": "de232686",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Path('.')"
      ]
     },
     "execution_count": 455,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = Path('')\n",
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "id": "a192f554",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Due to IPython and Windows limitation, python multiprocessing isn't available now.\n",
      "So `n_workers` has to be changed to 0 to avoid getting stuck\n"
     ]
    }
   ],
   "source": [
    "get_news = partial(get_text_files, folders=['train','test'])\n",
    "\n",
    "db = DataBlock(\n",
    "    blocks = TextBlock.from_folder(path,is_lm=True),\n",
    "    get_items = get_news,\n",
    "    splitter = RandomSplitter(0.1),\n",
    ")\n",
    "\n",
    "dls_lm = db.dataloaders(path, path=path, bs=128, seq_len=80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "id": "5d5e215a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>text_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xxbos xxmaj wamewahakikishia kuwa hivi sasa ushiriki wao unahitajika kwa maendeleo ya kiuchumi na kwa faida ya wananchi wa nchi hizo.rais xxmaj jakaya xxmaj kikwete alisema sekta ya biashara , wako tayari kufanya kazi sehemu xxunk kupata fedha . xxmaj alisema huu ni wakati wa watendaji katika nchi hizo , kufanya kazi kibiashara na kuachana na tabia ya urasimu , ambayo imekuwa xxunk wawekezaji . xxmaj kama tutafanya kazi kibiashara , miradi ya miundombinu itaweza kukamilika katika kipindi cha muda</td>\n",
       "      <td>xxmaj wamewahakikishia kuwa hivi sasa ushiriki wao unahitajika kwa maendeleo ya kiuchumi na kwa faida ya wananchi wa nchi hizo.rais xxmaj jakaya xxmaj kikwete alisema sekta ya biashara , wako tayari kufanya kazi sehemu xxunk kupata fedha . xxmaj alisema huu ni wakati wa watendaji katika nchi hizo , kufanya kazi kibiashara na kuachana na tabia ya urasimu , ambayo imekuwa xxunk wawekezaji . xxmaj kama tutafanya kazi kibiashara , miradi ya miundombinu itaweza kukamilika katika kipindi cha muda mfupi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lengo letu ni moja kuijenga nchi hii , alisema xxmaj mchange . xxmaj aidha alisema endapo xxmaj muswada huo xxunk na xxmaj rais na kuwa sheria , mapendekezo yake kwa serikali ni kwamba xxunk kubadili vipengele vilivyomo ndani , bali inapaswa iende mbali na kuwachukulia hatua watu wote watakaokwenda kinyume na sheria husika . xxbos xxup wakazi wa xxmaj mkoa wa xxmaj kagera hususani xxmaj bukoba xxmaj mjini pamoja na wilaya za xxmaj misenyi , xxmaj kyerwa na xxmaj karagwe</td>\n",
       "      <td>letu ni moja kuijenga nchi hii , alisema xxmaj mchange . xxmaj aidha alisema endapo xxmaj muswada huo xxunk na xxmaj rais na kuwa sheria , mapendekezo yake kwa serikali ni kwamba xxunk kubadili vipengele vilivyomo ndani , bali inapaswa iende mbali na kuwachukulia hatua watu wote watakaokwenda kinyume na sheria husika . xxbos xxup wakazi wa xxmaj mkoa wa xxmaj kagera hususani xxmaj bukoba xxmaj mjini pamoja na wilaya za xxmaj misenyi , xxmaj kyerwa na xxmaj karagwe ,</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dls_lm.show_batch(max_n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 648,
   "id": "dabdc3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLLM10(Module):\n",
    "    def __init__(self, vocab_sz, n_hidden,n_layers,p):\n",
    "        self.i_h = nn.Embedding(vocab_sz,n_hidden)\n",
    "        self.rnn = nn.LSTM(n_hidden,n_hidden, n_layers, batch_first=True)\n",
    "        self.drop = nn.Dropout(p) # Dropout\n",
    "        self.h_o = nn.Linear(n_hidden,vocab_sz)\n",
    "        self.h_o.weight = self.i_h.weight # Weight Tying\n",
    "        self.h = [torch.zeros(n_layers, bs, n_hidden) for _ in range(2)] # Some changes here\n",
    "    \n",
    "    def forward(self,x):\n",
    "        res,h = self.rnn(self.i_h(x), self.h)\n",
    "        out = self.drop(res)\n",
    "        self.h = [h_.detach() for h_ in h]\n",
    "        return self.h_o(out),res,out\n",
    "    \n",
    "    def reset(self):\n",
    "        for h in self.h:\n",
    "            h.zero_ # Some changes here\n",
    "    \n",
    "\n",
    "class MyLLM11(Module):\n",
    "    \"AWD-LSTM inspired by https://arxiv.org/abs/1708.02182\"\n",
    "    initrange=0.1\n",
    "\n",
    "    def __init__(self, \n",
    "        vocab_sz:int, # Size of the vocabulary\n",
    "        emb_sz:int, # Size of embedding vector\n",
    "        n_hid:int, # Number of features in hidden state\n",
    "        n_layers:int, # Number of LSTM layers\n",
    "        pad_token:int=1, # Padding token id\n",
    "        hidden_p:float=0.2, # Dropout probability for hidden state between layers\n",
    "        input_p:float=0.6, # Dropout probability for LSTM stack input\n",
    "        embed_p:float=0.1, # Embedding layer dropout probabillity\n",
    "        weight_p:float=0.5, # Hidden-to-hidden wight dropout probability for LSTM layers\n",
    "        bidir:bool=False # If set to `True` uses bidirectional LSTM layers\n",
    "    ):\n",
    "        store_attr('emb_sz,n_hid,n_layers,pad_token')\n",
    "        self.bs = 1\n",
    "        self.n_dir = 2 if bidir else 1\n",
    "        self.encoder = nn.Embedding(vocab_sz, emb_sz, padding_idx=pad_token)\n",
    "        self.encoder_dp = EmbeddingDropout(self.encoder, embed_p)\n",
    "        self.rnns = nn.ModuleList([self._one_rnn(emb_sz if l == 0 else n_hid, (n_hid if l != n_layers - 1 else emb_sz)//self.n_dir,\n",
    "                                                 bidir, weight_p, l) for l in range(n_layers)])\n",
    "        self.encoder.weight.data.uniform_(-self.initrange, self.initrange)\n",
    "        self.input_dp = RNNDropout(input_p)\n",
    "        self.hidden_dps = nn.ModuleList([RNNDropout(hidden_p) for l in range(n_layers)])\n",
    "        self.reset()\n",
    "\n",
    "    def forward(self, inp:Tensor, from_embeds:bool=False):\n",
    "        bs,sl = inp.shape[:2] if from_embeds else inp.shape\n",
    "        if bs!=self.bs: self._change_hidden(bs)\n",
    "\n",
    "        output = self.input_dp(inp if from_embeds else self.encoder_dp(inp))\n",
    "        new_hidden = []\n",
    "        for l, (rnn,hid_dp) in enumerate(zip(self.rnns, self.hidden_dps)):\n",
    "            output, new_h = rnn(output, self.hidden[l])\n",
    "            new_hidden.append(new_h)\n",
    "            if l != self.n_layers - 1: output = hid_dp(output)\n",
    "        self.hidden = to_detach(new_hidden, cpu=False, gather=False)\n",
    "        return tensor(np.zeros((10240,1))),tensor(np.zeros((10240,1))),tensor(np.zeros((10240)))\n",
    "\n",
    "    def _change_hidden(self, bs):\n",
    "        self.hidden = [self._change_one_hidden(l, bs) for l in range(self.n_layers)]\n",
    "        self.bs = bs\n",
    "\n",
    "    def _one_rnn(self, n_in, n_out, bidir, weight_p, l):\n",
    "        \"Return one of the inner rnn\"\n",
    "        rnn = nn.LSTM(n_in, n_out, 1, batch_first=True, bidirectional=bidir)\n",
    "        return WeightDropout(rnn, weight_p)\n",
    "\n",
    "    def _one_hidden(self, l):\n",
    "        \"Return one hidden state\"\n",
    "        nh = (self.n_hid if l != self.n_layers - 1 else self.emb_sz) // self.n_dir\n",
    "        return (one_param(self).new_zeros(self.n_dir, self.bs, nh), one_param(self).new_zeros(self.n_dir, self.bs, nh))\n",
    "\n",
    "    def _change_one_hidden(self, l, bs):\n",
    "        if self.bs < bs:\n",
    "            nh = (self.n_hid if l != self.n_layers - 1 else self.emb_sz) // self.n_dir\n",
    "            return tuple(torch.cat([h, h.new_zeros(self.n_dir, bs-self.bs, nh)], dim=1) for h in self.hidden[l])\n",
    "        if self.bs > bs: return (self.hidden[l][0][:,:bs].contiguous(), self.hidden[l][1][:,:bs].contiguous())\n",
    "        return self.hidden[l]\n",
    "\n",
    "    def reset(self):\n",
    "        \"Reset the hidden states\"\n",
    "        [r.reset() for r in self.rnns if hasattr(r, 'reset')]\n",
    "        self.hidden = [self._one_hidden(l) for l in range(self.n_layers)]\n",
    "        \n",
    "class MyLLM4(Module):\n",
    "    def __init__(self, vocab_sz, n_hidden):\n",
    "        self.i_h = nn.Embedding(vocab_sz,n_hidden)\n",
    "        self.h_h = nn.Linear(n_hidden,n_hidden)\n",
    "        self.h_o = nn.Linear(n_hidden,vocab_sz)\n",
    "        self.h = 0\n",
    "    \n",
    "    def forward(self,x):\n",
    "        num_cols = x.shape[1]\n",
    "        outs = []\n",
    "        for i in range(num_cols):\n",
    "            self.h = self.h + self.i_h(x[:,i]) # Access the Emb vector for the respective column\n",
    "            self.h = self.h_h(self.h) # Connect to a Linear NN\n",
    "            self.h = F.relu(self.h) # Our Non - liearization\n",
    "            outs.append(self.h_o(self.h)) # Pass to the output layer\n",
    "        res = self.h\n",
    "        self.h = self.h.detach()\n",
    "        return torch.stack(outs, dim=1),res,outs\n",
    "    \n",
    "    def reset(self):\n",
    "        self.h = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 649,
   "id": "eb95e9fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0.,  ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 649,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor(np.zeros((100000)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 650,
   "id": "80197d9d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28480"
      ]
     },
     "execution_count": 650,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dls_lm.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 651,
   "id": "ee1ee6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "MyLSTMModel = MyLLM11(len(dls_lm.vocab),64,64,4)\n",
    "# MyLSTMModel = MyLLM4(len(dls_lm.vocab),64)\n",
    "# MyLSTMModel = MyLLM10(len(dls_lm.vocab),64,4,0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 658,
   "id": "8309dac3",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [658]\u001b[0m, in \u001b[0;36m<cell line: 7>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# learn = LMLearner(\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#     dls_lm, MyLSTMModel, \u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m#     loss_func=CrossEntropyLossFlat(),\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m#     metrics=[accuracy, Perplexity()]\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# )\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m learn \u001b[38;5;241m=\u001b[39m \u001b[43mlanguage_model_learner\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdls_lm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mAWD_LSTM\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdrop_mult\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43maccuracy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mPerplexity\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto_fp16()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\fastai\\text\\learner.py:244\u001b[0m, in \u001b[0;36mlanguage_model_learner\u001b[1;34m(dls, arch, config, drop_mult, backwards, pretrained, pretrained_fnames, **kwargs)\u001b[0m\n\u001b[0;32m    242\u001b[0m     warn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThere are no pretrained weights for that architecture yet!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    243\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m learn\n\u001b[1;32m--> 244\u001b[0m model_path \u001b[38;5;241m=\u001b[39m \u001b[43muntar_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmeta\u001b[49m\u001b[43m[\u001b[49m\u001b[43murl\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    245\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m: fnames \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mlist\u001b[39m(model_path\u001b[38;5;241m.\u001b[39mglob(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m*.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mext\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m))[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m ext \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpth\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpkl\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n\u001b[0;32m    246\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m: \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe model in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is incomplete, download again\u001b[39m\u001b[38;5;124m'\u001b[39m); \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\fastai\\data\\external.py:136\u001b[0m, in \u001b[0;36muntar_data\u001b[1;34m(url, archive, data, c_key, force_download, base)\u001b[0m\n\u001b[0;32m    134\u001b[0m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDownload `url` using `FastDownload.get`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    135\u001b[0m d \u001b[38;5;241m=\u001b[39m FastDownload(fastai_cfg(), module\u001b[38;5;241m=\u001b[39mfastai\u001b[38;5;241m.\u001b[39mdata, archive\u001b[38;5;241m=\u001b[39marchive, data\u001b[38;5;241m=\u001b[39mdata, base\u001b[38;5;241m=\u001b[39mbase)\n\u001b[1;32m--> 136\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43md\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforce\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextract_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mc_key\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\fastdownload\\core.py:117\u001b[0m, in \u001b[0;36mFastDownload.get\u001b[1;34m(self, url, extract_key, force)\u001b[0m\n\u001b[0;32m    115\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_path(extract_key, urldest(url, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39march_path()))\n\u001b[0;32m    116\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data\u001b[38;5;241m.\u001b[39mexists(): \u001b[38;5;28;01mreturn\u001b[39;00m data\n\u001b[1;32m--> 117\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownload\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforce\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mextract(url, extract_key\u001b[38;5;241m=\u001b[39mextract_key, force\u001b[38;5;241m=\u001b[39mforce)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\fastdownload\\core.py:92\u001b[0m, in \u001b[0;36mFastDownload.download\u001b[1;34m(self, url, force)\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDownload `url` to archive path, unless exists and `self.check` fails and not `force`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39march_path()\u001b[38;5;241m.\u001b[39mmkdir(exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, parents\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m---> 92\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdownload_and_check\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murldest\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43march_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforce\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\fastdownload\\core.py:61\u001b[0m, in \u001b[0;36mdownload_and_check\u001b[1;34m(url, fpath, fmod, force)\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m check(fmod, url, fpath): \u001b[38;5;28;01mreturn\u001b[39;00m fpath\n\u001b[0;32m     60\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m: \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDownloading a new version of this dataset...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 61\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mdownload_url\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m check(fmod, url, fpath): \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDownloaded file is corrupt or not latest version\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\fastdownload\\core.py:19\u001b[0m, in \u001b[0;36mdownload_url\u001b[1;34m(url, dest, timeout, show_progress)\u001b[0m\n\u001b[0;32m     17\u001b[0m     pbar\u001b[38;5;241m.\u001b[39mtotal \u001b[38;5;241m=\u001b[39m tsize\n\u001b[0;32m     18\u001b[0m     pbar\u001b[38;5;241m.\u001b[39mupdate(count\u001b[38;5;241m*\u001b[39mbsize)\n\u001b[1;32m---> 19\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43murlsave\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreporthook\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mshow_progress\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\fastcore\\net.py:184\u001b[0m, in \u001b[0;36murlsave\u001b[1;34m(url, dest, reporthook, headers, timeout)\u001b[0m\n\u001b[0;32m    182\u001b[0m dest \u001b[38;5;241m=\u001b[39m urldest(url, dest)\n\u001b[0;32m    183\u001b[0m dest\u001b[38;5;241m.\u001b[39mparent\u001b[38;5;241m.\u001b[39mmkdir(parents\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m--> 184\u001b[0m nm,msg \u001b[38;5;241m=\u001b[39m \u001b[43murlretrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreporthook\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m nm\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\fastcore\\net.py:149\u001b[0m, in \u001b[0;36murlretrieve\u001b[1;34m(url, filename, reporthook, data, headers, timeout)\u001b[0m\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21murlretrieve\u001b[39m(url, filename\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, reporthook\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, headers\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    148\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSame as `urllib.request.urlretrieve` but also works with `Request` objects\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 149\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m contextlib\u001b[38;5;241m.\u001b[39mclosing(\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m) \u001b[38;5;28;01mas\u001b[39;00m fp:\n\u001b[0;32m    150\u001b[0m         headers \u001b[38;5;241m=\u001b[39m fp\u001b[38;5;241m.\u001b[39minfo()\n\u001b[0;32m    151\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m filename: tfp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(filename, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\fastcore\\net.py:108\u001b[0m, in \u001b[0;36murlopen\u001b[1;34m(url, data, headers, timeout, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, (\u001b[38;5;28mstr\u001b[39m,\u001b[38;5;28mbytes\u001b[39m)): data \u001b[38;5;241m=\u001b[39m urlencode(data)\n\u001b[0;32m    107\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mbytes\u001b[39m): data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mencode(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mascii\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m--> 108\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m: \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43murlopener\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43murlwrap\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    109\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m HTTPError \u001b[38;5;28;01mas\u001b[39;00m e: \n\u001b[0;32m    110\u001b[0m     e\u001b[38;5;241m.\u001b[39mmsg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m====Error Body====\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;241m.\u001b[39mread()\u001b[38;5;241m.\u001b[39mdecode(errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\urllib\\request.py:517\u001b[0m, in \u001b[0;36mOpenerDirector.open\u001b[1;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[0;32m    514\u001b[0m     req \u001b[38;5;241m=\u001b[39m meth(req)\n\u001b[0;32m    516\u001b[0m sys\u001b[38;5;241m.\u001b[39maudit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124murllib.Request\u001b[39m\u001b[38;5;124m'\u001b[39m, req\u001b[38;5;241m.\u001b[39mfull_url, req\u001b[38;5;241m.\u001b[39mdata, req\u001b[38;5;241m.\u001b[39mheaders, req\u001b[38;5;241m.\u001b[39mget_method())\n\u001b[1;32m--> 517\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    519\u001b[0m \u001b[38;5;66;03m# post-process response\u001b[39;00m\n\u001b[0;32m    520\u001b[0m meth_name \u001b[38;5;241m=\u001b[39m protocol\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_response\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\urllib\\request.py:534\u001b[0m, in \u001b[0;36mOpenerDirector._open\u001b[1;34m(self, req, data)\u001b[0m\n\u001b[0;32m    531\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[0;32m    533\u001b[0m protocol \u001b[38;5;241m=\u001b[39m req\u001b[38;5;241m.\u001b[39mtype\n\u001b[1;32m--> 534\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_chain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_open\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\n\u001b[0;32m    535\u001b[0m \u001b[43m                          \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m_open\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    536\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result:\n\u001b[0;32m    537\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\urllib\\request.py:494\u001b[0m, in \u001b[0;36mOpenerDirector._call_chain\u001b[1;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[0;32m    492\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m handler \u001b[38;5;129;01min\u001b[39;00m handlers:\n\u001b[0;32m    493\u001b[0m     func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(handler, meth_name)\n\u001b[1;32m--> 494\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    495\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    496\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\urllib\\request.py:1389\u001b[0m, in \u001b[0;36mHTTPSHandler.https_open\u001b[1;34m(self, req)\u001b[0m\n\u001b[0;32m   1388\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhttps_open\u001b[39m(\u001b[38;5;28mself\u001b[39m, req):\n\u001b[1;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhttp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mHTTPSConnection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1390\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_context\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_hostname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_hostname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\urllib\\request.py:1346\u001b[0m, in \u001b[0;36mAbstractHTTPHandler.do_open\u001b[1;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[0;32m   1344\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1345\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1346\u001b[0m         \u001b[43mh\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselector\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1347\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhas_header\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTransfer-encoding\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1348\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err: \u001b[38;5;66;03m# timeout error\u001b[39;00m\n\u001b[0;32m   1349\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m URLError(err)\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\http\\client.py:1285\u001b[0m, in \u001b[0;36mHTTPConnection.request\u001b[1;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[0;32m   1282\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\u001b[38;5;28mself\u001b[39m, method, url, body\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, headers\u001b[38;5;241m=\u001b[39m{}, \u001b[38;5;241m*\u001b[39m,\n\u001b[0;32m   1283\u001b[0m             encode_chunked\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m   1284\u001b[0m     \u001b[38;5;124;03m\"\"\"Send a complete request to the server.\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1285\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\http\\client.py:1331\u001b[0m, in \u001b[0;36mHTTPConnection._send_request\u001b[1;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[0;32m   1327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(body, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m   1328\u001b[0m     \u001b[38;5;66;03m# RFC 2616 Section 3.7.1 says that text default has a\u001b[39;00m\n\u001b[0;32m   1329\u001b[0m     \u001b[38;5;66;03m# default charset of iso-8859-1.\u001b[39;00m\n\u001b[0;32m   1330\u001b[0m     body \u001b[38;5;241m=\u001b[39m _encode(body, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbody\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m-> 1331\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mendheaders\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencode_chunked\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\http\\client.py:1280\u001b[0m, in \u001b[0;36mHTTPConnection.endheaders\u001b[1;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[0;32m   1278\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1279\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CannotSendHeader()\n\u001b[1;32m-> 1280\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_output\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencode_chunked\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\http\\client.py:1040\u001b[0m, in \u001b[0;36mHTTPConnection._send_output\u001b[1;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[0;32m   1038\u001b[0m msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\r\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_buffer)\n\u001b[0;32m   1039\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_buffer[:]\n\u001b[1;32m-> 1040\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1042\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m message_body \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1043\u001b[0m \n\u001b[0;32m   1044\u001b[0m     \u001b[38;5;66;03m# create a consistent interface to message_body\u001b[39;00m\n\u001b[0;32m   1045\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(message_body, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mread\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m   1046\u001b[0m         \u001b[38;5;66;03m# Let file-like take precedence over byte-like.  This\u001b[39;00m\n\u001b[0;32m   1047\u001b[0m         \u001b[38;5;66;03m# is needed to allow the current position of mmap'ed\u001b[39;00m\n\u001b[0;32m   1048\u001b[0m         \u001b[38;5;66;03m# files to be taken into account.\u001b[39;00m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\http\\client.py:980\u001b[0m, in \u001b[0;36mHTTPConnection.send\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    978\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    979\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_open:\n\u001b[1;32m--> 980\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    981\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    982\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m NotConnected()\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\http\\client.py:1454\u001b[0m, in \u001b[0;36mHTTPSConnection.connect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1451\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1452\u001b[0m     server_hostname \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhost\n\u001b[1;32m-> 1454\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrap_socket\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msock\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1455\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mserver_hostname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\ssl.py:500\u001b[0m, in \u001b[0;36mSSLContext.wrap_socket\u001b[1;34m(self, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, session)\u001b[0m\n\u001b[0;32m    494\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrap_socket\u001b[39m(\u001b[38;5;28mself\u001b[39m, sock, server_side\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    495\u001b[0m                 do_handshake_on_connect\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    496\u001b[0m                 suppress_ragged_eofs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    497\u001b[0m                 server_hostname\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, session\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    498\u001b[0m     \u001b[38;5;66;03m# SSLSocket class handles server_hostname encoding before it calls\u001b[39;00m\n\u001b[0;32m    499\u001b[0m     \u001b[38;5;66;03m# ctx._wrap_socket()\u001b[39;00m\n\u001b[1;32m--> 500\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msslsocket_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43msock\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msock\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43mserver_side\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mserver_side\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdo_handshake_on_connect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdo_handshake_on_connect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43msuppress_ragged_eofs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msuppress_ragged_eofs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    505\u001b[0m \u001b[43m        \u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mserver_hostname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    506\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    507\u001b[0m \u001b[43m        \u001b[49m\u001b[43msession\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msession\u001b[49m\n\u001b[0;32m    508\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\ssl.py:1040\u001b[0m, in \u001b[0;36mSSLSocket._create\u001b[1;34m(cls, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, context, session)\u001b[0m\n\u001b[0;32m   1037\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0.0\u001b[39m:\n\u001b[0;32m   1038\u001b[0m             \u001b[38;5;66;03m# non-blocking\u001b[39;00m\n\u001b[0;32m   1039\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdo_handshake_on_connect should not be specified for non-blocking sockets\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1040\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_handshake\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1041\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mOSError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[0;32m   1042\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\ssl.py:1309\u001b[0m, in \u001b[0;36mSSLSocket.do_handshake\u001b[1;34m(self, block)\u001b[0m\n\u001b[0;32m   1307\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0.0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m block:\n\u001b[0;32m   1308\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msettimeout(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m-> 1309\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_handshake\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1310\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m   1311\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msettimeout(timeout)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# learn = LMLearner(\n",
    "#     dls_lm, MyLSTMModel, \n",
    "#     loss_func=CrossEntropyLossFlat(),\n",
    "#     metrics=[accuracy, Perplexity()]\n",
    "# )\n",
    "\n",
    "learn = language_model_learner(\n",
    "    dls_lm, AWD_LSTM, drop_mult=0.3, \n",
    "    metrics=[accuracy, Perplexity()]).to_fp16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f6fb14c",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(1, 2e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2cf1d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(1, 2e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "id": "9b357acd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>perplexity</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>4.760979</td>\n",
       "      <td>4.770746</td>\n",
       "      <td>0.267244</td>\n",
       "      <td>118.007217</td>\n",
       "      <td>26:32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(1, 2e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "id": "2dbbc49c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>perplexity</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>4.638702</td>\n",
       "      <td>4.681375</td>\n",
       "      <td>0.276487</td>\n",
       "      <td>107.918358</td>\n",
       "      <td>25:55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4.426968</td>\n",
       "      <td>4.558434</td>\n",
       "      <td>0.286272</td>\n",
       "      <td>95.433914</td>\n",
       "      <td>26:28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(2, 2e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df8c54e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f1661cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "id": "6f09c486",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "<class '__main__.MyLLM10'>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[1;32mIn [468]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m learn \u001b[38;5;241m=\u001b[39m \u001b[43mlanguage_model_learner\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdls_lm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mMyLLM10\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdrop_mult\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43maccuracy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mPerplexity\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto_fp16()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\fastai\\text\\learner.py:233\u001b[0m, in \u001b[0;36mlanguage_model_learner\u001b[1;34m(dls, arch, config, drop_mult, backwards, pretrained, pretrained_fnames, **kwargs)\u001b[0m\n\u001b[0;32m    231\u001b[0m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreate a `Learner` with a language model from `dls` and `arch`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    232\u001b[0m vocab \u001b[38;5;241m=\u001b[39m _get_text_vocab(dls)\n\u001b[1;32m--> 233\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mget_language_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43march\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mvocab\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdrop_mult\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdrop_mult\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    234\u001b[0m meta \u001b[38;5;241m=\u001b[39m _model_meta[arch]\n\u001b[0;32m    235\u001b[0m learn \u001b[38;5;241m=\u001b[39m LMLearner(dls, model, loss_func\u001b[38;5;241m=\u001b[39mCrossEntropyLossFlat(), splitter\u001b[38;5;241m=\u001b[39mmeta[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msplit_lm\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\fastai\\text\\models\\core.py:60\u001b[0m, in \u001b[0;36mget_language_model\u001b[1;34m(arch, vocab_sz, config, drop_mult)\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_language_model\u001b[39m(\n\u001b[0;32m     54\u001b[0m     arch, \u001b[38;5;66;03m# Function or class that can generate a language model architecture\u001b[39;00m\n\u001b[0;32m     55\u001b[0m     vocab_sz:\u001b[38;5;28mint\u001b[39m, \u001b[38;5;66;03m# Size of the vocabulary\u001b[39;00m\n\u001b[0;32m     56\u001b[0m     config:\u001b[38;5;28mdict\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;66;03m# Model configuration dictionary\u001b[39;00m\n\u001b[0;32m     57\u001b[0m     drop_mult:\u001b[38;5;28mfloat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.\u001b[39m \u001b[38;5;66;03m# Multiplicative factor to scale all dropout probabilities in `config`\u001b[39;00m\n\u001b[0;32m     58\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m SequentialRNN: \u001b[38;5;66;03m# Language model with `arch` encoder and linear decoder\u001b[39;00m\n\u001b[0;32m     59\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreate a language model from `arch` and its `config`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 60\u001b[0m     meta \u001b[38;5;241m=\u001b[39m \u001b[43m_model_meta\u001b[49m\u001b[43m[\u001b[49m\u001b[43march\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     61\u001b[0m     config \u001b[38;5;241m=\u001b[39m ifnone(config, meta[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconfig_lm\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m     62\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m config\u001b[38;5;241m.\u001b[39mkeys():\n",
      "\u001b[1;31mKeyError\u001b[0m: <class '__main__.MyLLM10'>"
     ]
    }
   ],
   "source": [
    "learn = language_model_learner(\n",
    "    dls_lm, MyLLM10, drop_mult=0.3, \n",
    "    metrics=[accuracy, Perplexity()]).to_fp16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ed1fb9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "b451de85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SERIKALI imesema haitakuwa tayari kuona amani na utulivu wa nchi inachezewa huku ikisisitiza uwepo w'"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = ' xbos '.join([l.strip() for l in txts[:200]])\n",
    "text[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "fa3c7775",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'sp_model': Path('tmp/spm.model')}"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Tokenize\n",
    "\n",
    "sp = SubwordTokenizer(vocab_sz=2000)\n",
    "# sp.setup(txts[:1])\n",
    "sp.setup(txts)\n",
    "\n",
    "# spacy = WordTokenizer()\n",
    "# tkn = Tokenizer(spacy)\n",
    "\n",
    "# tokens = tkn(text)\n",
    "# tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "1fc09e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = list(sp([text]))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "adaf3adb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#112814) [0,1,2,3,4,5,6,7,8,9...]"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## To Numericalize\n",
    "\n",
    "\n",
    "# num = Numericalize()\n",
    "# num.setup(tokens)\n",
    "\n",
    "# # Generate the vocab with unique tokens\n",
    "vocab = L(*tokens).unique()\n",
    "\n",
    "word2idx = {w:i for i, w in enumerate(vocab)}\n",
    "nums = L(word2idx[w] for w in tokens)\n",
    "nums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "45935efb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(112814, 1977)"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nums),len(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c4cecaa",
   "metadata": {},
   "source": [
    "## Build a language model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b38b52",
   "metadata": {},
   "source": [
    "### Predict each word based on the previous 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "99337a36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#37604) [(['SER', 'IKA', 'LI'], 'ime'),(['ime', 'sema', 'hai'], 'ta'),(['ta', 'kuwa', 'tayari'], 'kuona'),(['kuona', 'amani', 'na'], 'u'),(['u', 'tu', 'li'], 'vu'),(['vu', 'wa', 'nchi'], 'ina'),(['ina', 'che', 'ze'], 'wa'),(['wa', 'huku', 'iki'], 'sisitiza'),(['sisitiza', 'uwepo', 'wa'], 'umoja'),(['umoja', 'kati', 'ya'], 'wananchi')...]"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L((tokens[i:i+3],tokens[i+3]) for i in range(0,len(tokens)-4,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af04aaa4",
   "metadata": {},
   "source": [
    "The model can't use the above but the numericalized version of the above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "3689c7af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#37604) [(tensor([0, 1, 2]), 3),(tensor([3, 4, 5]), 6),(tensor([6, 7, 8]), 9),(tensor([ 9, 10, 11]), 12),(tensor([12, 13, 14]), 15),(tensor([15, 16, 17]), 18),(tensor([18, 19, 20]), 21),(tensor([21, 22, 23]), 24),(tensor([24, 25, 16]), 26),(tensor([26, 27, 28]), 29)...]"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seqs = L((tensor(nums[i:i+3]),nums[i+3]) for i in range(0,len(nums)-4,3))\n",
    "seqs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64a207cc",
   "metadata": {},
   "source": [
    "### Creating the DataLoader with a `batch_size` of 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "53fcfcbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 64\n",
    "cut = int(len(seqs) * 0.8)\n",
    "dls = DataLoaders.from_dsets(seqs[:cut],seqs[cut:],shuffle=False,bs=bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "539c5a03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([64, 3]), torch.Size([64]))"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x,y = dls.one_batch()\n",
    "x.shape,y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d187c50",
   "metadata": {},
   "source": [
    "## Our Language Model in PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "412a7658",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLLM1(Module):\n",
    "    def __init__(self, vocab_sz, n_hidden):\n",
    "        self.i_h = nn.Embedding(vocab_sz,n_hidden)\n",
    "        self.h_h = nn.Linear(n_hidden,n_hidden)\n",
    "        self.h_o = nn.Linear(n_hidden,vocab_sz)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        h = self.i_h(x[:,0]) # Access the Emb vector for the first column\n",
    "        h = self.h_h(h) # Connect to the first set of Linear NN\n",
    "        h = F.relu(h) # Our Non - liearization\n",
    "        \n",
    "        h = h + self.i_h(x[:,1]) # Add the Emb vector for the second column\n",
    "        h = self.h_h(h) # Pass to the Linear Network\n",
    "        h = F.relu(h) # Again the Non-linearization\n",
    "        \n",
    "        h = h + self.i_h(x[:,2]) # Add the Emb vector for the third column\n",
    "        h = self.h_h(h) # Pass to the Linear Network\n",
    "        h = F.relu(h) # Again the Non-linearization\n",
    "        \n",
    "        h = self.h_o(h) # Pass to the output layer\n",
    "        return h"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e8424fd",
   "metadata": {},
   "source": [
    "Rewriting it as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "82eb051d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLLM2(Module):\n",
    "    def __init__(self, vocab_sz, n_hidden):\n",
    "        self.i_h = nn.Embedding(vocab_sz,n_hidden)\n",
    "        self.h_h = nn.Linear(n_hidden,n_hidden)\n",
    "        self.h_o = nn.Linear(n_hidden,vocab_sz)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        h = 0\n",
    "        num_cols = x.shape[1]\n",
    "        for i in range(num_cols):\n",
    "            h = h + self.i_h(x[:,i]) # Access the Emb vector for the respective column\n",
    "            h = self.h_h(h) # Connect to a Linear NN\n",
    "            h = F.relu(h) # Our Non - liearization\n",
    "        h = self.h_o(h) # Pass to the output layer\n",
    "        return h"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25682cac",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "a6802725",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(35), ',', 0.03297433851881399)"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Baseline model of always predicting the mode of the tokens\n",
    "\n",
    "n,counts = 0,torch.zeros(len(vocab))\n",
    "for x,y in dls.valid:\n",
    "    n += y.shape[0]\n",
    "    for i in range_of(vocab): counts[i] += (y==i).long().sum()\n",
    "idx = torch.argmax(counts)\n",
    "idx, vocab[idx.item()], counts[idx].item()/n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "9c6fac10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>5.797340</td>\n",
       "      <td>5.822598</td>\n",
       "      <td>0.092142</td>\n",
       "      <td>00:57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4.115510</td>\n",
       "      <td>5.921351</td>\n",
       "      <td>0.111022</td>\n",
       "      <td>00:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.717089</td>\n",
       "      <td>6.425860</td>\n",
       "      <td>0.127643</td>\n",
       "      <td>00:56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.376848</td>\n",
       "      <td>6.855087</td>\n",
       "      <td>0.131100</td>\n",
       "      <td>00:54</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn = Learner(dls, MyLLM2(len(vocab), 1024), loss_func=F.cross_entropy, \n",
    "                metrics=accuracy)\n",
    "learn.fit_one_cycle(4, 1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "158ba4da",
   "metadata": {},
   "source": [
    "Slightly better"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d927c38b",
   "metadata": {},
   "source": [
    "### Maintaining the state of the RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "7172e830",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLLM3(Module):\n",
    "    def __init__(self, vocab_sz, n_hidden):\n",
    "        self.i_h = nn.Embedding(vocab_sz,n_hidden)\n",
    "        self.h_h = nn.Linear(n_hidden,n_hidden)\n",
    "        self.h_o = nn.Linear(n_hidden,vocab_sz)\n",
    "        self.h = 0\n",
    "    \n",
    "    def forward(self,x):\n",
    "        num_cols = x.shape[1]\n",
    "        for i in range(num_cols):\n",
    "            self.h = self.h + self.i_h(x[:,i]) # Access the Emb vector for the respective column\n",
    "            self.h = self.h_h(self.h) # Connect to a Linear NN\n",
    "            self.h = F.relu(self.h) # Our Non - liearization\n",
    "        out = self.h_o(self.h) # Pass to the output layer\n",
    "        \n",
    "        self.h = self.h.detach()\n",
    "        return out\n",
    "    \n",
    "    def reset(self):\n",
    "        self.h = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "ff073828",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(587, 64, 37604)"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = len(seqs)//bs\n",
    "m,bs,len(seqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "179d530a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_chunks(ds, bs):\n",
    "    m = len(ds) // bs\n",
    "    new_ds = L()\n",
    "    for i in range(m): new_ds += L(ds[i + m*j] for j in range(bs))\n",
    "    return new_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "62385db7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(tensor([0, 1, 2]), 3),\n",
       " (tensor([ 9, 10, 11]), 12),\n",
       " (tensor([18, 19, 20]), 21),\n",
       " (tensor([26, 27, 28]), 29),\n",
       " (tensor([28, 34, 35]), 36),\n",
       " (tensor([42, 43, 44]), 45),\n",
       " (tensor([3, 4, 5]), 6),\n",
       " (tensor([12, 13, 14]), 15),\n",
       " (tensor([21, 22, 23]), 24),\n",
       " (tensor([29, 30, 31]), 32),\n",
       " (tensor([36, 37, 38]), 39),\n",
       " (tensor([45, 46, 47]), 48),\n",
       " (tensor([6, 7, 8]), 9),\n",
       " (tensor([15, 16, 17]), 18),\n",
       " (tensor([24, 25, 16]), 26),\n",
       " (tensor([32, 14, 33]), 28),\n",
       " (tensor([39, 40, 41]), 42),\n",
       " (tensor([48, 21, 11]), 49)]"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(group_chunks(seqs[:20],6))#.reshape(4,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "6875050f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cut = int(len(seqs) * 0.8)\n",
    "dls = DataLoaders.from_dsets(\n",
    "    group_chunks(seqs[:cut], bs), \n",
    "    group_chunks(seqs[cut:], bs), \n",
    "    bs=bs, drop_last=True, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "168bd7dc",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4be830b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>5.910364</td>\n",
       "      <td>6.097558</td>\n",
       "      <td>0.172414</td>\n",
       "      <td>02:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4.002608</td>\n",
       "      <td>6.482233</td>\n",
       "      <td>0.191092</td>\n",
       "      <td>02:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.467951</td>\n",
       "      <td>7.328877</td>\n",
       "      <td>0.176904</td>\n",
       "      <td>02:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.519905</td>\n",
       "      <td>8.706957</td>\n",
       "      <td>0.170797</td>\n",
       "      <td>02:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.959000</td>\n",
       "      <td>10.245851</td>\n",
       "      <td>0.169540</td>\n",
       "      <td>02:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.610137</td>\n",
       "      <td>10.246753</td>\n",
       "      <td>0.168103</td>\n",
       "      <td>02:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.438787</td>\n",
       "      <td>10.063964</td>\n",
       "      <td>0.180316</td>\n",
       "      <td>02:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.312056</td>\n",
       "      <td>10.027181</td>\n",
       "      <td>0.188398</td>\n",
       "      <td>02:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.263799</td>\n",
       "      <td>9.995111</td>\n",
       "      <td>0.191092</td>\n",
       "      <td>02:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.336758</td>\n",
       "      <td>9.742608</td>\n",
       "      <td>0.195582</td>\n",
       "      <td>02:07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn = Learner(dls, MyLLM3(len(vocab), 1024), loss_func=F.cross_entropy, \n",
    "                metrics=accuracy,cbs=ModelResetter)\n",
    "learn.fit_one_cycle(10, 1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4135da5",
   "metadata": {},
   "source": [
    "### Creating more signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "49a6ded1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sl = 16\n",
    "seqs = L((tensor(nums[i:i+sl]), tensor(nums[i+1:i+sl+1]))\n",
    "         for i in range(0,len(nums)-sl-1,sl))\n",
    "cut = int(len(seqs) * 0.8)\n",
    "dls = DataLoaders.from_dsets(group_chunks(seqs[:cut], bs),\n",
    "                             group_chunks(seqs[cut:], bs),\n",
    "                             bs=bs, drop_last=True, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adb0e0df",
   "metadata": {},
   "source": [
    "Looking at the first element of `seqs`, we can see that it contains two lists of the same size. The second list is the same as the first, but offset by one element:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "44a75f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLLM4(Module):\n",
    "    def __init__(self, vocab_sz, n_hidden):\n",
    "        self.i_h = nn.Embedding(vocab_sz,n_hidden)\n",
    "        self.h_h = nn.Linear(n_hidden,n_hidden)\n",
    "        self.h_o = nn.Linear(n_hidden,vocab_sz)\n",
    "        self.h = 0\n",
    "    \n",
    "    def forward(self,x):\n",
    "        num_cols = x.shape[1]\n",
    "        outs = []\n",
    "        for i in range(num_cols):\n",
    "            self.h = self.h + self.i_h(x[:,i]) # Access the Emb vector for the respective column\n",
    "            self.h = self.h_h(self.h) # Connect to a Linear NN\n",
    "            self.h = F.relu(self.h) # Our Non - liearization\n",
    "            outs.append(self.h_o(self.h)) # Pass to the output layer\n",
    "        \n",
    "        self.h = self.h.detach()\n",
    "        return torch.stack(outs, dim=1)\n",
    "    \n",
    "    def reset(self):\n",
    "        self.h = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "3744a899",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_func(inp, targ):\n",
    "    return F.cross_entropy(inp.view(-1, len(vocab)), targ.view(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "05886877",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>6.220513</td>\n",
       "      <td>5.796507</td>\n",
       "      <td>0.094638</td>\n",
       "      <td>00:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>5.071121</td>\n",
       "      <td>5.185163</td>\n",
       "      <td>0.136586</td>\n",
       "      <td>00:46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>4.194140</td>\n",
       "      <td>5.053366</td>\n",
       "      <td>0.156294</td>\n",
       "      <td>00:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3.569609</td>\n",
       "      <td>5.116390</td>\n",
       "      <td>0.164728</td>\n",
       "      <td>00:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>3.181340</td>\n",
       "      <td>5.093949</td>\n",
       "      <td>0.169389</td>\n",
       "      <td>00:43</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn = Learner(dls, MyLLM4(len(vocab), 1024), loss_func=loss_func, \n",
    "                metrics=accuracy,cbs=ModelResetter)\n",
    "learn.fit_one_cycle(5, 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "d057e25b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_pred(length):\n",
    "    to_pred = nums[95:95+length]\n",
    "    ans = nums[95+1:95+length+1]\n",
    "    \n",
    "    result = learn.predict(tensor([to_pred]))[0].argmax(1)\n",
    "    print(result,ans)\n",
    "\n",
    "    prompt = \"\"\n",
    "    for i in range(len(to_pred)):\n",
    "        prompt += vocab[to_pred[i]] +' '\n",
    "#     print(prompt)\n",
    "    prompt += \" <>  \"\n",
    "\n",
    "    for i in range(len(result)):\n",
    "        prompt += vocab[result[i]] + ' '\n",
    "#     return prompt\n",
    "    print(prompt)\n",
    "    \n",
    "    prompt = ' '.join(prompt.split(' ')[:len(ans)])\n",
    "    prompt += \"  <>  \"\n",
    "\n",
    "    for i in range(len(ans)):\n",
    "        prompt += vocab[ans[i]] + ' '\n",
    "    print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "91db797b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 15, 194, 340,  85,  86,  38,  87, 113,  61, 222]) [82, 83, 84, 85, 86, 38, 87, 35, 88, 79]\n",
      "wa taasisi za Ki i s la mu , lengo  <>  vu hiyo umma i s la mu nchini  la \n",
      "wa taasisi za Ki i s la mu , lengo  <>  taasisi za Ki i s la mu , lengo ikiwa \n"
     ]
    }
   ],
   "source": [
    "sample_pred(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "893b92d4",
   "metadata": {},
   "source": [
    "I am actually very surprised. Like I am wowed already.\n",
    "\n",
    "The original text is \" of the Government of the Fifth Phase is to promote \"<br>\n",
    "The predicted text is \" of Tanzania's Fifth Phase under promotion \"\n",
    "\n",
    "<b>NB</b>: \n",
    "<li> Translation done via Google Translate </li>\n",
    "<li> This prediction was done on the training set (But it is still remarkable I believe) </li>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a07889fe",
   "metadata": {},
   "source": [
    "### Multi-Layer RNNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "355d3ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLLM5(Module):\n",
    "    def __init__(self, vocab_sz, n_hidden,n_layers):\n",
    "        self.i_h = nn.Embedding(vocab_sz,n_hidden)\n",
    "        \n",
    "        self.network = []\n",
    "        for i in range(n_layers):\n",
    "            self.network.append(nn.Linear(n_hidden,n_hidden))\n",
    "            self.network.append(nn.ReLU())\n",
    "        self.h_h = nn.Sequential(\n",
    "            *self.network[:-1]\n",
    "        )\n",
    "#         self.h_h = nn.Linear(n_hidden,n_hidden)\n",
    "        self.h_o = nn.Linear(n_hidden,vocab_sz)\n",
    "        self.h = 0\n",
    "    \n",
    "    def forward(self,x):\n",
    "        num_cols = x.shape[1]\n",
    "        outs = []\n",
    "        for i in range(num_cols):\n",
    "            self.h = self.h + self.i_h(x[:,i]) # Access the Emb vector for the respective column\n",
    "            self.h = self.h_h(self.h) # Connect to a Linear NN\n",
    "            self.h = F.relu(self.h) # Our Non - liearization\n",
    "            outs.append(self.h_o(self.h)) # Pass to the output layer\n",
    "        \n",
    "        self.h = self.h.detach()\n",
    "        return torch.stack(outs, dim=1)\n",
    "    \n",
    "    def reset(self):\n",
    "        self.h = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "434b3ece",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>7.832971</td>\n",
       "      <td>6.765987</td>\n",
       "      <td>0.044739</td>\n",
       "      <td>02:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>6.556630</td>\n",
       "      <td>6.272907</td>\n",
       "      <td>0.160278</td>\n",
       "      <td>02:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>5.952004</td>\n",
       "      <td>6.013952</td>\n",
       "      <td>0.190002</td>\n",
       "      <td>02:20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>5.511847</td>\n",
       "      <td>5.976256</td>\n",
       "      <td>0.211121</td>\n",
       "      <td>02:21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5.108160</td>\n",
       "      <td>6.024221</td>\n",
       "      <td>0.216064</td>\n",
       "      <td>02:21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>4.775147</td>\n",
       "      <td>6.203149</td>\n",
       "      <td>0.220398</td>\n",
       "      <td>02:20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>4.493296</td>\n",
       "      <td>6.327516</td>\n",
       "      <td>0.227173</td>\n",
       "      <td>02:21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>4.273300</td>\n",
       "      <td>6.438957</td>\n",
       "      <td>0.224670</td>\n",
       "      <td>02:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>4.130563</td>\n",
       "      <td>6.620975</td>\n",
       "      <td>0.222656</td>\n",
       "      <td>02:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>4.093142</td>\n",
       "      <td>6.345071</td>\n",
       "      <td>0.230530</td>\n",
       "      <td>02:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>4.145858</td>\n",
       "      <td>6.137928</td>\n",
       "      <td>0.234009</td>\n",
       "      <td>02:21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>4.079705</td>\n",
       "      <td>6.195321</td>\n",
       "      <td>0.238586</td>\n",
       "      <td>02:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>3.885146</td>\n",
       "      <td>6.415190</td>\n",
       "      <td>0.237671</td>\n",
       "      <td>02:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>3.736405</td>\n",
       "      <td>6.487379</td>\n",
       "      <td>0.238770</td>\n",
       "      <td>02:21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>3.652735</td>\n",
       "      <td>6.458499</td>\n",
       "      <td>0.237427</td>\n",
       "      <td>02:21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn = Learner(dls, MyLLM5(len(vocab), 1024,4), loss_func=loss_func, \n",
    "                metrics=accuracy,cbs=ModelResetter)\n",
    "learn.fit_one_cycle(15, 1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "691343e2",
   "metadata": {},
   "source": [
    "In other words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "bbac4ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLLM6(Module):\n",
    "    def __init__(self, vocab_sz, n_hidden,n_layers):\n",
    "        self.i_h = nn.Embedding(vocab_sz,n_hidden)\n",
    "        self.rnn = nn.RNN(n_hidden,n_hidden, n_layers, batch_first=True)\n",
    "        self.h_o = nn.Linear(n_hidden,vocab_sz)\n",
    "        self.h = torch.zeros(n_layers, bs, n_hidden) # Some changes here\n",
    "    \n",
    "    def forward(self,x):\n",
    "        res,h = self.rnn(self.i_h(x), self.h)\n",
    "        self.h = h.detach()\n",
    "        return self.h_o(res)\n",
    "    \n",
    "    def reset(self):\n",
    "        self.h.zero_ # Some changes here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "63396b97",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>9.124417</td>\n",
       "      <td>9.022078</td>\n",
       "      <td>0.122498</td>\n",
       "      <td>00:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>8.783082</td>\n",
       "      <td>8.455340</td>\n",
       "      <td>0.122498</td>\n",
       "      <td>00:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>8.109900</td>\n",
       "      <td>7.619846</td>\n",
       "      <td>0.122498</td>\n",
       "      <td>00:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>7.321177</td>\n",
       "      <td>6.941107</td>\n",
       "      <td>0.122498</td>\n",
       "      <td>00:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>6.744375</td>\n",
       "      <td>6.657060</td>\n",
       "      <td>0.122498</td>\n",
       "      <td>00:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>6.491624</td>\n",
       "      <td>6.652512</td>\n",
       "      <td>0.122498</td>\n",
       "      <td>00:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>6.415926</td>\n",
       "      <td>6.688025</td>\n",
       "      <td>0.122498</td>\n",
       "      <td>00:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>6.396910</td>\n",
       "      <td>6.725154</td>\n",
       "      <td>0.122498</td>\n",
       "      <td>00:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>6.393860</td>\n",
       "      <td>6.759254</td>\n",
       "      <td>0.122498</td>\n",
       "      <td>00:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>6.394257</td>\n",
       "      <td>6.788418</td>\n",
       "      <td>0.122498</td>\n",
       "      <td>00:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>6.394333</td>\n",
       "      <td>6.812048</td>\n",
       "      <td>0.122498</td>\n",
       "      <td>00:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>6.393624</td>\n",
       "      <td>6.824253</td>\n",
       "      <td>0.122498</td>\n",
       "      <td>00:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>6.392339</td>\n",
       "      <td>6.832657</td>\n",
       "      <td>0.122498</td>\n",
       "      <td>00:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>6.390764</td>\n",
       "      <td>6.841636</td>\n",
       "      <td>0.122498</td>\n",
       "      <td>00:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>6.346683</td>\n",
       "      <td>6.721310</td>\n",
       "      <td>0.122498</td>\n",
       "      <td>00:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>6.266083</td>\n",
       "      <td>6.618015</td>\n",
       "      <td>0.123596</td>\n",
       "      <td>00:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>6.158525</td>\n",
       "      <td>6.514336</td>\n",
       "      <td>0.123596</td>\n",
       "      <td>00:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>6.036198</td>\n",
       "      <td>6.416707</td>\n",
       "      <td>0.138245</td>\n",
       "      <td>00:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>5.929802</td>\n",
       "      <td>6.360248</td>\n",
       "      <td>0.141418</td>\n",
       "      <td>00:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>5.851442</td>\n",
       "      <td>6.331236</td>\n",
       "      <td>0.144470</td>\n",
       "      <td>00:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>5.791691</td>\n",
       "      <td>6.306434</td>\n",
       "      <td>0.147888</td>\n",
       "      <td>00:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>5.741911</td>\n",
       "      <td>6.286253</td>\n",
       "      <td>0.150024</td>\n",
       "      <td>00:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>5.698960</td>\n",
       "      <td>6.284177</td>\n",
       "      <td>0.148682</td>\n",
       "      <td>00:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>5.660240</td>\n",
       "      <td>6.266245</td>\n",
       "      <td>0.149963</td>\n",
       "      <td>00:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>5.626951</td>\n",
       "      <td>6.255959</td>\n",
       "      <td>0.150513</td>\n",
       "      <td>00:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>5.598859</td>\n",
       "      <td>6.243095</td>\n",
       "      <td>0.152039</td>\n",
       "      <td>00:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>5.574529</td>\n",
       "      <td>6.236372</td>\n",
       "      <td>0.152039</td>\n",
       "      <td>00:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>5.551696</td>\n",
       "      <td>6.224903</td>\n",
       "      <td>0.152344</td>\n",
       "      <td>00:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>5.531609</td>\n",
       "      <td>6.216406</td>\n",
       "      <td>0.152527</td>\n",
       "      <td>00:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>5.512884</td>\n",
       "      <td>6.210415</td>\n",
       "      <td>0.154724</td>\n",
       "      <td>00:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>5.496809</td>\n",
       "      <td>6.212370</td>\n",
       "      <td>0.152771</td>\n",
       "      <td>00:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>5.482694</td>\n",
       "      <td>6.207172</td>\n",
       "      <td>0.152588</td>\n",
       "      <td>00:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>5.472106</td>\n",
       "      <td>6.207968</td>\n",
       "      <td>0.151978</td>\n",
       "      <td>00:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>5.463983</td>\n",
       "      <td>6.210777</td>\n",
       "      <td>0.154114</td>\n",
       "      <td>00:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>5.456168</td>\n",
       "      <td>6.208627</td>\n",
       "      <td>0.155823</td>\n",
       "      <td>00:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>5.450153</td>\n",
       "      <td>6.207768</td>\n",
       "      <td>0.155762</td>\n",
       "      <td>00:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>5.445815</td>\n",
       "      <td>6.205801</td>\n",
       "      <td>0.155945</td>\n",
       "      <td>00:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>5.443156</td>\n",
       "      <td>6.202513</td>\n",
       "      <td>0.155579</td>\n",
       "      <td>00:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>5.441360</td>\n",
       "      <td>6.204483</td>\n",
       "      <td>0.155579</td>\n",
       "      <td>00:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>5.440326</td>\n",
       "      <td>6.204522</td>\n",
       "      <td>0.155762</td>\n",
       "      <td>00:18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn = Learner(dls, MyLLM6(len(vocab), 64,8), loss_func=loss_func, \n",
    "                metrics=accuracy,cbs=ModelResetter)\n",
    "learn.fit_one_cycle(40, 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "91a39bad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>7.200701</td>\n",
       "      <td>6.618497</td>\n",
       "      <td>0.123840</td>\n",
       "      <td>01:48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>6.362325</td>\n",
       "      <td>6.229457</td>\n",
       "      <td>0.166504</td>\n",
       "      <td>01:48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>5.823647</td>\n",
       "      <td>6.021464</td>\n",
       "      <td>0.202515</td>\n",
       "      <td>01:50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>5.363237</td>\n",
       "      <td>6.079515</td>\n",
       "      <td>0.210083</td>\n",
       "      <td>01:49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4.953303</td>\n",
       "      <td>6.177130</td>\n",
       "      <td>0.211670</td>\n",
       "      <td>01:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>4.613482</td>\n",
       "      <td>6.241570</td>\n",
       "      <td>0.214600</td>\n",
       "      <td>01:55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>4.299594</td>\n",
       "      <td>6.321890</td>\n",
       "      <td>0.216125</td>\n",
       "      <td>01:53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>4.032951</td>\n",
       "      <td>6.331525</td>\n",
       "      <td>0.215576</td>\n",
       "      <td>01:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>3.806790</td>\n",
       "      <td>6.365344</td>\n",
       "      <td>0.218506</td>\n",
       "      <td>01:51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>3.682621</td>\n",
       "      <td>6.379865</td>\n",
       "      <td>0.219299</td>\n",
       "      <td>01:46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>3.484605</td>\n",
       "      <td>6.340055</td>\n",
       "      <td>0.224670</td>\n",
       "      <td>01:52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>3.203477</td>\n",
       "      <td>6.352996</td>\n",
       "      <td>0.225525</td>\n",
       "      <td>01:49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>2.980508</td>\n",
       "      <td>6.361646</td>\n",
       "      <td>0.226685</td>\n",
       "      <td>01:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>2.787237</td>\n",
       "      <td>6.359298</td>\n",
       "      <td>0.230164</td>\n",
       "      <td>01:53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>2.650961</td>\n",
       "      <td>6.354051</td>\n",
       "      <td>0.229187</td>\n",
       "      <td>01:49</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn = Learner(dls, MyLLM6(len(vocab), 1024,4), loss_func=CrossEntropyLossFlat(), # Change in the loss function\n",
    "                metrics=accuracy,cbs=ModelResetter)\n",
    "learn.fit_one_cycle(15, 1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "111449f7",
   "metadata": {},
   "source": [
    "Due to the problems of exploding or diasappearing activations, We will consider the use of LSTMs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "735fd230",
   "metadata": {},
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "8c5561ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLLM7(Module):\n",
    "    def __init__(self, ni, h):\n",
    "        self.forget_gate = nn.Linear(ni + nh, nh)\n",
    "        self.input_gate = nn.Linear(ni + nh, nh)\n",
    "        self.cell_gate = nn.Linear(ni + nh, nh)\n",
    "        self.output_gate = nn.Linear(ni + nh, nh)\n",
    "    \n",
    "    def forward(self, x, state):\n",
    "        h,c = state\n",
    "        h = torch.cat([h, x], dim=1)\n",
    "        forget = torch.sigmoid(self.forget_gate(h))\n",
    "        c = c * forget\n",
    "        \n",
    "        inputer = torchinput_gateigmoid(self.input_gate(h)) * torch.tanh(self.cell_gate(h))\n",
    "        c = c + inputer\n",
    "        \n",
    "        outputer = torch.sigmoid(self.output_gate(h))\n",
    "        h = torch.tanh(c) * outputer\n",
    "        return h, (h,c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2179e945",
   "metadata": {},
   "source": [
    "Refactoring the above for increase in GPU performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "2bc2a0e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLLM8(Module):\n",
    "    def __init__(self, ni, h):\n",
    "        self.ih = nn.Linear(ni,4*nh)\n",
    "        self.hh = nn.Linear(nh,4*nh)\n",
    "    \n",
    "    def forward(self, x, state):\n",
    "        h,c = state\n",
    "        \n",
    "        gates = (self.ih(x) + self.hh(h)).chunk(4,1)\n",
    "        ingate, forgetgate, outgate = map(torch.sigmoid, gates[:3]) ## Note: order does not matter here\n",
    "        cellgate = torch.tanh(gates[3])\n",
    "\n",
    "        c = forgetgate*c + ingate*cellgate\n",
    "        h = outgate * torch.tanh(c)\n",
    "        return h, (h,c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7acce68d",
   "metadata": {},
   "source": [
    "Now the LTSM network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "f6bcf373",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLLM9(Module):\n",
    "    def __init__(self, vocab_sz, n_hidden,n_layers):\n",
    "        self.i_h = nn.Embedding(vocab_sz,n_hidden)\n",
    "        self.rnn = nn.LSTM(n_hidden,n_hidden, n_layers, batch_first=True)\n",
    "        self.h_o = nn.Linear(n_hidden,vocab_sz)\n",
    "        self.h = [torch.zeros(n_layers, bs, n_hidden) for _ in range(2)] # Some changes here\n",
    "    \n",
    "    def forward(self,x):\n",
    "        res,h = self.rnn(self.i_h(x), self.h)\n",
    "        self.h = [h_.detach() for h_ in h]\n",
    "        return self.h_o(res)\n",
    "    \n",
    "    def reset(self):\n",
    "        for h in self.h:\n",
    "            h.zero_ # Some changes here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cb38015a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>7.978433</td>\n",
       "      <td>6.681934</td>\n",
       "      <td>0.122498</td>\n",
       "      <td>03:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>6.850881</td>\n",
       "      <td>6.777476</td>\n",
       "      <td>0.122498</td>\n",
       "      <td>03:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>6.598370</td>\n",
       "      <td>6.803113</td>\n",
       "      <td>0.122498</td>\n",
       "      <td>03:51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>6.429319</td>\n",
       "      <td>6.598124</td>\n",
       "      <td>0.122498</td>\n",
       "      <td>03:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>6.079883</td>\n",
       "      <td>6.307435</td>\n",
       "      <td>0.150940</td>\n",
       "      <td>03:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>5.721493</td>\n",
       "      <td>6.203966</td>\n",
       "      <td>0.170410</td>\n",
       "      <td>03:51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>5.413800</td>\n",
       "      <td>6.209413</td>\n",
       "      <td>0.174133</td>\n",
       "      <td>04:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>5.146466</td>\n",
       "      <td>6.146118</td>\n",
       "      <td>0.186951</td>\n",
       "      <td>03:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>4.899539</td>\n",
       "      <td>6.264096</td>\n",
       "      <td>0.185486</td>\n",
       "      <td>03:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>4.717854</td>\n",
       "      <td>6.252806</td>\n",
       "      <td>0.184509</td>\n",
       "      <td>03:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>4.580995</td>\n",
       "      <td>6.264646</td>\n",
       "      <td>0.191895</td>\n",
       "      <td>03:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>4.431023</td>\n",
       "      <td>6.332827</td>\n",
       "      <td>0.187561</td>\n",
       "      <td>03:32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>4.287086</td>\n",
       "      <td>6.405629</td>\n",
       "      <td>0.189270</td>\n",
       "      <td>03:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>4.169223</td>\n",
       "      <td>6.431261</td>\n",
       "      <td>0.186279</td>\n",
       "      <td>03:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>4.104361</td>\n",
       "      <td>6.438369</td>\n",
       "      <td>0.186707</td>\n",
       "      <td>03:37</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn = Learner(dls, MyLLM9(len(vocab), 1024, 4), \n",
    "                loss_func=CrossEntropyLossFlat(), \n",
    "                metrics=accuracy, cbs=ModelResetter)\n",
    "learn.fit_one_cycle(15, 1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc5eae42",
   "metadata": {},
   "source": [
    "### Regularizing\n",
    "We will add the following methods as seen in the paper taught by Jeremy;\n",
    "<li> Dropout </li>\n",
    "<li> Activation Regularization (AR) and Temporal Activation Regularization (TAR) </li>\n",
    "<li> Weight Tying </li>\n",
    "\n",
    "The LSTM that uses these techniques are called AWD-LSTM according to the author."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "dfb1a4e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLLM10(Module):\n",
    "    def __init__(self, vocab_sz, n_hidden,n_layers,p):\n",
    "        self.i_h = nn.Embedding(vocab_sz,n_hidden)\n",
    "        self.rnn = nn.LSTM(n_hidden,n_hidden, n_layers, batch_first=True)\n",
    "        self.drop = nn.Dropout(p) # Dropout\n",
    "        self.h_o = nn.Linear(n_hidden,vocab_sz)\n",
    "        self.h_o.weight = self.i_h.weight # Weight Tying\n",
    "        self.h = [torch.zeros(n_layers, bs, n_hidden) for _ in range(2)] # Some changes here\n",
    "    \n",
    "    def forward(self,x):\n",
    "        res,h = self.rnn(self.i_h(x), self.h)\n",
    "        out = self.drop(res)\n",
    "        self.h = [h_.detach() for h_ in h]\n",
    "        return self.h_o(out),res,out\n",
    "    \n",
    "    def reset(self):\n",
    "        for h in self.h:\n",
    "            h.zero_ # Some changes here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "361073c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>6.744831</td>\n",
       "      <td>6.390353</td>\n",
       "      <td>0.052823</td>\n",
       "      <td>04:09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "learn = Learner(dls, MyLLM10(len(vocab), 1024, 4, 0.5), \n",
    "                loss_func=CrossEntropyLossFlat(), \n",
    "                metrics=accuracy, \n",
    "                cbs=[ModelResetter,RNNRegularizer(alpha=2,beta=1)]\n",
    "               )\n",
    "\n",
    "# OR\n",
    "learn = TextLearner(dls, MyLLM10(len(vocab), 1024, 4, 0.4),\n",
    "                   loss_func = CrossEntropyLossFlat(), metrics=accuracy)\n",
    "\n",
    "learn.fit_one_cycle(5, 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b90372",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "52d252e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>7.567925</td>\n",
       "      <td>7.175681</td>\n",
       "      <td>0.122925</td>\n",
       "      <td>03:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>7.111494</td>\n",
       "      <td>6.670097</td>\n",
       "      <td>0.150391</td>\n",
       "      <td>03:20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>6.544221</td>\n",
       "      <td>6.191212</td>\n",
       "      <td>0.207458</td>\n",
       "      <td>03:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>5.991594</td>\n",
       "      <td>6.060913</td>\n",
       "      <td>0.219971</td>\n",
       "      <td>03:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5.410181</td>\n",
       "      <td>6.122361</td>\n",
       "      <td>0.226318</td>\n",
       "      <td>03:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>4.774519</td>\n",
       "      <td>6.354394</td>\n",
       "      <td>0.225830</td>\n",
       "      <td>03:17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [42]\u001b[0m, in \u001b[0;36m<cell line: 11>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# OR\u001b[39;00m\n\u001b[0;32m      8\u001b[0m learn \u001b[38;5;241m=\u001b[39m TextLearner(dls, MyLLM10(\u001b[38;5;28mlen\u001b[39m(vocab), \u001b[38;5;241m1024\u001b[39m, \u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m0.4\u001b[39m),\n\u001b[0;32m      9\u001b[0m                    loss_func \u001b[38;5;241m=\u001b[39m CrossEntropyLossFlat(), metrics\u001b[38;5;241m=\u001b[39maccuracy)\n\u001b[1;32m---> 11\u001b[0m \u001b[43mlearn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_one_cycle\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m15\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1e-3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\fastai\\callback\\schedule.py:119\u001b[0m, in \u001b[0;36mfit_one_cycle\u001b[1;34m(self, n_epoch, lr_max, div, div_final, pct_start, wd, moms, cbs, reset_opt, start_epoch)\u001b[0m\n\u001b[0;32m    116\u001b[0m lr_max \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([h[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m h \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mopt\u001b[38;5;241m.\u001b[39mhypers])\n\u001b[0;32m    117\u001b[0m scheds \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m'\u001b[39m: combined_cos(pct_start, lr_max\u001b[38;5;241m/\u001b[39mdiv, lr_max, lr_max\u001b[38;5;241m/\u001b[39mdiv_final),\n\u001b[0;32m    118\u001b[0m           \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmom\u001b[39m\u001b[38;5;124m'\u001b[39m: combined_cos(pct_start, \u001b[38;5;241m*\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmoms \u001b[38;5;28;01mif\u001b[39;00m moms \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m moms))}\n\u001b[1;32m--> 119\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_epoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcbs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mParamScheduler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mscheds\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43mL\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcbs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset_opt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset_opt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstart_epoch\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\fastai\\learner.py:264\u001b[0m, in \u001b[0;36mLearner.fit\u001b[1;34m(self, n_epoch, lr, wd, cbs, reset_opt, start_epoch)\u001b[0m\n\u001b[0;32m    262\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mopt\u001b[38;5;241m.\u001b[39mset_hypers(lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlr \u001b[38;5;28;01mif\u001b[39;00m lr \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m lr)\n\u001b[0;32m    263\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_epoch \u001b[38;5;241m=\u001b[39m n_epoch\n\u001b[1;32m--> 264\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_with_events\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_fit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfit\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCancelFitException\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_end_cleanup\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\fastai\\learner.py:199\u001b[0m, in \u001b[0;36mLearner._with_events\u001b[1;34m(self, f, event_type, ex, final)\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_with_events\u001b[39m(\u001b[38;5;28mself\u001b[39m, f, event_type, ex, final\u001b[38;5;241m=\u001b[39mnoop):\n\u001b[1;32m--> 199\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m: \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbefore_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m);  \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    200\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m ex: \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter_cancel_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    201\u001b[0m     \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m);  final()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\fastai\\learner.py:253\u001b[0m, in \u001b[0;36mLearner._do_fit\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    251\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_epoch):\n\u001b[0;32m    252\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepoch\u001b[38;5;241m=\u001b[39mepoch\n\u001b[1;32m--> 253\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_with_events\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_epoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mepoch\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCancelEpochException\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\fastai\\learner.py:199\u001b[0m, in \u001b[0;36mLearner._with_events\u001b[1;34m(self, f, event_type, ex, final)\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_with_events\u001b[39m(\u001b[38;5;28mself\u001b[39m, f, event_type, ex, final\u001b[38;5;241m=\u001b[39mnoop):\n\u001b[1;32m--> 199\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m: \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbefore_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m);  \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    200\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m ex: \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter_cancel_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    201\u001b[0m     \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m);  final()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\fastai\\learner.py:247\u001b[0m, in \u001b[0;36mLearner._do_epoch\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    246\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_do_epoch\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 247\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_epoch_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    248\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_do_epoch_validate()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\fastai\\learner.py:239\u001b[0m, in \u001b[0;36mLearner._do_epoch_train\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    237\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_do_epoch_train\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    238\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdl \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdls\u001b[38;5;241m.\u001b[39mtrain\n\u001b[1;32m--> 239\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_with_events\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mall_batches\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCancelTrainException\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\fastai\\learner.py:199\u001b[0m, in \u001b[0;36mLearner._with_events\u001b[1;34m(self, f, event_type, ex, final)\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_with_events\u001b[39m(\u001b[38;5;28mself\u001b[39m, f, event_type, ex, final\u001b[38;5;241m=\u001b[39mnoop):\n\u001b[1;32m--> 199\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m: \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbefore_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m);  \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    200\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m ex: \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter_cancel_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    201\u001b[0m     \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m);  final()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\fastai\\learner.py:205\u001b[0m, in \u001b[0;36mLearner.all_batches\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    203\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mall_batches\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    204\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdl)\n\u001b[1;32m--> 205\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m o \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdl): \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mone_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mo\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\fastai\\learner.py:235\u001b[0m, in \u001b[0;36mLearner.one_batch\u001b[1;34m(self, i, b)\u001b[0m\n\u001b[0;32m    233\u001b[0m b \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_device(b)\n\u001b[0;32m    234\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_split(b)\n\u001b[1;32m--> 235\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_with_events\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_one_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbatch\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCancelBatchException\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\fastai\\learner.py:199\u001b[0m, in \u001b[0;36mLearner._with_events\u001b[1;34m(self, f, event_type, ex, final)\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_with_events\u001b[39m(\u001b[38;5;28mself\u001b[39m, f, event_type, ex, final\u001b[38;5;241m=\u001b[39mnoop):\n\u001b[1;32m--> 199\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m: \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbefore_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m);  \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    200\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m ex: \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter_cancel_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    201\u001b[0m     \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m);  final()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\fastai\\learner.py:216\u001b[0m, in \u001b[0;36mLearner._do_one_batch\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_do_one_batch\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 216\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mxb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter_pred\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39myb):\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Input \u001b[1;32mIn [39]\u001b[0m, in \u001b[0;36mMyLLM10.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m,x):\n\u001b[1;32m---> 11\u001b[0m     res,h \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrnn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mi_h\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mh\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdrop(res)\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mh \u001b[38;5;241m=\u001b[39m [h_\u001b[38;5;241m.\u001b[39mdetach() \u001b[38;5;28;01mfor\u001b[39;00m h_ \u001b[38;5;129;01min\u001b[39;00m h]\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\modules\\rnn.py:812\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m    810\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_forward_args(\u001b[38;5;28minput\u001b[39m, hx, batch_sizes)\n\u001b[0;32m    811\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_sizes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 812\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    813\u001b[0m \u001b[43m                      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbidirectional\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_first\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    814\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    815\u001b[0m     result \u001b[38;5;241m=\u001b[39m _VF\u001b[38;5;241m.\u001b[39mlstm(\u001b[38;5;28minput\u001b[39m, batch_sizes, hx, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_weights, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias,\n\u001b[0;32m    816\u001b[0m                       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbidirectional)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "learn = Learner(dls, MyLLM10(len(vocab), 1024, 4, 0.5), \n",
    "                loss_func=CrossEntropyLossFlat(), \n",
    "                metrics=accuracy, \n",
    "                cbs=[ModelResetter,RNNRegularizer(alpha=2,beta=1)]\n",
    "               )\n",
    "\n",
    "# OR\n",
    "learn = TextLearner(dls, MyLLM10(len(vocab), 1024, 4, 0.4),\n",
    "                   loss_func = CrossEntropyLossFlat(), metrics=accuracy)\n",
    "\n",
    "learn.fit_one_cycle(15, 1e-3, wd=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "61e41d8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor([58]*64).dim()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "7e3f2ac8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(83865, 83865)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokens), len(nums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "2f4539e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#12) ['xbos','xupp','serikali','imesema','haitakuwa','tayari','kuona','amani','na','utulivu'...]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L(tokens[:12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "c6b6140a",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_p_nums = nums[-994:-970]\n",
    "to_p_nums = list(dls.valid.dataset[0][0])# + list(dls.valid.dataset[1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "96889164",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "na  s na wa na na na ya . . . ya ya ya "
     ]
    }
   ],
   "source": [
    "to_p = tensor([to_p_nums[:-1]]*64)\n",
    "\n",
    "prediction = learn.predict(to_p)#,[58]*64)])\n",
    "for p in prediction[0]:\n",
    "    print(vocab[p],end=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "501d7ee8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A th u ma n Ki hamia alisema hayo aki wasilisha ma da ya U "
     ]
    }
   ],
   "source": [
    "for a in to_p_nums[1:]:\n",
    "    print(vocab[a],end= ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10aaf9ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
