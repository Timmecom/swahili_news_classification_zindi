{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "065e33e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fastbook\n",
    "fastbook.setup_book()\n",
    "\n",
    "from fastbook import *\n",
    "import re\n",
    "from IPython.display import display,HTML\n",
    "\n",
    "from fastai.text.all import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e04528b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>content</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SW0</td>\n",
       "      <td>SERIKALI imesema haitakuwa tayari kuona amani na utulivu wa nchi inachezewa huku ikisisitiza uwepo wa umoja kati ya wananchi bila kujali tofauti ya imani, kabila au itikadi yoyote.Hayo yalisemwa na Naibu Waziri wa Mambo ya Ndani ya Nchi, Hamad Yussuf Masauni wakati akifungua semina ya siku mbili iliyofanyika jijini Dar es Salaam ikiwahusisha viongozi wa taasisi za Kiislamu, lengo ikiwa ni kuwakumbusha kuhubiri amani katika sehemu zao.Naibu Waziri amesema mwelekeo na malengo ya Serikali ya Awamu ya Tano ni kukuza maendeleo katika sehemu mbalimbali nchini lengo ikiwa kuinua maisha ya wananc...</td>\n",
       "      <td>Kitaifa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id  \\\n",
       "0  SW0   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   content  \\\n",
       "0   SERIKALI imesema haitakuwa tayari kuona amani na utulivu wa nchi inachezewa huku ikisisitiza uwepo wa umoja kati ya wananchi bila kujali tofauti ya imani, kabila au itikadi yoyote.Hayo yalisemwa na Naibu Waziri wa Mambo ya Ndani ya Nchi, Hamad Yussuf Masauni wakati akifungua semina ya siku mbili iliyofanyika jijini Dar es Salaam ikiwahusisha viongozi wa taasisi za Kiislamu, lengo ikiwa ni kuwakumbusha kuhubiri amani katika sehemu zao.Naibu Waziri amesema mwelekeo na malengo ya Serikali ya Awamu ya Tano ni kukuza maendeleo katika sehemu mbalimbali nchini lengo ikiwa kuinua maisha ya wananc...   \n",
       "\n",
       "  category  \n",
       "0  Kitaifa  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('datasets/Train.csv')\n",
    "test = pd.read_csv('datasets/Test.csv')\n",
    "train.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "576ff953",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c818dd50",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_news = partial(get_text_files, folders=['train','test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ead4e624",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#6439) [Path('test/001dd47ac202d9db6624a5ff734a5e7dddafeaf2.txt'),Path('test/0043d97f7690e9bc02f0ed8bb2b260d1d44bad92.txt'),Path('test/00579c2307b5c11003d21c40c3ecff5e922c3fd8.txt'),Path('test/00868eeee349e286303706ef0ffd851f39708d37.txt'),Path('test/00a5cb12d3058dcf2e42f277eee599992db32412.txt'),Path('test/00a93e174866089d7f4b59b72645573f963da555.txt'),Path('test/00caee8b79f36cc0a5ae4fe86b8abbedeef6c705.txt'),Path('test/00e72e69de296484ccacd96e38240844ac61be23.txt'),Path('test/018effc3b6ce812c825fb01d244f4b849658ef3c.txt'),Path('test/01996c3787dbce345ac122a8912dc9ab57334e2e.txt')...]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_news('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dea9b089",
   "metadata": {},
   "outputs": [],
   "source": [
    "db = DataBlock(\n",
    "    blocks = TextBlock.from_folder('',is_lm=True),\n",
    "    get_items = get_news,\n",
    "    splitter = RandomSplitter(0.1),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "19f516ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting-up type transforms pipelines\n",
      "Collecting items from \n",
      "Found 6439 items\n",
      "2 datasets of sizes 5796,643\n",
      "Setting up Pipeline: Tokenizer -> Numericalize\n",
      "\n",
      "Building one sample\n",
      "  Pipeline: Tokenizer -> Numericalize\n",
      "    starting from\n",
      "      train\\SW6256.txt\n",
      "    applying Tokenizer gives\n",
      "      ['xxbos', 'xxup', 'spika', 'xxmaj', 'job', 'xxmaj', 'ndugai', 'amewataka', 'xxmaj', 'watanzania', 'kujitokeza', 'kusajili', 'laini', 'za', 'simu', 'kwa', 'alama', 'za', 'vidole', 'kwa', 'ajili', 'ya', 'usalama', 'na', 'matumizi', 'bora', 'ya', 'simu.aidha', ',', 'mtu', 'yeyote', 'anayetakiwa', 'kusajili', 'laini', 'zaidi', 'ya', 'moja', 'kwa', 'mtoa', 'huduma', 'mmoja', ',', 'ni', 'lazima', 'aeleze', 'ni', 'kwanini', 'anahitaji', 'laini', 'ya', 'ziada', 'na', 'maelezo', 'yake', 'yakubaliwe.akizungumza', 'baada', 'ya', 'kutembelea', 'mabanda', 'na', 'kusajili', 'laini', 'zake', 'kwenye', 'viwanja', 'vya', 'xxmaj', 'bunge', ',', 'xxmaj', 'ndugai', 'amesema', 'ili', 'kuwa', 'na', 'usalama', 'na', 'matumizi', 'bora', 'ya', 'matumizi', 'ya', 'simu', 'ni', 'vyema', 'xxmaj', 'watanzania', 'wakasajili', 'laini', 'zao', 'na', 'pia', 'wakajitokeza', 'kujiandikisha', 'kwenye', 'uraia', '.', 'xxmaj', 'pia', 'niwasihi', 'wapigakura', 'wangu', 'xxmaj', 'kongwa', ',', 'pia', 'wajitokeze', 'kusajili', 'kwa', 'lengo', 'la', 'usalama', 'na', 'matumizi', 'bora', 'ya', 'simu', ',', 'watenge', 'muda', 'kwa', 'hili', 'maana', 'hata', 'hata', 'sekunde', 'chache', 'utakuwa', 'umesajili', ',', 'amesema.aidha', ',', 'kutokana', 'na', 'hoja', 'iliyoibuliwa', 'kuwa', 'wabunge', 'wa', 'xxmaj', 'zanzibar', 'wanashindwa', 'kusajili', 'laini', 'za', 'simu', 'kwa', 'alama', 'za', 'vidole', 'kwa', 'kuwa', 'na', 'kitambulisho', 'cha', 'xxmaj', 'mkazi', 'xxmaj', 'nzazibar', ',', 'xxmaj', 'ndugai', 'alisema', 'hakuna', 'mbunge', 'yeyote', 'ambaye', 'atashindwa', 'kusajiliwa', 'laini', 'zake.mamlaka', 'ya', 'xxmaj', 'mawasiliano', 'xxmaj', 'tanzania', '(', 'tcra', ')', 'imeshirikisha', 'watoa', 'huduma', 'wa', 'mawasiliano', 'kampuni', 'za', 'simu', 'kufanya', 'usajili', 'wa', 'laini', 'za', 'simu', 'kwa', 'alama', 'za', 'vidole', 'kwa', 'wabunge', ',', 'unaofanywa', 'kwenye', 'viwanja', 'vya', 'bunge.mkurugenzi', 'xxmaj', 'mkuu', 'wa', 'xxup', 'tcra', ',', 'xxmaj', 'james', 'xxmaj', 'kilaba', 'alisema', 'pamoja', 'na', 'kuwa', 'hawajazuia', 'mtu', 'mmoja', 'kusajili', 'laini', 'zaidi', 'ya', 'moja', 'kwa', 'mtoa', 'huduma', 'mmoja', ',', 'lakini', 'ni', 'lazima', 'mtu', 'huyo', 'aeleze', 'sababu', 'mahususi', 'kwa', 'kuwa', 'na', 'laini', 'zaidi', 'ya', 'moja', '.', 'xxmaj', 'mtakumbuka', 'hivi', 'karibuni', 'tumemkamata', 'mtu', 'mmoja', 'ana', 'laini', 'za', 'simu', '600', 'kwa', 'akili', 'ya', 'kawaida', 'unaweza', 'kujiuliza', 'anataka', 'kufanyia', 'nini', '.', 'xxmaj', 'tunasema', 'kuna', 'watu', 'milioni', '40', 'wanalaine', 'za', 'simu', 'huku', 'mmoja', 'ana', 'laini', '600', 'kwa', 'takwimu', 'kama', 'hizi', 'hatuwezi', 'kupanga', 'mipango', 'ya', 'maendeleo', ',', 'alisema.naibu', 'xxmaj', 'waziri', 'wa', 'xxmaj', 'ujenzi', ',', 'xxmaj', 'uchukuzi', 'na', 'xxmaj', 'mawasiliano', ',', 'xxmaj', 'atashasta', 'xxmaj', 'nditiye', 'alisema', 'serikali', 'imeanza', 'kusajili', 'laini', 'za', 'simu', 'kwa', 'alama', 'za', 'vidole', 'kwa', 'lengo', 'la', 'usalama', 'na', 'kuepusha', 'uhalifu', 'unaofanywa', 'kupitia', 'simu', 'za', 'mkononi', '.', 'xxmaj', 'serikali', 'tumefikia', 'hatua', 'hiyo', 'ili', 'kuwaepusha', 'xxmaj', 'watanzania', 'na', 'maumizo', 'ya', 'watu', 'wasio', 'waaminifu', 'wanaotumia', 'mitandao', 'ya', 'simu', 'kufanya', 'uhalifu', '.', 'xxmaj', 'tumeshuhudia', 'watu', 'wengi', 'wakiumizwa', 'na', 'wahalifu', 'kwa', 'kuambiwa', 'nitumie', 'hela', 'kwa', 'namba', 'hii', ',', 'na', 'watu', 'wamekuwa', 'wakituma', 'kwa', 'sababu', 'hujui', 'wakati', 'ujumbe', 'huo', 'unafika', 'ulikuwa', 'uko', 'kwenye', 'hali', 'gani', '.', 'xxmaj', 'aidha', ',', 'xxmaj', 'nditiye', 'alisema', 'kumekuwa', 'na', 'mwitikio', 'mzuri', 'wa', 'xxmaj', 'watanzania', 'wa', 'kusajili', 'laini', 'zao', 'za', 'simu', 'kwa', 'alama', 'za', 'vidole', 'ambao', 'ulianza', 'kabla', 'ya', 'xxmaj', 'mei', 'xxmaj', 'mosi', ',', 'mwaka', 'huu', ',', 'na', 'kuongeza', 'kuwa', 'xxmaj', 'septemba', '30', 'mwaka', 'huu', ',', 'serikali', 'itafanya', 'tathimini', 'ya', 'usajili', 'huo.akijibu', 'swali', 'kuhusu', 'wanafunzi', 'chini', 'ya', 'miaka', '18', 'kusajili', 'laini', 'zao', ',', 'xxmaj', 'nditiye', 'alisema', 'majukumu', 'ya', 'wanafunzi', 'ni', 'kusoma', 'na', 'kama', 'watakuwa', 'wanatumia', 'simu', 'basi', 'uwe', 'ni', 'kwa', 'udhamini', 'wa', 'mzazi', '.', 'xxmaj', 'serikali', 'tunasema', 'kijana', 'kuanzia', 'miaka', '18', 'ambaye', 'ndiye', 'anayestahili', 'kupata', 'kitambulisho', 'cha', 'uraia', 'na', 'ndiye', 'anayeweza', 'kumiliki', 'na', 'kutumia', 'simu', ',', 'chini', 'ya', 'hapo', 'iwe', 'kwa', 'udhamini', 'wa', 'mzazi', 'kama', 'ataamua', 'kumpa', 'laini', 'ya', 'simu', ',', 'kwani', 'umri', 'huo', 'jukumu', 'lao', 'kuu', 'ni', 'kusoma', ',', 'alisema', '.']\n",
      "    applying Numericalize gives\n",
      "      TensorText of size 519\n",
      "\n",
      "Final sample: (TensorText([    2,     7,   908,     8,  2177,     8,  1383,  1181,     8,   193,  1121,  1493,  2240,    16,   382,    13,  1211,    16,  4446,    13,    93,    10,   411,    11,   247,   160,    10,\n",
      "                0,     9,   281,   959, 27123,  1493,  2240,    50,    10,    74,    13,  4222,    70,   164,     9,    17,   342, 13212,    17,  2586,  2789,  2240,    10,  1597,    11,  1083,    44,\n",
      "                0,    30,    10,  1016,  3891,    11,  1493,  2240,   257,    25,   467,    32,     8,   355,     9,     8,  1383,    97,    29,    20,    11,   411,    11,   247,   160,    10,   247,\n",
      "               10,   382,    17,   538,     8,   193,     0,  2240,   106,    11,    41,     0,  4582,    25,  4761,    14,     8,    41, 15220,  5362,  1060,     8,  2773,     9,    41,  3493,  1493,\n",
      "               13,   177,    18,   411,    11,   247,   160,    10,   382,     9, 20667,   123,    13,   236,   359,   150,   150,  3604,  1220,   991,     0,     9,  6252,     9,    78,    11,   914,\n",
      "                0,    20,   669,    12,     8,   256,  3272,  1493,  2240,    16,   382,    13,  1211,    16,  4446,    13,    20,    11,  3114,    24,     8,   500,     8,     0,     9,     8,  1383,\n",
      "               19,   363,   389,   959,   121, 12687,  3065,  2240,     0,    10,     8,   379,     8,    31,    22,  2668,    23, 27079,  2226,    70,    12,   379,    98,    16,   382,    59,   412,\n",
      "               12,  2240,    16,   382,    13,  1211,    16,  4446,    13,   669,     9,  2629,    25,   467,    32,     0,     8,    46,    12,     7,  2668,     9,     8,  1182,     8, 12536,    19,\n",
      "               52,    11,    20,     0,   281,   164,  1493,  2240,    50,    10,    74,    13,  4222,    70,   164,     9,    42,    17,   342,   281,    56, 13212,   137,  2876,    13,    20,    11,\n",
      "             2240,    50,    10,    74,    14,     8,     0,   226,   373, 26540,   281,   164,   503,  2240,    16,   382,  2045,    13,  1773,    10,   628,  1202,  5926,   963,  1830,   665,    14,\n",
      "                8,  8002,   136,    77,   108,   766,     0,    16,   382,    91,   164,   503,  2240,  2045,    13,   719,    35,   561,  2250,  1468,   457,    10,   114,     9, 10519,     8,    71,\n",
      "               12,     8,   124,     9,     8,  1201,    11,     8,   379,     9,     8,  6494,     8,  4191,    19,    28,  1301,  1493,  2240,    16,   382,    13,  1211,    16,  4446,    13,   177,\n",
      "               18,   411,    11,  3461,  1395,  2629,   115,   382,    16,  1335,    14,     8,    28, 13170,    89,    21,    29, 11059,     8,   193,    11,     0,    10,    77,  1760,  2172,  2831,\n",
      "              961,    10,   382,    59,  1395,    14,     8,  9698,    77,   188,     0,    11,  2758,    13,  6766, 12042,  3876,    13,   462,   127,     9,    11,    77,   436,     0,    13,   137,\n",
      "            12012,    40,   764,    27, 10115,   919,  2453,    25,   157,   635,    14,     8,   549,     9,     8,  4191,    19,  1438,    11,  3422,   492,    12,     8,   193,    12,  1493,  2240,\n",
      "              106,    16,   382,    13,  1211,    16,  4446,    82,  2026,   184,    10,     8,   720,     8,  1212,     9,    26,    57,     9,    11,   140,    20,     8,   850,   365,    26,    57,\n",
      "                9,    28,  2788,  2739,    10,   412,     0,   825,   171,   267,   191,    10,    79,   472,  1493,  2240,   106,     9,     8,  4191,    19,   614,    10,   267,    17,  1354,    11,\n",
      "               35,   861,  1919,   382,   689,  2130,    17,    13,  2442,    12,  1986,    14,     8,    28,  8002,  1607,   248,    79,   472,   121,   998, 18436,    87,  3114,    24,  4761,    11,\n",
      "              998,  6679,  1838,    11,   173,   382,     9,   191,    10,   298,  1138,    13,  2442,    12,  1986,    35,  9821,  1592,  2240,    10,   382,     9,   120,   279,    27,   826,   969,\n",
      "              138,    17,  1354,     9,    19,    14]),)\n",
      "\n",
      "\n",
      "Collecting items from \n",
      "Found 6439 items\n",
      "2 datasets of sizes 5796,643\n",
      "Setting up Pipeline: Tokenizer -> Numericalize\n",
      "Setting up after_item: Pipeline: ToTensor\n",
      "Setting up before_batch: Pipeline: \n",
      "Setting up after_batch: Pipeline: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Building one batch\n",
      "Applying item_tfms to the first sample:\n",
      "  Pipeline: ToTensor\n",
      "    starting from\n",
      "      (TensorText of size 519)\n",
      "    applying ToTensor gives\n",
      "      (TensorText of size 519)\n",
      "\n",
      "Adding the next 3 samples\n",
      "\n",
      "No before_batch transform to apply\n",
      "\n",
      "Collating items in a batch\n",
      "Error! It's not possible to collate your items in a batch\n",
      "Could not collate the 0-th members of your tuples because got the following shapes\n",
      "torch.Size([519]),torch.Size([365]),torch.Size([724]),torch.Size([356])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error when trying to collate the data into batches with fa_collate, at least two tensors in the batch are not the same size.\n\nMismatch found on axis 0 of the batch and is of type `TensorText`:\n\tItem at index 0 has shape: torch.Size([519])\n\tItem at index 1 has shape: torch.Size([365])\n\nPlease include a transform in `after_item` that ensures all data of type TensorText is the same size",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[1;32mIn [29]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mdb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msummary\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mseq_len\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m80\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\fastai\\data\\block.py:237\u001b[0m, in \u001b[0;36msummary\u001b[1;34m(self, source, bs, show_batch, **kwargs)\u001b[0m\n\u001b[0;32m    235\u001b[0m     why \u001b[38;5;241m=\u001b[39m _find_fail_collate(s)\n\u001b[0;32m    236\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMake sure all parts of your samples are tensors of the same size\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m why \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m why)\n\u001b[1;32m--> 237\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m    239\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m([f \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m dls\u001b[38;5;241m.\u001b[39mtrain\u001b[38;5;241m.\u001b[39mafter_batch\u001b[38;5;241m.\u001b[39mfs \u001b[38;5;28;01mif\u001b[39;00m f\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnoop\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m!=\u001b[39m\u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    240\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mApplying batch_tfms to the batch built\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\fastai\\data\\block.py:231\u001b[0m, in \u001b[0;36msummary\u001b[1;34m(self, source, bs, show_batch, **kwargs)\u001b[0m\n\u001b[0;32m    229\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mCollating items in a batch\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    230\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 231\u001b[0m     b \u001b[38;5;241m=\u001b[39m \u001b[43mdls\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    232\u001b[0m     b \u001b[38;5;241m=\u001b[39m retain_types(b, s[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m is_listy(s) \u001b[38;5;28;01melse\u001b[39;00m s)\n\u001b[0;32m    233\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\fastai\\data\\load.py:166\u001b[0m, in \u001b[0;36mDataLoader.create_batch\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    164\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m: \u001b[38;5;28;01mreturn\u001b[39;00m (fa_collate,fa_convert)[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprebatched](b)\n\u001b[0;32m    165\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e: \n\u001b[1;32m--> 166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprebatched: \u001b[43mcollate_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    167\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\fastai\\data\\load.py:164\u001b[0m, in \u001b[0;36mDataLoader.create_batch\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    163\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_batch\u001b[39m(\u001b[38;5;28mself\u001b[39m, b): \n\u001b[1;32m--> 164\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m: \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m(\u001b[49m\u001b[43mfa_collate\u001b[49m\u001b[43m,\u001b[49m\u001b[43mfa_convert\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprebatched\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    165\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e: \n\u001b[0;32m    166\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprebatched: collate_error(e,b)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\fastai\\data\\load.py:52\u001b[0m, in \u001b[0;36mfa_collate\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA replacement for PyTorch `default_collate` which maintains types and handles `Sequence`s\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     50\u001b[0m b \u001b[38;5;241m=\u001b[39m t[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (default_collate(t) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(b, _collate_types)\n\u001b[1;32m---> 52\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(t[\u001b[38;5;241m0\u001b[39m])([fa_collate(s) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mt)]) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(b, Sequence)\n\u001b[0;32m     53\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m default_collate(t))\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\fastai\\data\\load.py:52\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA replacement for PyTorch `default_collate` which maintains types and handles `Sequence`s\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     50\u001b[0m b \u001b[38;5;241m=\u001b[39m t[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (default_collate(t) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(b, _collate_types)\n\u001b[1;32m---> 52\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(t[\u001b[38;5;241m0\u001b[39m])([\u001b[43mfa_collate\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mt)]) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(b, Sequence)\n\u001b[0;32m     53\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m default_collate(t))\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\fastai\\data\\load.py:51\u001b[0m, in \u001b[0;36mfa_collate\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA replacement for PyTorch `default_collate` which maintains types and handles `Sequence`s\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     50\u001b[0m b \u001b[38;5;241m=\u001b[39m t[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m---> 51\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[43mdefault_collate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(b, _collate_types)\n\u001b[0;32m     52\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(t[\u001b[38;5;241m0\u001b[39m])([fa_collate(s) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mt)]) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(b, Sequence)\n\u001b[0;32m     53\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m default_collate(t))\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\utils\\data\\_utils\\collate.py:265\u001b[0m, in \u001b[0;36mdefault_collate\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m    204\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdefault_collate\u001b[39m(batch):\n\u001b[0;32m    205\u001b[0m     \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;124;03m        Function that takes in a batch of data and puts the elements within the batch\u001b[39;00m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;124;03m        into a tensor with an additional outer dimension - batch size. The exact output type can be\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    263\u001b[0m \u001b[38;5;124;03m            >>> default_collate(batch)  # Handle `CustomType` automatically\u001b[39;00m\n\u001b[0;32m    264\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 265\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdefault_collate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\utils\\data\\_utils\\collate.py:123\u001b[0m, in \u001b[0;36mcollate\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m collate_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[0;32m    122\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, collate_type):\n\u001b[1;32m--> 123\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate_fn_map\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcollate_type\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    125\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, collections\u001b[38;5;241m.\u001b[39mabc\u001b[38;5;241m.\u001b[39mMapping):\n\u001b[0;32m    126\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\utils\\data\\_utils\\collate.py:162\u001b[0m, in \u001b[0;36mcollate_tensor_fn\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    160\u001b[0m     storage \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39m_typed_storage()\u001b[38;5;241m.\u001b[39m_new_shared(numel, device\u001b[38;5;241m=\u001b[39melem\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m    161\u001b[0m     out \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39mnew(storage)\u001b[38;5;241m.\u001b[39mresize_(\u001b[38;5;28mlen\u001b[39m(batch), \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mlist\u001b[39m(elem\u001b[38;5;241m.\u001b[39msize()))\n\u001b[1;32m--> 162\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\fastai\\torch_core.py:382\u001b[0m, in \u001b[0;36mTensorBase.__torch_function__\u001b[1;34m(cls, func, types, args, kwargs)\u001b[0m\n\u001b[0;32m    380\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mdebug \u001b[38;5;129;01mand\u001b[39;00m func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__str__\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__repr__\u001b[39m\u001b[38;5;124m'\u001b[39m): \u001b[38;5;28mprint\u001b[39m(func, types, args, kwargs)\n\u001b[0;32m    381\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _torch_handled(args, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_opt, func): types \u001b[38;5;241m=\u001b[39m (torch\u001b[38;5;241m.\u001b[39mTensor,)\n\u001b[1;32m--> 382\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__torch_function__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtypes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mifnone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    383\u001b[0m dict_objs \u001b[38;5;241m=\u001b[39m _find_args(args) \u001b[38;5;28;01mif\u001b[39;00m args \u001b[38;5;28;01melse\u001b[39;00m _find_args(\u001b[38;5;28mlist\u001b[39m(kwargs\u001b[38;5;241m.\u001b[39mvalues()))\n\u001b[0;32m    384\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(\u001b[38;5;28mtype\u001b[39m(res),TensorBase) \u001b[38;5;129;01mand\u001b[39;00m dict_objs: res\u001b[38;5;241m.\u001b[39mset_meta(dict_objs[\u001b[38;5;241m0\u001b[39m],as_copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\_tensor.py:1295\u001b[0m, in \u001b[0;36mTensor.__torch_function__\u001b[1;34m(cls, func, types, args, kwargs)\u001b[0m\n\u001b[0;32m   1292\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[0;32m   1294\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _C\u001b[38;5;241m.\u001b[39mDisableTorchFunctionSubclass():\n\u001b[1;32m-> 1295\u001b[0m     ret \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1296\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m func \u001b[38;5;129;01min\u001b[39;00m get_default_nowrap_functions():\n\u001b[0;32m   1297\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m ret\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Error when trying to collate the data into batches with fa_collate, at least two tensors in the batch are not the same size.\n\nMismatch found on axis 0 of the batch and is of type `TensorText`:\n\tItem at index 0 has shape: torch.Size([519])\n\tItem at index 1 has shape: torch.Size([365])\n\nPlease include a transform in `after_item` that ensures all data of type TensorText is the same size"
     ]
    }
   ],
   "source": [
    "db.summary('',seq_len=80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d426fcc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dls_lm = db.dataloaders(path, path=path, bs=128, seq_len=80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91138049",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4937acc4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#5151) [' SERIKALI imesema haitakuwa tayari kuona amani na utulivu wa nchi inachezewa huku ikisisitiza uwepo wa umoja kati ya wananchi bila kujali tofauti ya imani, kabila au itikadi yoyote.Hayo yalisemwa na Naibu Waziri wa Mambo ya Ndani ya Nchi, Hamad Yussuf Masauni wakati akifungua semina ya siku mbili iliyofanyika jijini Dar es Salaam ikiwahusisha viongozi wa taasisi za Kiislamu, lengo ikiwa ni kuwakumbusha kuhubiri amani katika sehemu zao.Naibu Waziri amesema mwelekeo na malengo ya Serikali ya Awamu ya Tano ni kukuza maendeleo katika sehemu mbalimbali nchini lengo ikiwa kuinua maisha ya wananchi na nchi kwa ujumla.“Serikali hii imejidhatiti kuhakikisha maendeleo yanakuja kwa kasi na maendeleo hayawezi kuja ikiwa amani na utulivu haupo, sisi kama serikali tutahakikisha tunalinda amani iliyopo ili wananchi wapate kufanya shughuli za kiuchumi bila wasiwasi wowote,” amesema Masauni.Akizungumza wakati wa ufunguzi huo, Shehe wa Mkoa wa Dar es Salaam, Alhaji Alhad Mussa Salum aliihakikishia serikali kutokuwepo kwa mifarakano kati ya taasisi mbalimbali kama ilivyokuwepo awali huku akisisitiza kuendelea kwa umoja huo ili jamii ipate kuendelea.“Sisi kama Bakwata tunaihakikishia serikali uwepo wa umoja na ushirikiano baina ya baraza na taasisi zingine na tofauti zetu hazipelekei kukoseana au kuvunjiana heshima kwahiyo tunaomba serikali iamini uwepo wa maelewano mazuri tu kwa maendeleo ya nchi hii,” amesema Shehe Alhad.Semina hiyo ya siku mbili imejumuisha viongozi wa taasisi 100 huku mada ya Nafasi ya Taasisi za Kiislamu katika Kuleta Umoja na Kuishi kwa Amani itajadiliwa.',' Mkuu wa Mkoa wa Tabora, Aggrey Mwanri amesitisha likizo za viongozi wote mkoani humo kutekeleza maazimio ya Jukwaa la Fursa za Biashara la mkoa huo.Mwanri ameagiza kuwa, hata kama kuna likizo zimeidhinishwa zifutwe.Amemuagiza Katibu Tawala wa Mkoa huo, Msalika Makungu kuandika barua kwa viongozi kuhusu uamuzi huo na amebainisha kuwa hakushauriwa na mtu, kaamua yeye.“Anayebisha anyooshe mkono, ajifanye angalau anajikuna tu” amesema Mwanri kwenye jukwaa hilo la nane lililomalizika leo.Amewaeleza viongozi wa Tabora kuwa, mambo waliyopanga kuyafanya wakati wa likizo nje ya Tabora wanaweza kuyafanya mkoani humo hivyo wawaite ndugu zao waende mkoani humo.Kiongozi huyo wa Tabora amewaagiza maofisa ugani mkoani humo watoke ofisini wahamie shambani.Viongozi mbalimbali wamehudhuria jukwaa la Tabora akiwemo mwenyekiti wa jukwaa hilo, Waziri wa Habari, Utamaduni, Sanaa na Michezo, Dk. Harrison Mwakyembe, Waziri wa Viwanda, Biashara na Uwekezaji Joseph Kakunda, Mwenyekiti wa Bodi ya Kampuni ya Magazeti ya Serikali, Hab Mkwizu na Mwenyekiti wa Chama cha Mapinduzi (CCM) Mkoa wa Tabora, Hassan Wakasuvi.Viongozi wengine waliohudhuria jukwaa hilo ni wakuu wa wilaya, wakurugenzi watendaji wa Halmashauri, makatibu tawala wa wilaya, wenyeviti wa halmashauri za wilaya, wakuu wa taasisi na waendai wengine mkoani humo.',' SERIKALI imetoa miezi sita kwa taasisi zote za umma ambazo hazitumii mfumo wa GePG katika ukusanyaji wa fedha kufanya hivyo na baada ya hapo itafanya ukaguzi na kuwawajibisha maofi sa masuhuli walioshindwa kutekeleza hilo.Akifungua mkutano wa mwaka wa kwanza wa watumiaji wa mfumo huo jana jijini hapa, Naibu Katibu Mkuu Wizara ya Fedha na Mipango, Dk Hartibu Kazungu alisema ukaguzi huo ambao utaanza kufanyika Juni mwakani baada ya kipindi kilichowekwa kupita ili kuwabaini maofisa wazembe.Alisema, wizara yake itafanya ukaguzi wa ofisi zote za umma ili kubaini kama kuna fedha zinazokusanywa bila kupitia kwenye mfumo wa GePG na kuwa ofisi itakayobainika kutotumia mfumo huo maofisa masuhuli watawajibishwa kwa mujibu wa sheria.“Mnifikishie ujumbe wa kuzikumbusha taasisi ambazo hazijaanza kutumia mfumo wa ukusanyaji mapato wa GePG kufanya hivyo, kwani tunataka hadi kufikia Juni 30, mwaka 2019, kusiwe na fedha yoyote kwenye taasisi ya umma ambayo inakusanywa nje ya mfumo huu,” alisema.Hata hivyo, alisisitiza kuwa utaratibu wa malipo kupitia GePG unawapa fursa ya kuwa na njia nyingi za kulipia zikiwa na lengo la kuwapa walipaji wa huduma za serikali utaratibu rafiki na machaguo mengi ya njia za kufanya malipo.“Nimepewa taarifa kuwa takribani benki kumi na moja (11) na mitandao sita ya malipo kwa njia ya simu za kiganjani zimeshaunganishwa na GePG. “Hii ni kuthibitisha namna mfumo wa GePG umekuwa na fursa nyingi za ulipaji, hivyo kuweka mazingira kwa umma katika kufanya malipo hivyo kuondoa urasimu na ucheleweshaji usiofaa.”Dk Kazungu alisema kuwa mfumo huo ulianzishwa ili kuongeza uwazi na udhibiti wa fedha za umma, kuboresha na kurahisisha namna ya kulipia huduma za umma pamoja na kupunguza gharama zinazoambatana na ukusanyaji wa fedha za umma.Akizungumza na waandishi wa habari baada ya ufunguzi huo Mkurugenzi wa mfumo kutoka wizara hiyo, John Sausi alisema changamoto wanayokuta nayo katika utekelezaji wa mfumo huo uelewa mdogo wa namna ya kutumia.Katika utekelezaji wa mfumo huo tuna changamoto moja kubwa ambayo ni uelewa wa watumiaji wa mfumo kushindwa kutumia vyema mfumo huu vizuri hivyo kulazimika kutumia watu wa operesheni kwa ajili ya kurudia utoaji wa elimu.Alisema changamoto nyingine ni ukosekanaji kwa mtandao katika maeneo ya vijijini hivyo mfumo kushindwa kufanya kazi. “Changamoto ya mtandao tunaangalia namna ya kukabiliana nayo mwaka mzima tangu kuanza kwa mfumo huu, lakini kama wizara tunaamini haiwezi kutusumbua,” alisema. Aidha, Sausi alisema tangu kuanza kutumika kwa mufmo huo hapa nchini hadi sasa taasisi 326 tayari zinatumia mfumo huo katika kutoa huduma.',' KAMPUNI ya mchezo wa kubahatisha ya M-bet imeingia makubaliano ya udhamini na timu ya soka ya Manispaa ya Kinondoni (KMC) kwa miaka mitano wenye thamani ya sh Bilioni 1.Akizungumzia udhamini huo jana baada ya kusaini mkataba huo, Meneja Masoko wa Mbet, Allen Mushi alisema sababu ya kuiunga mkono timu hiyo ni baada ya kuvutiwa na kiwango bora walichokionesha timu hiyo tangu msimu uliopita. Alisema kitendo cha kumaliza ligi katika nafasi ya nne bora sio cha mchezo na kwamba hata wanapokuwa uwanjani hucheza soka la kuvutia tofauti na wengine.“Tumeichagua KMC kwasababu tumevutiwa na mambo mengi, kwanza jinsi wanavyojiongoza katika mipango yao ya muda mfupi na mrefu, lakini kingine wanapokuwa uwanjani soka lao ni la kuvutia,”alisema.Alisema wanaweza kuboresha kiwango cha fedha kila mwaka endapo timu hiyo itakuwa inafanya vizuri na hata kuchukua taji la Ligi Kuu. Kwa upande wake, Meya wa Manispaa ya Kinondoni Benjamini Sitta alisema udhamini huo hauzuii fursa mbalimbali kutoka kwa wadau wengine.Alisema fursa za kudhamini timu hiyo zipo na wanategemea wengine watajitokeza kuwaunga mkono kuelekea katika harakati zao za kujenga uwanja wa kisasa wa klabu hiyo.Katika hatua nyingine, Kocha wa KMC Jakson Mayanja alizungumzia maandalizi ya kikosi chake kuelekea katika mchezo wa marudiano wa Kombe la Shirikisho Afrika dhidi ya AS Kigali kuwa yanakwenda vizuri. Mchezo huo utafanyika kesho Ijumaa.',' WATANZANIA wamekumbushwa kusherehekea sikukuu ya Krismasi kwa kuenzi amani, umoja na kulinda tamaduni za nchi ili kupambana na changamoto mbalimbali zinazojitokeza, ikiwemo vitendo vya ushoga na matumizi ya dawa za kulevya.Akizungumza wakati wa kutoa heri ya sikukuu hiyo ya Kuzaliwa Yesu Kristo, Kiongozi wa Waislamu wa madhehebu ya Shia Ithnasheriya, Shehe Hemed Jalala alisema kuzaliwa kwa Yesu kunalenga kuhubiri na kutangaza amani ulimwenguni. Shehe Jalala alisema licha ya Wayahudi kutilia shaka kuzaliwa kwa Yesu, lakini pindi alipozaliwa alitangaza amani kwake na duniani kote akitaka kila mtu kuishi kwa upendo, amani na umoja.“Jamii yenye amani mara nyingi hupambana na vitendo vya uvunjifu wa amani, kulinda mila na desturi kwa kupinga vitendo vya ushoga, matumizi ya dawa za kulevya na rushwa. Pia upendo utatawala miongoni mwa majirani, familia na kutokuwa na ukabila,” alisema Shehe Jalala. Pia alisema nchi inayoondoa ujinga, kupambana na maradhi na kuhimiza watu wake kufanya kazi kwa bidii, ina lengo la kudumisha amani hivyo huenda sambamba na ujumbe wa amani aliouacha Yesu.Shehe Jalala alisema amani inaenziwa katika nyanja mbalimbali kuanzia kwa mtu mmoja mmoja, kitaifa na kimataifa na kwamba eneo ambalo kuna uhuru wa kuabudu na mtu kujifanyia mambo yake mwenyewe ni ishara ya uwepo wa amani. “Katika Kitabu Kitakatifu cha Kurani, Mwenyezi Mungu amezungumzia kuzaliwa kwa Yesu na neno la kwanza Yesu (Isa bin Mariam) ni amani iwe kwangu siku niliyozaliwa, kufa na kufufuka nikiwa hai,” alisisitiza.Aliongeza kuwa mambo yote yanayosababisha uvunjifu wa amani yasipewe nafasi badala yake kuendelea kudumisha upendo na amani siku zote. Kwa upande wake, Mkurugenzi wa Taasisi ya Kikristo ya Outreach Ministries (TCOM), Mchungaji Banza Seleman alisema Yesu alizaliwa baada ya mwanadamu kumuasi Mwenyezi Mungu hivyo alikuja kuwakomboa kutoka dhambini.Alisema kuja kwa mkombozi huo ni upendo mkubwa wa Mungu kwa wanadamu na kwamba lengo ni kuihubiri amani na upendo ili watu waweze kushirikiana na kusaidiana. “Katika Biblia na Kurani, vitabu hivi vinaeleza kuwa Yesu ni mfalme wa amani hivyo tunastahili kulinda amani, kuishi kwa upendo na umoja. Yesu alizaliwa ili aweze kuhubiri amani kwa watu wote,” alisema Mchungaji Seleman.',' Malkia wa Mipasho Afrika Mashariki, Khadija Omary Kopa amesema wasanii nchini hawana umoja, na kwamba, wale wa bongo fleva na watu wengine, wanawaona wa taarabu ni watu wa hali ya chini na masikini.Amesema jijini Dar es Salaam kuwa, kutokana na mtazamo huo, wasanii wa fani nyingine wamekuwa hawawashirikishi katika mambo yao wale wa taarabu.Amedai kuwa, hata Serikali imekuwa haiwajali wasanii wa taarabu hata inapotokea misiba, na ametoa mfano mfano wa ajali iliyowaua wasanii wengi wa Kundi la Zanzibar Stars Modern Taarabu.Amesema umoja uwe kwa wasanii wote na sio kwa baadhi tu na alilalamika kuwa wamekuwa wakitozwa fedha nyingi wakitaka maeneo ya kurekodia video zao za nyimbo.Katika mkutano huo, muimbaji wa muziki wa dansi nchini, Nyosh El Saadat amesema, amechoka kuwakimbia watu wa Uhamiaji na sasa anataka uraia wa Tanzania baada ya kuishi nchini kwa zaidi ya miaka 20.Nyoshi alimwambia Mkuu wa Mkoa wa Dar es Salaam, Paul Makonda wakati wa wasanii wa fani mbalimbali na wanamichezo walipokutana na mkuu huyo wa mkoa katika viwanja vya Leaders.Nyoshi alimwambia Makonda kuwa amekaa nchini kwa muda mrefu na mara kwa amekuwa akijificha uvunguni ya kitanda au kupanda darini kujificha kuakwepa watu wa Idara ya Uhamiaji kutokana na kutokuwa na uraia.Alisema kuwa sasa wakati umefika kwa yeye kuwa raia wa Tanzania. Naye Kikumbi Mwanza Mpango au King Kiki aliwataka wasanii kupenda na kushirikiana bila ya kujali tofauti ya fani zao.Alitoa masikitiko yake kwa baadhi ya wasanii kutokuwa na ushirikiano miongoni mwao, hivyo aliwataka washirikiane.Nasseeb Abdul au Diamond amesema, mengi yamezungumza ila alipongeza ujenzi wa ukumbi mkubwa utakaoingiza watu 20,000, huku akiwapa shavu wasanii kupigiwa au kuoneshwa bure katika Wasafi Radio na Wasafi TV.',' Meneja Masoko na Mawasiliano wa taasisi hiyo, Ngula Cheyo aliyasema hayo jana ikiwa ni siku chache baada ya kuzinduliwa kwa huduma ya mikopo ya viwanja jijini Dar es Salaam, huku akisisitiza kwamba si lazima mkopaji wa viwanja hivyo atoke Dar es Salaam au Kibaha.Cheyo alisema kwamba huduma hiyo ni ya Watanzania wote, ndio sababu taasisi hiyo wamesambaza fomu za kuomba mkopo wa viwanja katika matawi yao mbalimbali, bila kusahau wale wanaoweza kukopa kwa njia ya mtandao.“Nafasi ni chache, maana maombi yetu yanafanyika kwa siku ishirini na yameanza Mei 22 hadi Juni 10, na fomu za maombi zinapatikana matawi yote ya taasisi yetu, bila kusahau kupitia B ank of Africa (BOA), ambapo malilipo ya awali yanaanzia Sh 150,000,” alisema.Alisema kukaa mikoani si sababu ya kushindwa kukopa kiwanja kwa sababu wamefungua matawi katika wilaya na mikoa mbalimbali.Meneja Biashara wa Bayport Financial Services, Thabit Mndeme, alisema ukubwa wa viwanja hivyo unaanzia hatua 15 kwa 16, huku thamani yake ikianzia Sh 1,400,000 bila riba.',' IDADI ya vifo vya waendesha bodaboda nchini vitokanavyo na ajali imepungua katika kipindi cha robo ya kwanza ya mwaka huu kinachoanzia Januari hadi Machi, ikilinganishwa na idadi ya vifo vya bodaboda kwa kipindi kama hicho kwa mwaka jana. Mwanasheria wa Kikosi cha Usalama Barabarani, Afande Deusi Sokoni akizungumza na gazeti hili katika mahojiano maalumu alisema kuwa idadi ya waendeshaji bodaboda waliopoteza maisha kwa mwaka huu ni 73 huku majeruhi wakiwa 121.Alisema, kwa mwaka jana kwa kipindi kama hicho waliopoteza maisha walikuwa ni 108 huku waliojeruhiwa ni 214. Sokoni aliongeza kuwa robo ya kwanza ya mwaka huu kwa upande wa waendesha baiskeli waliopoteza maisha kwa ajali za barabarani walikuwa 23 idadi ambayo ni sawa na ya majeruhi lakini mwaka jana kuanzia Januari hadi Machi, idadi ya waliokufa ilikuwa ni 34 huku waliojeruhiwa wakiwa 30. Alisema pia waendesha mikokoteni tisa wamekufa na wanne wamejeruhiwa huku mwaka jana aliyekufa alikuwa mmoja na 12 walijeruhiwa. Kundi la watembea kwa miguu ambalo ni moja kati ya waathirika wakubwa wa ajali kwa mwaka huu wamekufa 90 na kujeruhiwa 106. Wakati kwa mwaka jana waliokufa walikuwa 163 na kujeruhiwa 179. Kwa upande wa abiria waliokufa kwa ajali kwa mwaka huu ni 108 na 393 wamekumbwa na majeraha mbalimbali wakati kwa mwaka jana waliokufa walikuwa 191 na majeruhi 575.',' Katika uzinduzi huo, rais amesema kuna haja ya kutafuta majawabu kuhusu namna ya kuongeza maghala ya kuhifadhia mazao kwani kadiri kilimo kinavyoboreshwa mazao yanayozalishwa yanakosa pa kuhifadhiwa.Rais Kikwete aliyasema hayo- Dar es Salaam juzi wakati akizindua kampuni hiyo ambayo itakuwa chini ya Mamlaka ya Soko la Bidhaa Tanzania (CMSA). Alisema uzinduzi wa soko hilo ambalo litaanza kufanya kazi rasmi mwezi Mei, mwakani kwa kuanzia na mazao ya korosho, ufuta, alizeti na mpunga ni muendelezo wa jitihada za serikali katika kuleta mageuzi ya kilimo nchini.“Hii ni habari njema kwa wakulima wa Tanzania kwani katika jitihada zetu za kuleta mageuzi ya kilimo zisingefanikiwa kama Tanzania kusingekuwa na soko la uhakika. Mfumo uliopo sasa unawakandamiza wakulima na kuwanufaisha walanguzi,” alisema Rais Kikwete.Alisema pamoja na kuanzishwa kwa sera ya kilimo kwanza, stakabadhi ghalani, uanzishwaji wa benki ya wakulima na vyama vya ushirika kwa ajili ya kuboresha sekta ya kilimo nchini, bado sekta hiyo ilikabiliwa na tatizo la ukosefu wa uhakika wa masoko.Mkurugenzi wa bodi ya wakurugenzi wa TMX, Peter Noni alisema kampuni hiyo ilisajiliwa Agosti, mwaka jana kama kiungo muhimu katika mchakato wa kuanzisha soko la bidhaa nchini.Aliwataja wanahisa waanzilishi wa kampuni hiyo kuwa ni msajili wa hazina, Mfuko wa Pensheni kwa Watumishi wa Umma (PSPF), Benki ya Maendeleo (TIB) na Shirika la Vyama vya Ushirika.',' Mshindi wa mchezo utakaozikutanisha Tottenham huko Rochdale jana atakutana na Sheffield Jumatano au Swansea, ambaye atacheza baada ya suluhu ya jana Jumamosi.Southampton leo itasafiri na kucheza na mshindi kati ya Manchester City na Wigan, wakati Leicester na Chelsea watakutana katika mchezo utakaozikutanisha timu za Ligi Kuu.Rochdale, timu ya chini kabisa iliyobaki katika mashindano hayo, iko mkiani katika Ligi Daraja la Pili, jana ilitarajia kucheza dhidi ya Tottenham. Wigan, iliyopo katika nafasi ya pili katika Ligi Daraja la Pili, itacheza dhidi ya Manchester City leo Jumatatu.Leicester, ambayo iliifunga Sheffield United 1-0 Ijumaa, itakuwa na kibarua kigumu wakati itakapocheza dhidi ya Chelsea, ambao nao walishinda Ijumaa kwa mabao 4-0 dhidi ya Hull City.Ratiba ya robo fainali ya FA Cup Leicester v Chelsea Man United v Brighton Sheffield au Swansea v Rochdale au Tottenham Wigan au Manchester City v Southampton'...]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L(list(train.content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b8602a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f0884514",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       Kitaifa - SERIKALI imesema haitakuwa tayari kuona amani na utulivu wa nchi inachezewa huku ikisisitiza uwepo wa umoja kati ya wananchi bila kujali tofauti ya imani, kabila au itikadi yoyote.Hayo yalisemwa na Naibu Waziri wa Mambo ya Ndani ya Nchi, Hamad Yussuf Masauni wakati akifungua semina ya siku mbili iliyofanyika jijini Dar es Salaam ikiwahusisha viongozi wa taasisi za Kiislamu, lengo ikiwa ni kuwakumbusha kuhubiri amani katika sehemu zao.Naibu Waziri amesema mwelekeo na malengo ya Serikali ya Awamu ya Tano ni kukuza maendeleo katika sehemu mbalimbali nchini lengo ikiwa kuinua maisha ...\n",
       "1       Biashara - Mkuu wa Mkoa wa Tabora, Aggrey Mwanri amesitisha likizo za viongozi wote mkoani humo kutekeleza maazimio ya Jukwaa la Fursa za Biashara la mkoa huo.Mwanri ameagiza kuwa, hata kama kuna likizo zimeidhinishwa zifutwe.Amemuagiza Katibu Tawala wa Mkoa huo, Msalika Makungu kuandika barua kwa viongozi kuhusu uamuzi huo na amebainisha kuwa hakushauriwa na mtu, kaamua yeye.“Anayebisha anyooshe mkono, ajifanye angalau anajikuna tu” amesema Mwanri kwenye jukwaa hilo la nane lililomalizika leo.Amewaeleza viongozi wa Tabora kuwa, mambo waliyopanga kuyafanya wakati wa likizo nje ya Tabora wa...\n",
       "2       Kitaifa - SERIKALI imetoa miezi sita kwa taasisi zote za umma ambazo hazitumii mfumo wa GePG katika ukusanyaji wa fedha kufanya hivyo na baada ya hapo itafanya ukaguzi na kuwawajibisha maofi sa masuhuli walioshindwa kutekeleza hilo.Akifungua mkutano wa mwaka wa kwanza wa watumiaji wa mfumo huo jana jijini hapa, Naibu Katibu Mkuu Wizara ya Fedha na Mipango, Dk Hartibu Kazungu alisema ukaguzi huo ambao utaanza kufanyika Juni mwakani baada ya kipindi kilichowekwa kupita ili kuwabaini maofisa wazembe.Alisema, wizara yake itafanya ukaguzi wa ofisi zote za umma ili kubaini kama kuna fedha zinazo...\n",
       "3       michezo - KAMPUNI ya mchezo wa kubahatisha ya M-bet imeingia makubaliano ya udhamini na timu ya soka ya Manispaa ya Kinondoni (KMC) kwa miaka mitano wenye thamani ya sh Bilioni 1.Akizungumzia udhamini huo jana baada ya kusaini mkataba huo, Meneja Masoko wa Mbet, Allen Mushi alisema sababu ya kuiunga mkono timu hiyo ni baada ya kuvutiwa na kiwango bora walichokionesha timu hiyo tangu msimu uliopita. Alisema kitendo cha kumaliza ligi katika nafasi ya nne bora sio cha mchezo na kwamba hata wanapokuwa uwanjani hucheza soka la kuvutia tofauti na wengine.“Tumeichagua KMC kwasababu tumevutiwa na ...\n",
       "4       Kitaifa - WATANZANIA wamekumbushwa kusherehekea sikukuu ya Krismasi kwa kuenzi amani, umoja na kulinda tamaduni za nchi ili kupambana na changamoto mbalimbali zinazojitokeza, ikiwemo vitendo vya ushoga na matumizi ya dawa za kulevya.Akizungumza wakati wa kutoa heri ya sikukuu hiyo ya Kuzaliwa Yesu Kristo, Kiongozi wa Waislamu wa madhehebu ya Shia Ithnasheriya, Shehe Hemed Jalala alisema kuzaliwa kwa Yesu kunalenga kuhubiri na kutangaza amani ulimwenguni. Shehe Jalala alisema licha ya Wayahudi kutilia shaka kuzaliwa kwa Yesu, lakini pindi alipozaliwa alitangaza amani kwake na duniani kote a...\n",
       "                                                                                                                                                                                                                                                                                                                 ...                                                                                                                                                                                                                                                                                                           \n",
       "5146    Kitaifa - RAIS John Magufuli ameendelea kung’ara katika siasa za kimataifa mwaka huu, baada ya Taasisi ya Transparency International (TI), kuitaja Tanzania kuwa moja ya nchi zilizofanya vizuri katika masuala ya kupiga vita rushwa.Ripoti ya TI ya mwaka huu, iliyopatikana Dar es Salam juzi, imesema Tanzania imeendelea kufanya vizuri katika vita dhidi ya rushwa kubwa na ndogo, zinazohujumu uchumi na kuumiza wananchi wa kawaida wapatapo huduma.Rais Magufuli amekuwa kinara wa mapambanodhidi ya rushwa tangu aingie madararakani mwaka 2015, ambapo Tanzania imekuwa katika vita dhidi ya uhujumu uchu...\n",
       "5147    Kitaifa - KAMPENI inayohimiza watafi ti kuandika upya historia ya ukombozi wa nchi na Afrika kwa ujumla imeanza, lengo likiwa ni kuwezesha wanafunzi kusoma historia ambayo haijapotoshwa kwa makusudi.Akiwasilisha Makadirio ya Mapato na Matumizi ya Fedha kwa Mwaka 2019/20 bungeni jana, Waziri wa Habari, Utamaduni, Sanaa na Michezo, Dk Harrison Mwakyembe (pichani) alisema mbali na wizara yake kusimamia hilo, pia itafufua kampeni ya kurejesha fuvu la shujaa Leti Hema wa Wanyaturu na mashujaa wengine lililochukuliwa na Wajerumani wakati wa ukoloni.“Wizara itahimiza kampeni... kuwezesha wanafunz...\n",
       "5148    Kitaifa - MATUKIO mapya ya malaria kwa kila watu 1,000 katika jamii, yamepungua kwa asilimia 62 kutoka matukio 295 kwa kila watu 1,000 mwaka 2008 hadi matukio 112 kwa kila watu 1,000 .Hiyo ni kwa mujibu wa tafiti zilizofanywa mwaka 2008/2017 na Mpango wa Taifa wa Kudhibiti Malaria (NMCP) kwa kushirikiana na Wizara ya Afya, Maendeleo ya Jamii, Wazee na Watoto. Aidha vifo vinavyosababishwa na malaria, vimepungua kwa asilimia 73 kutoka vifo 33 kwa watu 1,000 katika jamii kwa mwaka 2008 hadi vifo 9 kwa watu 1,000 kwa mwaka 2017.Mhamasishaji Theresia Shirima kutoka NMCP, akizungumza na wanahaba...\n",
       "5149    Kitaifa - IMEELEZWA kuwa hakuna sheria yoyote inayokataza taarifa za Tume ya Haki za Binadamu na Utawala Bora kujadiliwa Bungeni endapo mbunge ataona kuna jambo la kuibua kutoka kwenye taarifa iliyoibuliwa.Akijibu swali la mbunge wa Mgogoni Dk Suleiman Ally Yusuf (CUF), kwa niaba ya Waziri wa Katiba na Sheria, Naibu Waziri wa Elimu, Sayansi na Teknolojia, William ole Nasha alisema kwamba tume imekuwa ikitimiza wajibu wake na ripoti zake ziwazi. Katika swali lake la msingi, mbunge huyo alikuwa anataka kujua kwa nini ripoti za tume hiyo haziwekwi wazi kwa umma na kama serikali haioni kuwa wa...\n",
       "5150    Biashara - Akizungumza mara baada ya kutiwa saini kwa makubaliano hayo jana jioni Waziri wa Nchi Ofisi ya Waziri Mkuu Tawala za Mikoa na Serikali za Mitaa, Hawa Ghasia, alisema uwekezaji huo unatarajiwa kuleta manufaa kwa shirika hilo kwani uwekezaji wake pia utasaidia kutoa elimu kwa vitendo juu ya ufugaji kwa kada mbalimbali.Alisema miaka ya nyuma shirika hilo lilikuwa likisifika kwa ufugaji wa kuku kabla ya kusitisha shughuli hizo kutokana na uwepo wa sababu mbalimbali na kusababisha shirika hilo kukosa mapato yaliyokuwa yakitokana na uuzaji wa kuku na mayai.Mkurugenzi wa Shirika la Eli...\n",
       "Length: 5151, dtype: object"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['category'] + ' -' + train['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "2cb2b001",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(x):\n",
    "    # return L(list(x[['content','category']]))\n",
    "    # return L(list(x['content']))\n",
    "    return L(list(x['category'] + ' /' + x['content']))\n",
    "\n",
    "db = DataBlock(\n",
    "    blocks = (TextBlock.from_df(['content']), CategoryBlock),\n",
    "    splitter = RandomSplitter(0.1),\n",
    "    get_items = get_data,\n",
    "    get_y = parent_label\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ab396e8d",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"Label '['Hakika ni habari ambazo mashabiki wengi wa klabu ya Arsenal wanapenda kuzisikia.', 'Tajiri namba moja Afrika, Mnigeria Aliko Dangote anahusishwa tena na taarifa za  kutaka kuinunua klabu anayoishabikia ya Arsenal. ', 'Tofauti ni kuwa safari hii, duru zinasema kuwa jambo hilo linaweza kutokea mwaka 2021. ', 'Dangote amenukuliwa na shirika la habari la Bloomberg akisema kuwa: ' was not included in the training dataset\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\fastai\\data\\transforms.py:261\u001b[0m, in \u001b[0;36mCategorize.encodes\u001b[1;34m(self, o)\u001b[0m\n\u001b[0;32m    260\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 261\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m TensorCategory(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvocab\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mo2i\u001b[49m\u001b[43m[\u001b[49m\u001b[43mo\u001b[49m\u001b[43m]\u001b[49m)\n\u001b[0;32m    262\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['Hakika ni habari ambazo mashabiki wengi wa klabu ya Arsenal wanapenda kuzisikia.', 'Tajiri namba moja Afrika, Mnigeria Aliko Dangote anahusishwa tena na taarifa za  kutaka kuinunua klabu anayoishabikia ya Arsenal. ', 'Tofauti ni kuwa safari hii, duru zinasema kuwa jambo hilo linaweza kutokea mwaka 2021. ', 'Dangote amenukuliwa na shirika la habari la Bloomberg akisema kuwa: \"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[1;32mIn [69]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m dls_lm \u001b[38;5;241m=\u001b[39m \u001b[43mdb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataloaders\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseq_len\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m80\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\fastai\\data\\block.py:157\u001b[0m, in \u001b[0;36mDataBlock.dataloaders\u001b[1;34m(self, source, path, verbose, **kwargs)\u001b[0m\n\u001b[0;32m    155\u001b[0m dsets \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdatasets(source, verbose\u001b[38;5;241m=\u001b[39mverbose)\n\u001b[0;32m    156\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdls_kwargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mverbose\u001b[39m\u001b[38;5;124m'\u001b[39m: verbose}\n\u001b[1;32m--> 157\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m dsets\u001b[38;5;241m.\u001b[39mdataloaders(path\u001b[38;5;241m=\u001b[39mpath, after_item\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitem_tfms, after_batch\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_tfms, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\fastai\\data\\core.py:337\u001b[0m, in \u001b[0;36mFilteredBase.dataloaders\u001b[1;34m(self, bs, shuffle_train, shuffle, val_shuffle, n, path, dl_type, dl_kwargs, device, drop_last, val_bs, **kwargs)\u001b[0m\n\u001b[0;32m    335\u001b[0m dl \u001b[38;5;241m=\u001b[39m dl_type(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msubset(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmerge(kwargs,def_kwargs, dl_kwargs[\u001b[38;5;241m0\u001b[39m]))\n\u001b[0;32m    336\u001b[0m def_kwargs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbs\u001b[39m\u001b[38;5;124m'\u001b[39m:bs \u001b[38;5;28;01mif\u001b[39;00m val_bs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m val_bs,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mshuffle\u001b[39m\u001b[38;5;124m'\u001b[39m:val_shuffle,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;28;01mNone\u001b[39;00m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdrop_last\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;28;01mFalse\u001b[39;00m}\n\u001b[1;32m--> 337\u001b[0m dls \u001b[38;5;241m=\u001b[39m [dl] \u001b[38;5;241m+\u001b[39m [dl\u001b[38;5;241m.\u001b[39mnew(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msubset(i), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmerge(kwargs,def_kwargs,val_kwargs,dl_kwargs[i]))\n\u001b[0;32m    338\u001b[0m               \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_subsets)]\n\u001b[0;32m    339\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dbunch_type(\u001b[38;5;241m*\u001b[39mdls, path\u001b[38;5;241m=\u001b[39mpath, device\u001b[38;5;241m=\u001b[39mdevice)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\fastai\\data\\core.py:337\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    335\u001b[0m dl \u001b[38;5;241m=\u001b[39m dl_type(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msubset(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmerge(kwargs,def_kwargs, dl_kwargs[\u001b[38;5;241m0\u001b[39m]))\n\u001b[0;32m    336\u001b[0m def_kwargs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbs\u001b[39m\u001b[38;5;124m'\u001b[39m:bs \u001b[38;5;28;01mif\u001b[39;00m val_bs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m val_bs,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mshuffle\u001b[39m\u001b[38;5;124m'\u001b[39m:val_shuffle,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;28;01mNone\u001b[39;00m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdrop_last\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;28;01mFalse\u001b[39;00m}\n\u001b[1;32m--> 337\u001b[0m dls \u001b[38;5;241m=\u001b[39m [dl] \u001b[38;5;241m+\u001b[39m [dl\u001b[38;5;241m.\u001b[39mnew(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msubset(i), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmerge(kwargs,def_kwargs,val_kwargs,dl_kwargs[i]))\n\u001b[0;32m    338\u001b[0m               \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_subsets)]\n\u001b[0;32m    339\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dbunch_type(\u001b[38;5;241m*\u001b[39mdls, path\u001b[38;5;241m=\u001b[39mpath, device\u001b[38;5;241m=\u001b[39mdevice)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\fastai\\text\\data.py:218\u001b[0m, in \u001b[0;36mSortedDL.new\u001b[1;34m(self, dataset, **kwargs)\u001b[0m\n\u001b[0;32m    216\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_res\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m kwargs \u001b[38;5;129;01mand\u001b[39;00m kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_res\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m: res \u001b[38;5;241m=\u001b[39m kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_res\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m    217\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m: res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mres \u001b[38;5;28;01mif\u001b[39;00m dataset \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 218\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mnew(dataset\u001b[38;5;241m=\u001b[39mdataset, res\u001b[38;5;241m=\u001b[39mres, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\fastai\\data\\core.py:94\u001b[0m, in \u001b[0;36mTfmdDL.new\u001b[1;34m(self, dataset, cls, **kwargs)\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[38;5;129m@delegates\u001b[39m(DataLoader\u001b[38;5;241m.\u001b[39mnew)\n\u001b[0;32m     89\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnew\u001b[39m(\u001b[38;5;28mself\u001b[39m, \n\u001b[0;32m     90\u001b[0m     dataset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;66;03m# Map- or iterable-style dataset from which to load the data\u001b[39;00m\n\u001b[0;32m     91\u001b[0m     \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;66;03m# Class of the newly created `DataLoader` object\u001b[39;00m\n\u001b[0;32m     92\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m     93\u001b[0m ):\n\u001b[1;32m---> 94\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mnew(dataset, \u001b[38;5;28mcls\u001b[39m, do_setup\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     95\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_n_inp\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_types\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m     96\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\fastai\\data\\load.py:148\u001b[0m, in \u001b[0;36mDataLoader.new\u001b[1;34m(self, dataset, cls, **kwargs)\u001b[0m\n\u001b[0;32m    146\u001b[0m     o \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, n)\n\u001b[0;32m    147\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(o, MethodType): cur_kwargs[n] \u001b[38;5;241m=\u001b[39m o\n\u001b[1;32m--> 148\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmerge(cur_kwargs, kwargs))\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\fastai\\text\\data.py:191\u001b[0m, in \u001b[0;36mSortedDL.__init__\u001b[1;34m(self, dataset, sort_func, res, **kwargs)\u001b[0m\n\u001b[0;32m    189\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msort_func \u001b[38;5;241m=\u001b[39m _default_sort \u001b[38;5;28;01mif\u001b[39;00m sort_func \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m sort_func\n\u001b[0;32m    190\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m res \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msort_func \u001b[38;5;241m==\u001b[39m _default_sort: res \u001b[38;5;241m=\u001b[39m _get_lengths(dataset)\n\u001b[1;32m--> 191\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mres \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msort_func(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdo_item(i)) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m range_of(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset)] \u001b[38;5;28;01mif\u001b[39;00m res \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m res\n\u001b[0;32m    192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mres) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39midx_max \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mres)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\fastai\\text\\data.py:191\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    189\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msort_func \u001b[38;5;241m=\u001b[39m _default_sort \u001b[38;5;28;01mif\u001b[39;00m sort_func \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m sort_func\n\u001b[0;32m    190\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m res \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msort_func \u001b[38;5;241m==\u001b[39m _default_sort: res \u001b[38;5;241m=\u001b[39m _get_lengths(dataset)\n\u001b[1;32m--> 191\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mres \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msort_func(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_item\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m range_of(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset)] \u001b[38;5;28;01mif\u001b[39;00m res \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m res\n\u001b[0;32m    192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mres) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39midx_max \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mres)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\fastai\\data\\load.py:153\u001b[0m, in \u001b[0;36mDataLoader.do_item\u001b[1;34m(self, s)\u001b[0m\n\u001b[0;32m    152\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdo_item\u001b[39m(\u001b[38;5;28mself\u001b[39m, s):\n\u001b[1;32m--> 153\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m: \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mafter_item(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_item\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    154\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m SkipItemException: \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\fastai\\data\\load.py:160\u001b[0m, in \u001b[0;36mDataLoader.create_item\u001b[1;34m(self, s)\u001b[0m\n\u001b[0;32m    159\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_item\u001b[39m(\u001b[38;5;28mself\u001b[39m, s):\n\u001b[1;32m--> 160\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindexed: \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43ms\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m    161\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m s \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:  \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mit)\n\u001b[0;32m    162\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m: \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot index an iterable dataset numerically - must use `None`.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\fastai\\data\\core.py:458\u001b[0m, in \u001b[0;36mDatasets.__getitem__\u001b[1;34m(self, it)\u001b[0m\n\u001b[0;32m    457\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, it):\n\u001b[1;32m--> 458\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m([tl[it] \u001b[38;5;28;01mfor\u001b[39;00m tl \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtls])\n\u001b[0;32m    459\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m res \u001b[38;5;28;01mif\u001b[39;00m is_indexer(it) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mres))\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\fastai\\data\\core.py:458\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    457\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, it):\n\u001b[1;32m--> 458\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m([\u001b[43mtl\u001b[49m\u001b[43m[\u001b[49m\u001b[43mit\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m tl \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtls])\n\u001b[0;32m    459\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m res \u001b[38;5;28;01mif\u001b[39;00m is_indexer(it) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mres))\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\fastai\\data\\core.py:417\u001b[0m, in \u001b[0;36mTfmdLists.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m    415\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getitem__\u001b[39m(idx)\n\u001b[0;32m    416\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_after_item \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m: \u001b[38;5;28;01mreturn\u001b[39;00m res\n\u001b[1;32m--> 417\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_after_item\u001b[49m\u001b[43m(\u001b[49m\u001b[43mres\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m is_indexer(idx) \u001b[38;5;28;01melse\u001b[39;00m res\u001b[38;5;241m.\u001b[39mmap(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_after_item)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\fastai\\data\\core.py:377\u001b[0m, in \u001b[0;36mTfmdLists._after_item\u001b[1;34m(self, o)\u001b[0m\n\u001b[1;32m--> 377\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_after_item\u001b[39m(\u001b[38;5;28mself\u001b[39m, o): \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtfms\u001b[49m\u001b[43m(\u001b[49m\u001b[43mo\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\fastcore\\transform.py:208\u001b[0m, in \u001b[0;36mPipeline.__call__\u001b[1;34m(self, o)\u001b[0m\n\u001b[1;32m--> 208\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, o): \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcompose_tfms\u001b[49m\u001b[43m(\u001b[49m\u001b[43mo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtfms\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit_idx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\fastcore\\transform.py:158\u001b[0m, in \u001b[0;36mcompose_tfms\u001b[1;34m(x, tfms, is_enc, reverse, **kwargs)\u001b[0m\n\u001b[0;32m    156\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m tfms:\n\u001b[0;32m    157\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_enc: f \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mdecode\n\u001b[1;32m--> 158\u001b[0m     x \u001b[38;5;241m=\u001b[39m f(x, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    159\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\fastcore\\transform.py:81\u001b[0m, in \u001b[0;36mTransform.__call__\u001b[1;34m(self, x, **kwargs)\u001b[0m\n\u001b[0;32m     79\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[0;32m     80\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mname\u001b[39m(\u001b[38;5;28mself\u001b[39m): \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_name\u001b[39m\u001b[38;5;124m'\u001b[39m, _get_name(\u001b[38;5;28mself\u001b[39m))\n\u001b[1;32m---> 81\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs): \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencodes\u001b[39m\u001b[38;5;124m'\u001b[39m, x, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     82\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode\u001b[39m  (\u001b[38;5;28mself\u001b[39m, x, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs): \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdecodes\u001b[39m\u001b[38;5;124m'\u001b[39m, x, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     83\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__repr__\u001b[39m(\u001b[38;5;28mself\u001b[39m): \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mencodes: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencodes\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124mdecodes: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecodes\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\fastcore\\transform.py:91\u001b[0m, in \u001b[0;36mTransform._call\u001b[1;34m(self, fn, x, split_idx, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_call\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn, x, split_idx\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     90\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m split_idx\u001b[38;5;241m!=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msplit_idx \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msplit_idx \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m: \u001b[38;5;28;01mreturn\u001b[39;00m x\n\u001b[1;32m---> 91\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_do_call(\u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn), x, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\fastcore\\transform.py:97\u001b[0m, in \u001b[0;36mTransform._do_call\u001b[1;34m(self, f, x, **kwargs)\u001b[0m\n\u001b[0;32m     95\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m f \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m: \u001b[38;5;28;01mreturn\u001b[39;00m x\n\u001b[0;32m     96\u001b[0m     ret \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mreturns(x) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(f,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreturns\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m---> 97\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m retain_type(f(x, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs), x, ret)\n\u001b[0;32m     98\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_do_call(f, x_, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;28;01mfor\u001b[39;00m x_ \u001b[38;5;129;01min\u001b[39;00m x)\n\u001b[0;32m     99\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m retain_type(res, x)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\fastcore\\dispatch.py:120\u001b[0m, in \u001b[0;36mTypeDispatch.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minst \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m: f \u001b[38;5;241m=\u001b[39m MethodType(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minst)\n\u001b[0;32m    119\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mowner \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m: f \u001b[38;5;241m=\u001b[39m MethodType(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mowner)\n\u001b[1;32m--> 120\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\fastai\\data\\transforms.py:263\u001b[0m, in \u001b[0;36mCategorize.encodes\u001b[1;34m(self, o)\u001b[0m\n\u001b[0;32m    261\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m TensorCategory(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvocab\u001b[38;5;241m.\u001b[39mo2i[o])\n\u001b[0;32m    262\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m--> 263\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLabel \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mo\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m was not included in the training dataset\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"Label '['Hakika ni habari ambazo mashabiki wengi wa klabu ya Arsenal wanapenda kuzisikia.', 'Tajiri namba moja Afrika, Mnigeria Aliko Dangote anahusishwa tena na taarifa za  kutaka kuinunua klabu anayoishabikia ya Arsenal. ', 'Tofauti ni kuwa safari hii, duru zinasema kuwa jambo hilo linaweza kutokea mwaka 2021. ', 'Dangote amenukuliwa na shirika la habari la Bloomberg akisema kuwa: ' was not included in the training dataset\""
     ]
    }
   ],
   "source": [
    "dls_lm = db.dataloaders(train, bs=128, seq_len=80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "8bedcb4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xxbos [ ' manchester xxmaj united xxunk katika harakati ya kutaka kumsaini beki wa xxmaj leicester na xxmaj uingereza xxmaj harry xxmaj maguire baada ya kuambiwa kwamba mchezaji huyo mwenye umri wa miaka 26 xxunk £ 100 m. ( mirror ) ' , ' mkufunzi wa klabu ya xxmaj nice nchini xxmaj ufaransa xxmaj patrick xxmaj vieira , 43 , xxmaj mkufunzi wa klabu ya xxmaj rangers xxmaj steven xxmaj gerrard , 39 , kocha wa xxmaj manchester xxmaj city xxmaj mikel xxmaj arteta , 37 , xxunk miongoni mwa wakufunzi wanaotarajiwa kumrithi xxmaj rafael xxmaj benitez . ( telegraph ) ' , ' raia wa xxmaj uhispania xxmaj mikel xxmaj arteta ameungwa mkono kuchukua ukufunzi wa klabu ya xxmaj manchester xxmaj city wakati kocha xxmaj pep xxmaj guardiola atakapoondoka katika klabu hiyo . ( evening xxmaj standard ) ' , ' mkufunzi wa klabu ya xxmaj burnley xxmaj sean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>xxbos xxup rais xxmaj john xxmaj magufuli amewaagiza wafanyabiashara kulipa kodi kwa wakati , kutotoa rushwa na kuripoti xxunk rushwa . xxmaj akizungumza na wafanyabiasha xxmaj ikulu jana , xxmaj rais xxmaj magufuli aliwapongeza wafanyabiashara hao kufika katika mkutano huo kwa gharama zao na pia kutoa michango yao kwa lengo la kuboresha huduma za serikali lakini pia mazingira ya biashara.alisema lengo la mkutano huo ilikuwa ni kueleza changamoto mbalimbali zinazosababisha kodi xxunk ipasavyo ambapo alikumbusha kuwa kazi ya xxmaj mamlaka ya xxmaj mapato ( tra ) ni kukusanya kodi . xxmaj aliwashukuru wafanyabiashara hao kwa kusema ukweli na wameeleza kodi inayokusanywa labda asilimia tatu ndio inakwenda serikali na asilimia kubwa inapotea kutokana na rushwa.alisema kodi xxunk kama nchi itaingia katika matatizo makubwa na kuongeza kuwa maendelo yote yanayofanyika ni kutokana na kodi za wananchi . “ vituo vya afya , hospitali vyote xxunk kwa kodi za wananchi . xxmaj kuna</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dls_lm.show_batch(max_n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "22029063",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#5151) [' SERIKALI imesema haitakuwa tayari kuona amani na utulivu wa nchi inachezewa huku ikisisitiza uwepo wa umoja kati ya wananchi bila kujali tofauti ya imani, kabila au itikadi yoyote.Hayo yalisemwa na Naibu Waziri wa Mambo ya Ndani ya Nchi, Hamad Yussuf Masauni wakati akifungua semina ya siku mbili iliyofanyika jijini Dar es Salaam ikiwahusisha viongozi wa taasisi za Kiislamu, lengo ikiwa ni kuwakumbusha kuhubiri amani katika sehemu zao.Naibu Waziri amesema mwelekeo na malengo ya Serikali ya Awamu ya Tano ni kukuza maendeleo katika sehemu mbalimbali nchini lengo ikiwa kuinua maisha ya wananchi na nchi kwa ujumla.“Serikali hii imejidhatiti kuhakikisha maendeleo yanakuja kwa kasi na maendeleo hayawezi kuja ikiwa amani na utulivu haupo, sisi kama serikali tutahakikisha tunalinda amani iliyopo ili wananchi wapate kufanya shughuli za kiuchumi bila wasiwasi wowote,” amesema Masauni.Akizungumza wakati wa ufunguzi huo, Shehe wa Mkoa wa Dar es Salaam, Alhaji Alhad Mussa Salum aliihakikishia serikali kutokuwepo kwa mifarakano kati ya taasisi mbalimbali kama ilivyokuwepo awali huku akisisitiza kuendelea kwa umoja huo ili jamii ipate kuendelea.“Sisi kama Bakwata tunaihakikishia serikali uwepo wa umoja na ushirikiano baina ya baraza na taasisi zingine na tofauti zetu hazipelekei kukoseana au kuvunjiana heshima kwahiyo tunaomba serikali iamini uwepo wa maelewano mazuri tu kwa maendeleo ya nchi hii,” amesema Shehe Alhad.Semina hiyo ya siku mbili imejumuisha viongozi wa taasisi 100 huku mada ya Nafasi ya Taasisi za Kiislamu katika Kuleta Umoja na Kuishi kwa Amani itajadiliwa.',' Mkuu wa Mkoa wa Tabora, Aggrey Mwanri amesitisha likizo za viongozi wote mkoani humo kutekeleza maazimio ya Jukwaa la Fursa za Biashara la mkoa huo.Mwanri ameagiza kuwa, hata kama kuna likizo zimeidhinishwa zifutwe.Amemuagiza Katibu Tawala wa Mkoa huo, Msalika Makungu kuandika barua kwa viongozi kuhusu uamuzi huo na amebainisha kuwa hakushauriwa na mtu, kaamua yeye.“Anayebisha anyooshe mkono, ajifanye angalau anajikuna tu” amesema Mwanri kwenye jukwaa hilo la nane lililomalizika leo.Amewaeleza viongozi wa Tabora kuwa, mambo waliyopanga kuyafanya wakati wa likizo nje ya Tabora wanaweza kuyafanya mkoani humo hivyo wawaite ndugu zao waende mkoani humo.Kiongozi huyo wa Tabora amewaagiza maofisa ugani mkoani humo watoke ofisini wahamie shambani.Viongozi mbalimbali wamehudhuria jukwaa la Tabora akiwemo mwenyekiti wa jukwaa hilo, Waziri wa Habari, Utamaduni, Sanaa na Michezo, Dk. Harrison Mwakyembe, Waziri wa Viwanda, Biashara na Uwekezaji Joseph Kakunda, Mwenyekiti wa Bodi ya Kampuni ya Magazeti ya Serikali, Hab Mkwizu na Mwenyekiti wa Chama cha Mapinduzi (CCM) Mkoa wa Tabora, Hassan Wakasuvi.Viongozi wengine waliohudhuria jukwaa hilo ni wakuu wa wilaya, wakurugenzi watendaji wa Halmashauri, makatibu tawala wa wilaya, wenyeviti wa halmashauri za wilaya, wakuu wa taasisi na waendai wengine mkoani humo.',' SERIKALI imetoa miezi sita kwa taasisi zote za umma ambazo hazitumii mfumo wa GePG katika ukusanyaji wa fedha kufanya hivyo na baada ya hapo itafanya ukaguzi na kuwawajibisha maofi sa masuhuli walioshindwa kutekeleza hilo.Akifungua mkutano wa mwaka wa kwanza wa watumiaji wa mfumo huo jana jijini hapa, Naibu Katibu Mkuu Wizara ya Fedha na Mipango, Dk Hartibu Kazungu alisema ukaguzi huo ambao utaanza kufanyika Juni mwakani baada ya kipindi kilichowekwa kupita ili kuwabaini maofisa wazembe.Alisema, wizara yake itafanya ukaguzi wa ofisi zote za umma ili kubaini kama kuna fedha zinazokusanywa bila kupitia kwenye mfumo wa GePG na kuwa ofisi itakayobainika kutotumia mfumo huo maofisa masuhuli watawajibishwa kwa mujibu wa sheria.“Mnifikishie ujumbe wa kuzikumbusha taasisi ambazo hazijaanza kutumia mfumo wa ukusanyaji mapato wa GePG kufanya hivyo, kwani tunataka hadi kufikia Juni 30, mwaka 2019, kusiwe na fedha yoyote kwenye taasisi ya umma ambayo inakusanywa nje ya mfumo huu,” alisema.Hata hivyo, alisisitiza kuwa utaratibu wa malipo kupitia GePG unawapa fursa ya kuwa na njia nyingi za kulipia zikiwa na lengo la kuwapa walipaji wa huduma za serikali utaratibu rafiki na machaguo mengi ya njia za kufanya malipo.“Nimepewa taarifa kuwa takribani benki kumi na moja (11) na mitandao sita ya malipo kwa njia ya simu za kiganjani zimeshaunganishwa na GePG. “Hii ni kuthibitisha namna mfumo wa GePG umekuwa na fursa nyingi za ulipaji, hivyo kuweka mazingira kwa umma katika kufanya malipo hivyo kuondoa urasimu na ucheleweshaji usiofaa.”Dk Kazungu alisema kuwa mfumo huo ulianzishwa ili kuongeza uwazi na udhibiti wa fedha za umma, kuboresha na kurahisisha namna ya kulipia huduma za umma pamoja na kupunguza gharama zinazoambatana na ukusanyaji wa fedha za umma.Akizungumza na waandishi wa habari baada ya ufunguzi huo Mkurugenzi wa mfumo kutoka wizara hiyo, John Sausi alisema changamoto wanayokuta nayo katika utekelezaji wa mfumo huo uelewa mdogo wa namna ya kutumia.Katika utekelezaji wa mfumo huo tuna changamoto moja kubwa ambayo ni uelewa wa watumiaji wa mfumo kushindwa kutumia vyema mfumo huu vizuri hivyo kulazimika kutumia watu wa operesheni kwa ajili ya kurudia utoaji wa elimu.Alisema changamoto nyingine ni ukosekanaji kwa mtandao katika maeneo ya vijijini hivyo mfumo kushindwa kufanya kazi. “Changamoto ya mtandao tunaangalia namna ya kukabiliana nayo mwaka mzima tangu kuanza kwa mfumo huu, lakini kama wizara tunaamini haiwezi kutusumbua,” alisema. Aidha, Sausi alisema tangu kuanza kutumika kwa mufmo huo hapa nchini hadi sasa taasisi 326 tayari zinatumia mfumo huo katika kutoa huduma.',' KAMPUNI ya mchezo wa kubahatisha ya M-bet imeingia makubaliano ya udhamini na timu ya soka ya Manispaa ya Kinondoni (KMC) kwa miaka mitano wenye thamani ya sh Bilioni 1.Akizungumzia udhamini huo jana baada ya kusaini mkataba huo, Meneja Masoko wa Mbet, Allen Mushi alisema sababu ya kuiunga mkono timu hiyo ni baada ya kuvutiwa na kiwango bora walichokionesha timu hiyo tangu msimu uliopita. Alisema kitendo cha kumaliza ligi katika nafasi ya nne bora sio cha mchezo na kwamba hata wanapokuwa uwanjani hucheza soka la kuvutia tofauti na wengine.“Tumeichagua KMC kwasababu tumevutiwa na mambo mengi, kwanza jinsi wanavyojiongoza katika mipango yao ya muda mfupi na mrefu, lakini kingine wanapokuwa uwanjani soka lao ni la kuvutia,”alisema.Alisema wanaweza kuboresha kiwango cha fedha kila mwaka endapo timu hiyo itakuwa inafanya vizuri na hata kuchukua taji la Ligi Kuu. Kwa upande wake, Meya wa Manispaa ya Kinondoni Benjamini Sitta alisema udhamini huo hauzuii fursa mbalimbali kutoka kwa wadau wengine.Alisema fursa za kudhamini timu hiyo zipo na wanategemea wengine watajitokeza kuwaunga mkono kuelekea katika harakati zao za kujenga uwanja wa kisasa wa klabu hiyo.Katika hatua nyingine, Kocha wa KMC Jakson Mayanja alizungumzia maandalizi ya kikosi chake kuelekea katika mchezo wa marudiano wa Kombe la Shirikisho Afrika dhidi ya AS Kigali kuwa yanakwenda vizuri. Mchezo huo utafanyika kesho Ijumaa.',' WATANZANIA wamekumbushwa kusherehekea sikukuu ya Krismasi kwa kuenzi amani, umoja na kulinda tamaduni za nchi ili kupambana na changamoto mbalimbali zinazojitokeza, ikiwemo vitendo vya ushoga na matumizi ya dawa za kulevya.Akizungumza wakati wa kutoa heri ya sikukuu hiyo ya Kuzaliwa Yesu Kristo, Kiongozi wa Waislamu wa madhehebu ya Shia Ithnasheriya, Shehe Hemed Jalala alisema kuzaliwa kwa Yesu kunalenga kuhubiri na kutangaza amani ulimwenguni. Shehe Jalala alisema licha ya Wayahudi kutilia shaka kuzaliwa kwa Yesu, lakini pindi alipozaliwa alitangaza amani kwake na duniani kote akitaka kila mtu kuishi kwa upendo, amani na umoja.“Jamii yenye amani mara nyingi hupambana na vitendo vya uvunjifu wa amani, kulinda mila na desturi kwa kupinga vitendo vya ushoga, matumizi ya dawa za kulevya na rushwa. Pia upendo utatawala miongoni mwa majirani, familia na kutokuwa na ukabila,” alisema Shehe Jalala. Pia alisema nchi inayoondoa ujinga, kupambana na maradhi na kuhimiza watu wake kufanya kazi kwa bidii, ina lengo la kudumisha amani hivyo huenda sambamba na ujumbe wa amani aliouacha Yesu.Shehe Jalala alisema amani inaenziwa katika nyanja mbalimbali kuanzia kwa mtu mmoja mmoja, kitaifa na kimataifa na kwamba eneo ambalo kuna uhuru wa kuabudu na mtu kujifanyia mambo yake mwenyewe ni ishara ya uwepo wa amani. “Katika Kitabu Kitakatifu cha Kurani, Mwenyezi Mungu amezungumzia kuzaliwa kwa Yesu na neno la kwanza Yesu (Isa bin Mariam) ni amani iwe kwangu siku niliyozaliwa, kufa na kufufuka nikiwa hai,” alisisitiza.Aliongeza kuwa mambo yote yanayosababisha uvunjifu wa amani yasipewe nafasi badala yake kuendelea kudumisha upendo na amani siku zote. Kwa upande wake, Mkurugenzi wa Taasisi ya Kikristo ya Outreach Ministries (TCOM), Mchungaji Banza Seleman alisema Yesu alizaliwa baada ya mwanadamu kumuasi Mwenyezi Mungu hivyo alikuja kuwakomboa kutoka dhambini.Alisema kuja kwa mkombozi huo ni upendo mkubwa wa Mungu kwa wanadamu na kwamba lengo ni kuihubiri amani na upendo ili watu waweze kushirikiana na kusaidiana. “Katika Biblia na Kurani, vitabu hivi vinaeleza kuwa Yesu ni mfalme wa amani hivyo tunastahili kulinda amani, kuishi kwa upendo na umoja. Yesu alizaliwa ili aweze kuhubiri amani kwa watu wote,” alisema Mchungaji Seleman.',' Malkia wa Mipasho Afrika Mashariki, Khadija Omary Kopa amesema wasanii nchini hawana umoja, na kwamba, wale wa bongo fleva na watu wengine, wanawaona wa taarabu ni watu wa hali ya chini na masikini.Amesema jijini Dar es Salaam kuwa, kutokana na mtazamo huo, wasanii wa fani nyingine wamekuwa hawawashirikishi katika mambo yao wale wa taarabu.Amedai kuwa, hata Serikali imekuwa haiwajali wasanii wa taarabu hata inapotokea misiba, na ametoa mfano mfano wa ajali iliyowaua wasanii wengi wa Kundi la Zanzibar Stars Modern Taarabu.Amesema umoja uwe kwa wasanii wote na sio kwa baadhi tu na alilalamika kuwa wamekuwa wakitozwa fedha nyingi wakitaka maeneo ya kurekodia video zao za nyimbo.Katika mkutano huo, muimbaji wa muziki wa dansi nchini, Nyosh El Saadat amesema, amechoka kuwakimbia watu wa Uhamiaji na sasa anataka uraia wa Tanzania baada ya kuishi nchini kwa zaidi ya miaka 20.Nyoshi alimwambia Mkuu wa Mkoa wa Dar es Salaam, Paul Makonda wakati wa wasanii wa fani mbalimbali na wanamichezo walipokutana na mkuu huyo wa mkoa katika viwanja vya Leaders.Nyoshi alimwambia Makonda kuwa amekaa nchini kwa muda mrefu na mara kwa amekuwa akijificha uvunguni ya kitanda au kupanda darini kujificha kuakwepa watu wa Idara ya Uhamiaji kutokana na kutokuwa na uraia.Alisema kuwa sasa wakati umefika kwa yeye kuwa raia wa Tanzania. Naye Kikumbi Mwanza Mpango au King Kiki aliwataka wasanii kupenda na kushirikiana bila ya kujali tofauti ya fani zao.Alitoa masikitiko yake kwa baadhi ya wasanii kutokuwa na ushirikiano miongoni mwao, hivyo aliwataka washirikiane.Nasseeb Abdul au Diamond amesema, mengi yamezungumza ila alipongeza ujenzi wa ukumbi mkubwa utakaoingiza watu 20,000, huku akiwapa shavu wasanii kupigiwa au kuoneshwa bure katika Wasafi Radio na Wasafi TV.',' Meneja Masoko na Mawasiliano wa taasisi hiyo, Ngula Cheyo aliyasema hayo jana ikiwa ni siku chache baada ya kuzinduliwa kwa huduma ya mikopo ya viwanja jijini Dar es Salaam, huku akisisitiza kwamba si lazima mkopaji wa viwanja hivyo atoke Dar es Salaam au Kibaha.Cheyo alisema kwamba huduma hiyo ni ya Watanzania wote, ndio sababu taasisi hiyo wamesambaza fomu za kuomba mkopo wa viwanja katika matawi yao mbalimbali, bila kusahau wale wanaoweza kukopa kwa njia ya mtandao.“Nafasi ni chache, maana maombi yetu yanafanyika kwa siku ishirini na yameanza Mei 22 hadi Juni 10, na fomu za maombi zinapatikana matawi yote ya taasisi yetu, bila kusahau kupitia B ank of Africa (BOA), ambapo malilipo ya awali yanaanzia Sh 150,000,” alisema.Alisema kukaa mikoani si sababu ya kushindwa kukopa kiwanja kwa sababu wamefungua matawi katika wilaya na mikoa mbalimbali.Meneja Biashara wa Bayport Financial Services, Thabit Mndeme, alisema ukubwa wa viwanja hivyo unaanzia hatua 15 kwa 16, huku thamani yake ikianzia Sh 1,400,000 bila riba.',' IDADI ya vifo vya waendesha bodaboda nchini vitokanavyo na ajali imepungua katika kipindi cha robo ya kwanza ya mwaka huu kinachoanzia Januari hadi Machi, ikilinganishwa na idadi ya vifo vya bodaboda kwa kipindi kama hicho kwa mwaka jana. Mwanasheria wa Kikosi cha Usalama Barabarani, Afande Deusi Sokoni akizungumza na gazeti hili katika mahojiano maalumu alisema kuwa idadi ya waendeshaji bodaboda waliopoteza maisha kwa mwaka huu ni 73 huku majeruhi wakiwa 121.Alisema, kwa mwaka jana kwa kipindi kama hicho waliopoteza maisha walikuwa ni 108 huku waliojeruhiwa ni 214. Sokoni aliongeza kuwa robo ya kwanza ya mwaka huu kwa upande wa waendesha baiskeli waliopoteza maisha kwa ajali za barabarani walikuwa 23 idadi ambayo ni sawa na ya majeruhi lakini mwaka jana kuanzia Januari hadi Machi, idadi ya waliokufa ilikuwa ni 34 huku waliojeruhiwa wakiwa 30. Alisema pia waendesha mikokoteni tisa wamekufa na wanne wamejeruhiwa huku mwaka jana aliyekufa alikuwa mmoja na 12 walijeruhiwa. Kundi la watembea kwa miguu ambalo ni moja kati ya waathirika wakubwa wa ajali kwa mwaka huu wamekufa 90 na kujeruhiwa 106. Wakati kwa mwaka jana waliokufa walikuwa 163 na kujeruhiwa 179. Kwa upande wa abiria waliokufa kwa ajali kwa mwaka huu ni 108 na 393 wamekumbwa na majeraha mbalimbali wakati kwa mwaka jana waliokufa walikuwa 191 na majeruhi 575.',' Katika uzinduzi huo, rais amesema kuna haja ya kutafuta majawabu kuhusu namna ya kuongeza maghala ya kuhifadhia mazao kwani kadiri kilimo kinavyoboreshwa mazao yanayozalishwa yanakosa pa kuhifadhiwa.Rais Kikwete aliyasema hayo- Dar es Salaam juzi wakati akizindua kampuni hiyo ambayo itakuwa chini ya Mamlaka ya Soko la Bidhaa Tanzania (CMSA). Alisema uzinduzi wa soko hilo ambalo litaanza kufanya kazi rasmi mwezi Mei, mwakani kwa kuanzia na mazao ya korosho, ufuta, alizeti na mpunga ni muendelezo wa jitihada za serikali katika kuleta mageuzi ya kilimo nchini.“Hii ni habari njema kwa wakulima wa Tanzania kwani katika jitihada zetu za kuleta mageuzi ya kilimo zisingefanikiwa kama Tanzania kusingekuwa na soko la uhakika. Mfumo uliopo sasa unawakandamiza wakulima na kuwanufaisha walanguzi,” alisema Rais Kikwete.Alisema pamoja na kuanzishwa kwa sera ya kilimo kwanza, stakabadhi ghalani, uanzishwaji wa benki ya wakulima na vyama vya ushirika kwa ajili ya kuboresha sekta ya kilimo nchini, bado sekta hiyo ilikabiliwa na tatizo la ukosefu wa uhakika wa masoko.Mkurugenzi wa bodi ya wakurugenzi wa TMX, Peter Noni alisema kampuni hiyo ilisajiliwa Agosti, mwaka jana kama kiungo muhimu katika mchakato wa kuanzisha soko la bidhaa nchini.Aliwataja wanahisa waanzilishi wa kampuni hiyo kuwa ni msajili wa hazina, Mfuko wa Pensheni kwa Watumishi wa Umma (PSPF), Benki ya Maendeleo (TIB) na Shirika la Vyama vya Ushirika.',' Mshindi wa mchezo utakaozikutanisha Tottenham huko Rochdale jana atakutana na Sheffield Jumatano au Swansea, ambaye atacheza baada ya suluhu ya jana Jumamosi.Southampton leo itasafiri na kucheza na mshindi kati ya Manchester City na Wigan, wakati Leicester na Chelsea watakutana katika mchezo utakaozikutanisha timu za Ligi Kuu.Rochdale, timu ya chini kabisa iliyobaki katika mashindano hayo, iko mkiani katika Ligi Daraja la Pili, jana ilitarajia kucheza dhidi ya Tottenham. Wigan, iliyopo katika nafasi ya pili katika Ligi Daraja la Pili, itacheza dhidi ya Manchester City leo Jumatatu.Leicester, ambayo iliifunga Sheffield United 1-0 Ijumaa, itakuwa na kibarua kigumu wakati itakapocheza dhidi ya Chelsea, ambao nao walishinda Ijumaa kwa mabao 4-0 dhidi ya Hull City.Ratiba ya robo fainali ya FA Cup Leicester v Chelsea Man United v Brighton Sheffield au Swansea v Rochdale au Tottenham Wigan au Manchester City v Southampton'...]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_data(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "637a2b40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f08653bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "443bf08c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "70206633",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting-up type transforms pipelines\n",
      "Collecting items from           id  \\\n",
      "0        SW0   \n",
      "1        SW1   \n",
      "2       SW10   \n",
      "3      SW100   \n",
      "4     SW1000   \n",
      "...      ...   \n",
      "5146   SW993   \n",
      "5147   SW994   \n",
      "5148   SW996   \n",
      "5149   SW997   \n",
      "5150   SW999   \n",
      "\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      content  \\\n",
      "0      SERIKALI imesema haitakuwa tayari kuona amani na utulivu wa nchi inachezewa huku ikisisitiza uwepo wa umoja kati ya wananchi bila kujali tofauti ya imani, kabila au itikadi yoyote.Hayo yalisemwa na Naibu Waziri wa Mambo ya Ndani ya Nchi, Hamad Yussuf Masauni wakati akifungua semina ya siku mbili iliyofanyika jijini Dar es Salaam ikiwahusisha viongozi wa taasisi za Kiislamu, lengo ikiwa ni kuwakumbusha kuhubiri amani katika sehemu zao.Naibu Waziri amesema mwelekeo na malengo ya Serikali ya Awamu ya Tano ni kukuza maendeleo katika sehemu mbalimbali nchini lengo ikiwa kuinua maisha ya wananc...   \n",
      "1      Mkuu wa Mkoa wa Tabora, Aggrey Mwanri amesitisha likizo za viongozi wote mkoani humo kutekeleza maazimio ya Jukwaa la Fursa za Biashara la mkoa huo.Mwanri ameagiza kuwa, hata kama kuna likizo zimeidhinishwa zifutwe.Amemuagiza Katibu Tawala wa Mkoa huo, Msalika Makungu kuandika barua kwa viongozi kuhusu uamuzi huo na amebainisha kuwa hakushauriwa na mtu, kaamua yeye.“Anayebisha anyooshe mkono, ajifanye angalau anajikuna tu” amesema Mwanri kwenye jukwaa hilo la nane lililomalizika leo.Amewaeleza viongozi wa Tabora kuwa, mambo waliyopanga kuyafanya wakati wa likizo nje ya Tabora wanaweza kuy...   \n",
      "2      SERIKALI imetoa miezi sita kwa taasisi zote za umma ambazo hazitumii mfumo wa GePG katika ukusanyaji wa fedha kufanya hivyo na baada ya hapo itafanya ukaguzi na kuwawajibisha maofi sa masuhuli walioshindwa kutekeleza hilo.Akifungua mkutano wa mwaka wa kwanza wa watumiaji wa mfumo huo jana jijini hapa, Naibu Katibu Mkuu Wizara ya Fedha na Mipango, Dk Hartibu Kazungu alisema ukaguzi huo ambao utaanza kufanyika Juni mwakani baada ya kipindi kilichowekwa kupita ili kuwabaini maofisa wazembe.Alisema, wizara yake itafanya ukaguzi wa ofisi zote za umma ili kubaini kama kuna fedha zinazokusanywa ...   \n",
      "3      KAMPUNI ya mchezo wa kubahatisha ya M-bet imeingia makubaliano ya udhamini na timu ya soka ya Manispaa ya Kinondoni (KMC) kwa miaka mitano wenye thamani ya sh Bilioni 1.Akizungumzia udhamini huo jana baada ya kusaini mkataba huo, Meneja Masoko wa Mbet, Allen Mushi alisema sababu ya kuiunga mkono timu hiyo ni baada ya kuvutiwa na kiwango bora walichokionesha timu hiyo tangu msimu uliopita. Alisema kitendo cha kumaliza ligi katika nafasi ya nne bora sio cha mchezo na kwamba hata wanapokuwa uwanjani hucheza soka la kuvutia tofauti na wengine.“Tumeichagua KMC kwasababu tumevutiwa na mambo men...   \n",
      "4      WATANZANIA wamekumbushwa kusherehekea sikukuu ya Krismasi kwa kuenzi amani, umoja na kulinda tamaduni za nchi ili kupambana na changamoto mbalimbali zinazojitokeza, ikiwemo vitendo vya ushoga na matumizi ya dawa za kulevya.Akizungumza wakati wa kutoa heri ya sikukuu hiyo ya Kuzaliwa Yesu Kristo, Kiongozi wa Waislamu wa madhehebu ya Shia Ithnasheriya, Shehe Hemed Jalala alisema kuzaliwa kwa Yesu kunalenga kuhubiri na kutangaza amani ulimwenguni. Shehe Jalala alisema licha ya Wayahudi kutilia shaka kuzaliwa kwa Yesu, lakini pindi alipozaliwa alitangaza amani kwake na duniani kote akitaka ki...   \n",
      "...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       ...   \n",
      "5146   RAIS John Magufuli ameendelea kung’ara katika siasa za kimataifa mwaka huu, baada ya Taasisi ya Transparency International (TI), kuitaja Tanzania kuwa moja ya nchi zilizofanya vizuri katika masuala ya kupiga vita rushwa.Ripoti ya TI ya mwaka huu, iliyopatikana Dar es Salam juzi, imesema Tanzania imeendelea kufanya vizuri katika vita dhidi ya rushwa kubwa na ndogo, zinazohujumu uchumi na kuumiza wananchi wa kawaida wapatapo huduma.Rais Magufuli amekuwa kinara wa mapambanodhidi ya rushwa tangu aingie madararakani mwaka 2015, ambapo Tanzania imekuwa katika vita dhidi ya uhujumu uchumi na rus...   \n",
      "5147   KAMPENI inayohimiza watafi ti kuandika upya historia ya ukombozi wa nchi na Afrika kwa ujumla imeanza, lengo likiwa ni kuwezesha wanafunzi kusoma historia ambayo haijapotoshwa kwa makusudi.Akiwasilisha Makadirio ya Mapato na Matumizi ya Fedha kwa Mwaka 2019/20 bungeni jana, Waziri wa Habari, Utamaduni, Sanaa na Michezo, Dk Harrison Mwakyembe (pichani) alisema mbali na wizara yake kusimamia hilo, pia itafufua kampeni ya kurejesha fuvu la shujaa Leti Hema wa Wanyaturu na mashujaa wengine lililochukuliwa na Wajerumani wakati wa ukoloni.“Wizara itahimiza kampeni... kuwezesha wanafunzi na vija...   \n",
      "5148   MATUKIO mapya ya malaria kwa kila watu 1,000 katika jamii, yamepungua kwa asilimia 62 kutoka matukio 295 kwa kila watu 1,000 mwaka 2008 hadi matukio 112 kwa kila watu 1,000 .Hiyo ni kwa mujibu wa tafiti zilizofanywa mwaka 2008/2017 na Mpango wa Taifa wa Kudhibiti Malaria (NMCP) kwa kushirikiana na Wizara ya Afya, Maendeleo ya Jamii, Wazee na Watoto. Aidha vifo vinavyosababishwa na malaria, vimepungua kwa asilimia 73 kutoka vifo 33 kwa watu 1,000 katika jamii kwa mwaka 2008 hadi vifo 9 kwa watu 1,000 kwa mwaka 2017.Mhamasishaji Theresia Shirima kutoka NMCP, akizungumza na wanahabari kwenye...   \n",
      "5149   IMEELEZWA kuwa hakuna sheria yoyote inayokataza taarifa za Tume ya Haki za Binadamu na Utawala Bora kujadiliwa Bungeni endapo mbunge ataona kuna jambo la kuibua kutoka kwenye taarifa iliyoibuliwa.Akijibu swali la mbunge wa Mgogoni Dk Suleiman Ally Yusuf (CUF), kwa niaba ya Waziri wa Katiba na Sheria, Naibu Waziri wa Elimu, Sayansi na Teknolojia, William ole Nasha alisema kwamba tume imekuwa ikitimiza wajibu wake na ripoti zake ziwazi. Katika swali lake la msingi, mbunge huyo alikuwa anataka kujua kwa nini ripoti za tume hiyo haziwekwi wazi kwa umma na kama serikali haioni kuwa wakati umef...   \n",
      "5150   Akizungumza mara baada ya kutiwa saini kwa makubaliano hayo jana jioni Waziri wa Nchi Ofisi ya Waziri Mkuu Tawala za Mikoa na Serikali za Mitaa, Hawa Ghasia, alisema uwekezaji huo unatarajiwa kuleta manufaa kwa shirika hilo kwani uwekezaji wake pia utasaidia kutoa elimu kwa vitendo juu ya ufugaji kwa kada mbalimbali.Alisema miaka ya nyuma shirika hilo lilikuwa likisifika kwa ufugaji wa kuku kabla ya kusitisha shughuli hizo kutokana na uwepo wa sababu mbalimbali na kusababisha shirika hilo kukosa mapato yaliyokuwa yakitokana na uuzaji wa kuku na mayai.Mkurugenzi wa Shirika la Elimu Kibaha,...   \n",
      "\n",
      "      category  \n",
      "0      Kitaifa  \n",
      "1     Biashara  \n",
      "2      Kitaifa  \n",
      "3      michezo  \n",
      "4      Kitaifa  \n",
      "...        ...  \n",
      "5146   Kitaifa  \n",
      "5147   Kitaifa  \n",
      "5148   Kitaifa  \n",
      "5149   Kitaifa  \n",
      "5150  Biashara  \n",
      "\n",
      "[5151 rows x 3 columns]\n",
      "Found 5151 items\n",
      "2 datasets of sizes 4636,515\n",
      "Setting up Pipeline: Tokenizer -> Numericalize\n",
      "\n",
      "Building one sample\n",
      "  Pipeline: Tokenizer -> Numericalize\n",
      "    starting from\n",
      "      .Jaji Mkuu wa Tanzania, Profesa Ibrahim Juma amesema kuwa licha ya idara ya mahakama nchini kuendelea kufanya kazi nzuri bado inakabiliwa na upungufu wa watumishi.Akizungumza jijini Dar es Salaam wakati wa kilele cha maadhimisho ya siku ya sheria nchini ikiwa ni mwanzo wa kuanza kwa shughuli za mahakama, Jaji Mkuu amesema kuwa mahitaji ya idara hiyo ni  watumishi 10, 351 lakini waliopo sasa ni 5, 947 tu.Jaji Mkuu ameongeza kuwa idadi ya watumishi wa mahakama imekua ikiendelea kupungua mwaka hadi hadi mwaka, ambapo kuanzia mwezi Januari hadi Disemba mwaka 2019 watumishi 258 waliondoka kazini kwa sababu mbalimbali ikiwa ni pamoja na kustaafu, kuhama na vifo.Kufuatia hali hiyo, Jaji Mkuu Profesa Ibrahim Juma ameiomba Serikali kuajiri watumishi zaidi wa idara ya mahakama ili waweze kufanya kazi katika mahakama mbalimbali zinazoanzishwa hapa nchini na hivyo kutoa haki kwa wakati kwa wananchi.Kaulimbiu ya siku ya mahakama kwa mwaka huu ni Uwekezaji na Biashara: Wajibu wa Mahakama na Wadau kuweka Mazingira Wezeshi ya Uwekezaji.\n",
      "    applying Tokenizer gives\n",
      "      ['xxbos', '.jaji', 'xxmaj', 'mkuu', 'wa', 'xxmaj', 'tanzania', ',', 'xxmaj', 'profesa', 'xxmaj', 'ibrahim', 'xxmaj', 'juma', 'amesema', 'kuwa', 'licha', 'ya', 'idara', 'ya', 'mahakama', 'nchini', 'kuendelea', 'kufanya', 'kazi', 'nzuri', 'bado', 'inakabiliwa', 'na', 'upungufu', 'wa', '\\xa0', 'watumishi.akizungumza', 'jijini', 'xxmaj', 'dar', 'es', 'xxmaj', 'salaam', 'wakati', 'wa', 'kilele', 'cha', 'maadhimisho', 'ya', 'siku', 'ya', 'sheria', 'nchini', 'ikiwa', 'ni', 'mwanzo', 'wa', 'kuanza', 'kwa', 'shughuli', 'za', 'mahakama', ',', 'xxmaj', 'jaji', 'xxmaj', 'mkuu', 'amesema', 'kuwa', 'mahitaji', 'ya', 'idara', 'hiyo', 'ni', 'watumishi', '10', ',', '351', 'lakini', 'waliopo', 'sasa', 'ni', '5', ',', '947', 'tu.jaji', 'xxmaj', 'mkuu', 'ameongeza', 'kuwa', 'idadi', 'ya', 'watumishi', 'wa', 'mahakama', 'imekua', 'ikiendelea', 'kupungua', 'mwaka', 'hadi', 'hadi', 'mwaka', ',', 'ambapo', 'kuanzia', 'mwezi', 'xxmaj', 'januari', 'hadi', 'xxmaj', 'disemba', 'mwaka', '2019', '\\xa0', 'watumishi', '258', 'waliondoka', 'kazini', 'kwa', 'sababu', 'mbalimbali', 'ikiwa', 'ni', 'pamoja', 'na', 'kustaafu', ',', 'kuhama', 'na', 'vifo.kufuatia', 'hali', 'hiyo', ',', 'xxmaj', 'jaji', 'xxmaj', 'mkuu', 'xxmaj', 'profesa', 'xxmaj', 'ibrahim', 'xxmaj', 'juma', 'ameiomba', 'xxmaj', 'serikali', 'kuajiri', 'watumishi', 'zaidi', 'wa', 'idara', 'ya', 'mahakama', 'ili', 'waweze', 'kufanya', 'kazi', 'katika', 'mahakama', 'mbalimbali', 'zinazoanzishwa', 'hapa', 'nchini', 'na', 'hivyo', 'kutoa', 'haki', 'kwa', 'wakati', 'kwa', 'wananchi.kaulimbiu', 'ya', 'siku', 'ya', 'mahakama', 'kwa', 'mwaka', 'huu', 'ni', 'xxmaj', 'uwekezaji', 'na', 'xxmaj', 'biashara', ':', 'xxmaj', 'wajibu', 'wa', 'xxmaj', 'mahakama', 'na', 'xxmaj', 'wadau', 'kuweka', 'xxmaj', 'mazingira', 'xxmaj', 'wezeshi', 'ya', 'xxmaj', 'uwekezaji', '.']\n",
      "    applying Numericalize gives\n",
      "      TensorText of size 198\n",
      "\n",
      "Final sample: (TensorText([    2,     0,     8,    49,    12,     8,    33,     9,     8,   495,     8,  1429,     8,   619,   101,    20,   365,    10,   684,    10,   272,    40,   282,    60,    52,   348,   235,\n",
      "             3957,    11,  1091,    12,   912,     0,   174,     8,    69,    71,     8,    90,    42,    12,  2733,    25,  1387,    10,   106,    10,   131,    40,   128,    17,  1130,    12,   237,\n",
      "               13,   265,    16,   272,     9,     8,  1273,     8,    49,   101,    20,   563,    10,   684,    21,    17,   453,   254,     9,     0,    44,  1388,    46,    17,   581,     9,     0,\n",
      "                0,     8,    49,  4632,    20,   357,    10,   453,    12,   272,  6800,  2793,  1909,    27,    68,    68,    27,     9,    98,   270,   206,     8,   375,    68,     8,  5688,    27,\n",
      "              379,   912,   453, 17824,  5264,  2316,    13,   145,    67,   128,    17,    54,    11,  2994,     9,  3842,    11,     0,   156,    21,     9,     8,  1273,     8,    49,     8,   495,\n",
      "                8,  1429,     8,   619,  6169,     8,    29,  2218,   453,    51,    12,   684,    10,   272,    30,   718,    60,    52,    15,   272,    67,     0,   171,    40,    11,    41,   108,\n",
      "              428,    13,    42,    13,     0,    10,   106,    10,   272,    13,    27,    59,    17,     8,   203,    11,     8,    86,   440,     8,   799,    12,     8,   272,    11,     8,   262,\n",
      "              347,     8,   209,     8,  3328,    10,     8,   203,    14]),)\n",
      "\n",
      "\n",
      "Collecting items from           id  \\\n",
      "0        SW0   \n",
      "1        SW1   \n",
      "2       SW10   \n",
      "3      SW100   \n",
      "4     SW1000   \n",
      "...      ...   \n",
      "5146   SW993   \n",
      "5147   SW994   \n",
      "5148   SW996   \n",
      "5149   SW997   \n",
      "5150   SW999   \n",
      "\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      content  \\\n",
      "0      SERIKALI imesema haitakuwa tayari kuona amani na utulivu wa nchi inachezewa huku ikisisitiza uwepo wa umoja kati ya wananchi bila kujali tofauti ya imani, kabila au itikadi yoyote.Hayo yalisemwa na Naibu Waziri wa Mambo ya Ndani ya Nchi, Hamad Yussuf Masauni wakati akifungua semina ya siku mbili iliyofanyika jijini Dar es Salaam ikiwahusisha viongozi wa taasisi za Kiislamu, lengo ikiwa ni kuwakumbusha kuhubiri amani katika sehemu zao.Naibu Waziri amesema mwelekeo na malengo ya Serikali ya Awamu ya Tano ni kukuza maendeleo katika sehemu mbalimbali nchini lengo ikiwa kuinua maisha ya wananc...   \n",
      "1      Mkuu wa Mkoa wa Tabora, Aggrey Mwanri amesitisha likizo za viongozi wote mkoani humo kutekeleza maazimio ya Jukwaa la Fursa za Biashara la mkoa huo.Mwanri ameagiza kuwa, hata kama kuna likizo zimeidhinishwa zifutwe.Amemuagiza Katibu Tawala wa Mkoa huo, Msalika Makungu kuandika barua kwa viongozi kuhusu uamuzi huo na amebainisha kuwa hakushauriwa na mtu, kaamua yeye.“Anayebisha anyooshe mkono, ajifanye angalau anajikuna tu” amesema Mwanri kwenye jukwaa hilo la nane lililomalizika leo.Amewaeleza viongozi wa Tabora kuwa, mambo waliyopanga kuyafanya wakati wa likizo nje ya Tabora wanaweza kuy...   \n",
      "2      SERIKALI imetoa miezi sita kwa taasisi zote za umma ambazo hazitumii mfumo wa GePG katika ukusanyaji wa fedha kufanya hivyo na baada ya hapo itafanya ukaguzi na kuwawajibisha maofi sa masuhuli walioshindwa kutekeleza hilo.Akifungua mkutano wa mwaka wa kwanza wa watumiaji wa mfumo huo jana jijini hapa, Naibu Katibu Mkuu Wizara ya Fedha na Mipango, Dk Hartibu Kazungu alisema ukaguzi huo ambao utaanza kufanyika Juni mwakani baada ya kipindi kilichowekwa kupita ili kuwabaini maofisa wazembe.Alisema, wizara yake itafanya ukaguzi wa ofisi zote za umma ili kubaini kama kuna fedha zinazokusanywa ...   \n",
      "3      KAMPUNI ya mchezo wa kubahatisha ya M-bet imeingia makubaliano ya udhamini na timu ya soka ya Manispaa ya Kinondoni (KMC) kwa miaka mitano wenye thamani ya sh Bilioni 1.Akizungumzia udhamini huo jana baada ya kusaini mkataba huo, Meneja Masoko wa Mbet, Allen Mushi alisema sababu ya kuiunga mkono timu hiyo ni baada ya kuvutiwa na kiwango bora walichokionesha timu hiyo tangu msimu uliopita. Alisema kitendo cha kumaliza ligi katika nafasi ya nne bora sio cha mchezo na kwamba hata wanapokuwa uwanjani hucheza soka la kuvutia tofauti na wengine.“Tumeichagua KMC kwasababu tumevutiwa na mambo men...   \n",
      "4      WATANZANIA wamekumbushwa kusherehekea sikukuu ya Krismasi kwa kuenzi amani, umoja na kulinda tamaduni za nchi ili kupambana na changamoto mbalimbali zinazojitokeza, ikiwemo vitendo vya ushoga na matumizi ya dawa za kulevya.Akizungumza wakati wa kutoa heri ya sikukuu hiyo ya Kuzaliwa Yesu Kristo, Kiongozi wa Waislamu wa madhehebu ya Shia Ithnasheriya, Shehe Hemed Jalala alisema kuzaliwa kwa Yesu kunalenga kuhubiri na kutangaza amani ulimwenguni. Shehe Jalala alisema licha ya Wayahudi kutilia shaka kuzaliwa kwa Yesu, lakini pindi alipozaliwa alitangaza amani kwake na duniani kote akitaka ki...   \n",
      "...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       ...   \n",
      "5146   RAIS John Magufuli ameendelea kung’ara katika siasa za kimataifa mwaka huu, baada ya Taasisi ya Transparency International (TI), kuitaja Tanzania kuwa moja ya nchi zilizofanya vizuri katika masuala ya kupiga vita rushwa.Ripoti ya TI ya mwaka huu, iliyopatikana Dar es Salam juzi, imesema Tanzania imeendelea kufanya vizuri katika vita dhidi ya rushwa kubwa na ndogo, zinazohujumu uchumi na kuumiza wananchi wa kawaida wapatapo huduma.Rais Magufuli amekuwa kinara wa mapambanodhidi ya rushwa tangu aingie madararakani mwaka 2015, ambapo Tanzania imekuwa katika vita dhidi ya uhujumu uchumi na rus...   \n",
      "5147   KAMPENI inayohimiza watafi ti kuandika upya historia ya ukombozi wa nchi na Afrika kwa ujumla imeanza, lengo likiwa ni kuwezesha wanafunzi kusoma historia ambayo haijapotoshwa kwa makusudi.Akiwasilisha Makadirio ya Mapato na Matumizi ya Fedha kwa Mwaka 2019/20 bungeni jana, Waziri wa Habari, Utamaduni, Sanaa na Michezo, Dk Harrison Mwakyembe (pichani) alisema mbali na wizara yake kusimamia hilo, pia itafufua kampeni ya kurejesha fuvu la shujaa Leti Hema wa Wanyaturu na mashujaa wengine lililochukuliwa na Wajerumani wakati wa ukoloni.“Wizara itahimiza kampeni... kuwezesha wanafunzi na vija...   \n",
      "5148   MATUKIO mapya ya malaria kwa kila watu 1,000 katika jamii, yamepungua kwa asilimia 62 kutoka matukio 295 kwa kila watu 1,000 mwaka 2008 hadi matukio 112 kwa kila watu 1,000 .Hiyo ni kwa mujibu wa tafiti zilizofanywa mwaka 2008/2017 na Mpango wa Taifa wa Kudhibiti Malaria (NMCP) kwa kushirikiana na Wizara ya Afya, Maendeleo ya Jamii, Wazee na Watoto. Aidha vifo vinavyosababishwa na malaria, vimepungua kwa asilimia 73 kutoka vifo 33 kwa watu 1,000 katika jamii kwa mwaka 2008 hadi vifo 9 kwa watu 1,000 kwa mwaka 2017.Mhamasishaji Theresia Shirima kutoka NMCP, akizungumza na wanahabari kwenye...   \n",
      "5149   IMEELEZWA kuwa hakuna sheria yoyote inayokataza taarifa za Tume ya Haki za Binadamu na Utawala Bora kujadiliwa Bungeni endapo mbunge ataona kuna jambo la kuibua kutoka kwenye taarifa iliyoibuliwa.Akijibu swali la mbunge wa Mgogoni Dk Suleiman Ally Yusuf (CUF), kwa niaba ya Waziri wa Katiba na Sheria, Naibu Waziri wa Elimu, Sayansi na Teknolojia, William ole Nasha alisema kwamba tume imekuwa ikitimiza wajibu wake na ripoti zake ziwazi. Katika swali lake la msingi, mbunge huyo alikuwa anataka kujua kwa nini ripoti za tume hiyo haziwekwi wazi kwa umma na kama serikali haioni kuwa wakati umef...   \n",
      "5150   Akizungumza mara baada ya kutiwa saini kwa makubaliano hayo jana jioni Waziri wa Nchi Ofisi ya Waziri Mkuu Tawala za Mikoa na Serikali za Mitaa, Hawa Ghasia, alisema uwekezaji huo unatarajiwa kuleta manufaa kwa shirika hilo kwani uwekezaji wake pia utasaidia kutoa elimu kwa vitendo juu ya ufugaji kwa kada mbalimbali.Alisema miaka ya nyuma shirika hilo lilikuwa likisifika kwa ufugaji wa kuku kabla ya kusitisha shughuli hizo kutokana na uwepo wa sababu mbalimbali na kusababisha shirika hilo kukosa mapato yaliyokuwa yakitokana na uuzaji wa kuku na mayai.Mkurugenzi wa Shirika la Elimu Kibaha,...   \n",
      "\n",
      "      category  \n",
      "0      Kitaifa  \n",
      "1     Biashara  \n",
      "2      Kitaifa  \n",
      "3      michezo  \n",
      "4      Kitaifa  \n",
      "...        ...  \n",
      "5146   Kitaifa  \n",
      "5147   Kitaifa  \n",
      "5148   Kitaifa  \n",
      "5149   Kitaifa  \n",
      "5150  Biashara  \n",
      "\n",
      "[5151 rows x 3 columns]\n",
      "Found 5151 items\n",
      "2 datasets of sizes 4636,515\n",
      "Setting up Pipeline: Tokenizer -> Numericalize\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up after_item: Pipeline: ToTensor\n",
      "Setting up before_batch: Pipeline: \n",
      "Setting up after_batch: Pipeline: \n",
      "\n",
      "Building one batch\n",
      "Applying item_tfms to the first sample:\n",
      "  Pipeline: ToTensor\n",
      "    starting from\n",
      "      (TensorText of size 198)\n",
      "    applying ToTensor gives\n",
      "      (TensorText of size 198)\n",
      "\n",
      "Adding the next 3 samples\n",
      "\n",
      "No before_batch transform to apply\n",
      "\n",
      "Collating items in a batch\n",
      "Error! It's not possible to collate your items in a batch\n",
      "Could not collate the 0-th members of your tuples because got the following shapes\n",
      "torch.Size([198]),torch.Size([390]),torch.Size([172]),torch.Size([824])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error when trying to collate the data into batches with fa_collate, at least two tensors in the batch are not the same size.\n\nMismatch found on axis 0 of the batch and is of type `TensorText`:\n\tItem at index 0 has shape: torch.Size([198])\n\tItem at index 1 has shape: torch.Size([390])\n\nPlease include a transform in `after_item` that ensures all data of type TensorText is the same size",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[1;32mIn [17]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mdb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msummary\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\fastai\\data\\block.py:237\u001b[0m, in \u001b[0;36msummary\u001b[1;34m(self, source, bs, show_batch, **kwargs)\u001b[0m\n\u001b[0;32m    235\u001b[0m     why \u001b[38;5;241m=\u001b[39m _find_fail_collate(s)\n\u001b[0;32m    236\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMake sure all parts of your samples are tensors of the same size\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m why \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m why)\n\u001b[1;32m--> 237\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m    239\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m([f \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m dls\u001b[38;5;241m.\u001b[39mtrain\u001b[38;5;241m.\u001b[39mafter_batch\u001b[38;5;241m.\u001b[39mfs \u001b[38;5;28;01mif\u001b[39;00m f\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnoop\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m!=\u001b[39m\u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    240\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mApplying batch_tfms to the batch built\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\fastai\\data\\block.py:231\u001b[0m, in \u001b[0;36msummary\u001b[1;34m(self, source, bs, show_batch, **kwargs)\u001b[0m\n\u001b[0;32m    229\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mCollating items in a batch\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    230\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 231\u001b[0m     b \u001b[38;5;241m=\u001b[39m \u001b[43mdls\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    232\u001b[0m     b \u001b[38;5;241m=\u001b[39m retain_types(b, s[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m is_listy(s) \u001b[38;5;28;01melse\u001b[39;00m s)\n\u001b[0;32m    233\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\fastai\\data\\load.py:166\u001b[0m, in \u001b[0;36mDataLoader.create_batch\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    164\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m: \u001b[38;5;28;01mreturn\u001b[39;00m (fa_collate,fa_convert)[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprebatched](b)\n\u001b[0;32m    165\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e: \n\u001b[1;32m--> 166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprebatched: \u001b[43mcollate_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    167\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\fastai\\data\\load.py:164\u001b[0m, in \u001b[0;36mDataLoader.create_batch\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    163\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_batch\u001b[39m(\u001b[38;5;28mself\u001b[39m, b): \n\u001b[1;32m--> 164\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m: \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m(\u001b[49m\u001b[43mfa_collate\u001b[49m\u001b[43m,\u001b[49m\u001b[43mfa_convert\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprebatched\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    165\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e: \n\u001b[0;32m    166\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprebatched: collate_error(e,b)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\fastai\\data\\load.py:52\u001b[0m, in \u001b[0;36mfa_collate\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA replacement for PyTorch `default_collate` which maintains types and handles `Sequence`s\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     50\u001b[0m b \u001b[38;5;241m=\u001b[39m t[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (default_collate(t) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(b, _collate_types)\n\u001b[1;32m---> 52\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(t[\u001b[38;5;241m0\u001b[39m])([fa_collate(s) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mt)]) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(b, Sequence)\n\u001b[0;32m     53\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m default_collate(t))\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\fastai\\data\\load.py:52\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA replacement for PyTorch `default_collate` which maintains types and handles `Sequence`s\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     50\u001b[0m b \u001b[38;5;241m=\u001b[39m t[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (default_collate(t) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(b, _collate_types)\n\u001b[1;32m---> 52\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(t[\u001b[38;5;241m0\u001b[39m])([\u001b[43mfa_collate\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mt)]) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(b, Sequence)\n\u001b[0;32m     53\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m default_collate(t))\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\fastai\\data\\load.py:51\u001b[0m, in \u001b[0;36mfa_collate\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA replacement for PyTorch `default_collate` which maintains types and handles `Sequence`s\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     50\u001b[0m b \u001b[38;5;241m=\u001b[39m t[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m---> 51\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[43mdefault_collate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(b, _collate_types)\n\u001b[0;32m     52\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(t[\u001b[38;5;241m0\u001b[39m])([fa_collate(s) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mt)]) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(b, Sequence)\n\u001b[0;32m     53\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m default_collate(t))\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\utils\\data\\_utils\\collate.py:265\u001b[0m, in \u001b[0;36mdefault_collate\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m    204\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdefault_collate\u001b[39m(batch):\n\u001b[0;32m    205\u001b[0m     \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;124;03m        Function that takes in a batch of data and puts the elements within the batch\u001b[39;00m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;124;03m        into a tensor with an additional outer dimension - batch size. The exact output type can be\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    263\u001b[0m \u001b[38;5;124;03m            >>> default_collate(batch)  # Handle `CustomType` automatically\u001b[39;00m\n\u001b[0;32m    264\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 265\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdefault_collate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\utils\\data\\_utils\\collate.py:123\u001b[0m, in \u001b[0;36mcollate\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m collate_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[0;32m    122\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, collate_type):\n\u001b[1;32m--> 123\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate_fn_map\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcollate_type\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    125\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, collections\u001b[38;5;241m.\u001b[39mabc\u001b[38;5;241m.\u001b[39mMapping):\n\u001b[0;32m    126\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\utils\\data\\_utils\\collate.py:162\u001b[0m, in \u001b[0;36mcollate_tensor_fn\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    160\u001b[0m     storage \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39m_typed_storage()\u001b[38;5;241m.\u001b[39m_new_shared(numel, device\u001b[38;5;241m=\u001b[39melem\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m    161\u001b[0m     out \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39mnew(storage)\u001b[38;5;241m.\u001b[39mresize_(\u001b[38;5;28mlen\u001b[39m(batch), \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mlist\u001b[39m(elem\u001b[38;5;241m.\u001b[39msize()))\n\u001b[1;32m--> 162\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\fastai\\torch_core.py:382\u001b[0m, in \u001b[0;36mTensorBase.__torch_function__\u001b[1;34m(cls, func, types, args, kwargs)\u001b[0m\n\u001b[0;32m    380\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mdebug \u001b[38;5;129;01mand\u001b[39;00m func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__str__\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__repr__\u001b[39m\u001b[38;5;124m'\u001b[39m): \u001b[38;5;28mprint\u001b[39m(func, types, args, kwargs)\n\u001b[0;32m    381\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _torch_handled(args, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_opt, func): types \u001b[38;5;241m=\u001b[39m (torch\u001b[38;5;241m.\u001b[39mTensor,)\n\u001b[1;32m--> 382\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__torch_function__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtypes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mifnone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    383\u001b[0m dict_objs \u001b[38;5;241m=\u001b[39m _find_args(args) \u001b[38;5;28;01mif\u001b[39;00m args \u001b[38;5;28;01melse\u001b[39;00m _find_args(\u001b[38;5;28mlist\u001b[39m(kwargs\u001b[38;5;241m.\u001b[39mvalues()))\n\u001b[0;32m    384\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(\u001b[38;5;28mtype\u001b[39m(res),TensorBase) \u001b[38;5;129;01mand\u001b[39;00m dict_objs: res\u001b[38;5;241m.\u001b[39mset_meta(dict_objs[\u001b[38;5;241m0\u001b[39m],as_copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\_tensor.py:1295\u001b[0m, in \u001b[0;36mTensor.__torch_function__\u001b[1;34m(cls, func, types, args, kwargs)\u001b[0m\n\u001b[0;32m   1292\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[0;32m   1294\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _C\u001b[38;5;241m.\u001b[39mDisableTorchFunctionSubclass():\n\u001b[1;32m-> 1295\u001b[0m     ret \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1296\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m func \u001b[38;5;129;01min\u001b[39;00m get_default_nowrap_functions():\n\u001b[0;32m   1297\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m ret\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Error when trying to collate the data into batches with fa_collate, at least two tensors in the batch are not the same size.\n\nMismatch found on axis 0 of the batch and is of type `TensorText`:\n\tItem at index 0 has shape: torch.Size([198])\n\tItem at index 1 has shape: torch.Size([390])\n\nPlease include a transform in `after_item` that ensures all data of type TensorText is the same size"
     ]
    }
   ],
   "source": [
    "db.summary(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "572f8749",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83029954",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Index(['id', 'content', 'category'], dtype='object'),\n",
       " Index(['swahili_id', 'content'], dtype='object'))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns,test.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f6e56f",
   "metadata": {},
   "source": [
    "### Read the entire texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "id": "8e1acbc1",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' SERIKALI imetoa miezi sita kwa taasisi zote za umma ambazo hazitumii mfumo wa GePG katika ukusanyaji wa fedha kufanya hivyo na baada ya hapo itafanya ukaguzi na kuwawajibisha maofi sa masuhuli walioshindwa kutekeleza hilo.Akifungua mkutano wa mwaka wa kwanza wa watumiaji wa mfumo huo jana jijini hapa, Naibu Katibu Mkuu Wizara ya Fedha na Mipango, Dk Hartibu Kazungu alisema ukaguzi huo ambao utaanza kufanyika Juni mwakani baada ya kipindi kilichowekwa kupita ili kuwabaini maofisa wazembe.Alisema, wizara yake itafanya ukaguzi wa ofisi zote za umma ili kubaini kama kuna fedha zinazokusanywa bila kupitia kwenye mfumo wa GePG na kuwa ofisi itakayobainika kutotumia mfumo huo maofisa masuhuli watawajibishwa kwa mujibu wa sheria. Mnifikishie ujumbe wa kuzikumbusha taasisi ambazo hazijaanza kutumia mfumo wa ukusanyaji mapato wa GePG kufanya hivyo, kwani tunataka hadi kufikia Juni 30, mwaka 2019, kusiwe na fedha yoyote kwenye taasisi ya umma ambayo inakusanywa nje ya mfumo huu,  alisema.Hata hivyo, alisisitiza kuwa utaratibu wa malipo kupitia GePG unawapa fursa ya kuwa na njia nyingi za kulipia zikiwa na lengo la kuwapa walipaji wa huduma za serikali utaratibu rafiki na machaguo mengi ya njia za kufanya malipo. Nimepewa taarifa kuwa takribani benki kumi na moja (11) na mitandao sita ya malipo kwa njia ya simu za kiganjani zimeshaunganishwa na GePG.  Hii ni kuthibitisha namna mfumo wa GePG umekuwa na fursa nyingi za ulipaji, hivyo kuweka mazingira kwa umma katika kufanya malipo hivyo kuondoa urasimu na ucheleweshaji usiofaa. Dk Kazungu alisema kuwa mfumo huo ulianzishwa ili kuongeza uwazi na udhibiti wa fedha za umma, kuboresha na kurahisisha namna ya kulipia huduma za umma pamoja na kupunguza gharama zinazoambatana na ukusanyaji wa fedha za umma.Akizungumza na waandishi wa habari baada ya ufunguzi huo Mkurugenzi wa mfumo kutoka wizara hiyo, John Sausi alisema changamoto wanayokuta nayo katika utekelezaji wa mfumo huo uelewa mdogo wa namna ya kutumia.Katika utekelezaji wa mfumo huo tuna changamoto moja kubwa ambayo ni uelewa wa watumiaji wa mfumo kushindwa kutumia vyema mfumo huu vizuri hivyo kulazimika kutumia watu wa operesheni kwa ajili ya kurudia utoaji wa elimu.Alisema changamoto nyingine ni ukosekanaji kwa mtandao katika maeneo ya vijijini hivyo mfumo kushindwa kufanya kazi.  Changamoto ya mtandao tunaangalia namna ya kukabiliana nayo mwaka mzima tangu kuanza kwa mfumo huu, lakini kama wizara tunaamini haiwezi kutusumbua,  alisema. Aidha, Sausi alisema tangu kuanza kutumika kwa mufmo huo hapa nchini hadi sasa taasisi 326 tayari zinatumia mfumo huo katika kutoa huduma.'"
      ]
     },
     "execution_count": 540,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.iloc[2,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "8e9059ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6439"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clean_row(x):\n",
    "    x = ''.join(x.split('\\'')).strip('[]')\n",
    "    return re.sub(r\"[^\\x00-\\x7F]\", ' ', x)\n",
    "    \n",
    "txts = L(\n",
    "    list(train['content'].apply(clean_row).values) + \n",
    "#     list(train.loc[:,'content'].values) + \n",
    "#     list(test.loc[:,'content'].values) \n",
    "    list(test['content'].apply(clean_row).values)\n",
    ")\n",
    "len(txts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2da7780",
   "metadata": {},
   "source": [
    "### Concatenate into one big stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "d8564add",
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy = WordTokenizer()\n",
    "tkn = Tokenizer(spacy)\n",
    "\n",
    "toks200 = txts[:200].map(tkn)\n",
    "\n",
    "num = Numericalize()\n",
    "num.setup(toks200)\n",
    "\n",
    "nums200 = toks200.map(num)\n",
    "\n",
    "dl = LMDataLoader(nums200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "id": "7c89571a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([64, 72]), torch.Size([64, 72]))"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x,y = first(dl)\n",
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "id": "931aef40",
   "metadata": {},
   "outputs": [],
   "source": [
    "TextBlock.from_df??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "id": "1f185a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['content_cleaned'] = train['content'].apply(clean_row)\n",
    "test['content_cleaned'] = test['content'].apply(clean_row)\n",
    "\n",
    "train.to_csv('train/Train.csv')\n",
    "test.to_csv('test/Test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "id": "33108fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in train.index:\n",
    "    filename = f'train/{train.loc[i,\"id\"]}.txt'\n",
    "    with open(filename,'w') as f:\n",
    "        f.write(train.loc[i,'content_cleaned'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "id": "f985b012",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in test.index:\n",
    "    filename = f'test/{test.loc[i,\"swahili_id\"]}.txt'\n",
    "    with open(filename,'w') as f:\n",
    "        f.write(test.loc[i,'content_cleaned'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc291332",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "id": "a6ff59d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#2) [Path('test/Test.csv'),Path('train/Train.csv')]"
      ]
     },
     "execution_count": 381,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_files('',extensions=['.csv'],folders=['train','test',],recurse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "id": "864ffa55",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_text_files??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "id": "bfd0d62a",
   "metadata": {},
   "outputs": [],
   "source": [
    "partial??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "id": "142342ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "TextBlock??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "id": "1c4de79b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<fastai.text.data.TextBlock at 0x280fee20f10>"
      ]
     },
     "execution_count": 407,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TextBlock.from_df('gh',is_lm=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b29e5b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "id": "bf685d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "train[:4].to_csv('train/Train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "948e00f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "id": "de232686",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Path('.')"
      ]
     },
     "execution_count": 455,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = Path('')\n",
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "id": "a192f554",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Due to IPython and Windows limitation, python multiprocessing isn't available now.\n",
      "So `n_workers` has to be changed to 0 to avoid getting stuck\n"
     ]
    }
   ],
   "source": [
    "get_news = partial(get_text_files, folders=['train','test'])\n",
    "\n",
    "db = DataBlock(\n",
    "    blocks = TextBlock.from_folder(path,is_lm=True),\n",
    "    get_items = get_news,\n",
    "    splitter = RandomSplitter(0.1),\n",
    ")\n",
    "\n",
    "dls_lm = db.dataloaders(path, path=path, bs=128, seq_len=80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "id": "5d5e215a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>text_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xxbos xxmaj wamewahakikishia kuwa hivi sasa ushiriki wao unahitajika kwa maendeleo ya kiuchumi na kwa faida ya wananchi wa nchi hizo.rais xxmaj jakaya xxmaj kikwete alisema sekta ya biashara , wako tayari kufanya kazi sehemu xxunk kupata fedha . xxmaj alisema huu ni wakati wa watendaji katika nchi hizo , kufanya kazi kibiashara na kuachana na tabia ya urasimu , ambayo imekuwa xxunk wawekezaji . xxmaj kama tutafanya kazi kibiashara , miradi ya miundombinu itaweza kukamilika katika kipindi cha muda</td>\n",
       "      <td>xxmaj wamewahakikishia kuwa hivi sasa ushiriki wao unahitajika kwa maendeleo ya kiuchumi na kwa faida ya wananchi wa nchi hizo.rais xxmaj jakaya xxmaj kikwete alisema sekta ya biashara , wako tayari kufanya kazi sehemu xxunk kupata fedha . xxmaj alisema huu ni wakati wa watendaji katika nchi hizo , kufanya kazi kibiashara na kuachana na tabia ya urasimu , ambayo imekuwa xxunk wawekezaji . xxmaj kama tutafanya kazi kibiashara , miradi ya miundombinu itaweza kukamilika katika kipindi cha muda mfupi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lengo letu ni moja kuijenga nchi hii , alisema xxmaj mchange . xxmaj aidha alisema endapo xxmaj muswada huo xxunk na xxmaj rais na kuwa sheria , mapendekezo yake kwa serikali ni kwamba xxunk kubadili vipengele vilivyomo ndani , bali inapaswa iende mbali na kuwachukulia hatua watu wote watakaokwenda kinyume na sheria husika . xxbos xxup wakazi wa xxmaj mkoa wa xxmaj kagera hususani xxmaj bukoba xxmaj mjini pamoja na wilaya za xxmaj misenyi , xxmaj kyerwa na xxmaj karagwe</td>\n",
       "      <td>letu ni moja kuijenga nchi hii , alisema xxmaj mchange . xxmaj aidha alisema endapo xxmaj muswada huo xxunk na xxmaj rais na kuwa sheria , mapendekezo yake kwa serikali ni kwamba xxunk kubadili vipengele vilivyomo ndani , bali inapaswa iende mbali na kuwachukulia hatua watu wote watakaokwenda kinyume na sheria husika . xxbos xxup wakazi wa xxmaj mkoa wa xxmaj kagera hususani xxmaj bukoba xxmaj mjini pamoja na wilaya za xxmaj misenyi , xxmaj kyerwa na xxmaj karagwe ,</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dls_lm.show_batch(max_n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 648,
   "id": "dabdc3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLLM10(Module):\n",
    "    def __init__(self, vocab_sz, n_hidden,n_layers,p):\n",
    "        self.i_h = nn.Embedding(vocab_sz,n_hidden)\n",
    "        self.rnn = nn.LSTM(n_hidden,n_hidden, n_layers, batch_first=True)\n",
    "        self.drop = nn.Dropout(p) # Dropout\n",
    "        self.h_o = nn.Linear(n_hidden,vocab_sz)\n",
    "        self.h_o.weight = self.i_h.weight # Weight Tying\n",
    "        self.h = [torch.zeros(n_layers, bs, n_hidden) for _ in range(2)] # Some changes here\n",
    "    \n",
    "    def forward(self,x):\n",
    "        res,h = self.rnn(self.i_h(x), self.h)\n",
    "        out = self.drop(res)\n",
    "        self.h = [h_.detach() for h_ in h]\n",
    "        return self.h_o(out),res,out\n",
    "    \n",
    "    def reset(self):\n",
    "        for h in self.h:\n",
    "            h.zero_ # Some changes here\n",
    "    \n",
    "\n",
    "class MyLLM11(Module):\n",
    "    \"AWD-LSTM inspired by https://arxiv.org/abs/1708.02182\"\n",
    "    initrange=0.1\n",
    "\n",
    "    def __init__(self, \n",
    "        vocab_sz:int, # Size of the vocabulary\n",
    "        emb_sz:int, # Size of embedding vector\n",
    "        n_hid:int, # Number of features in hidden state\n",
    "        n_layers:int, # Number of LSTM layers\n",
    "        pad_token:int=1, # Padding token id\n",
    "        hidden_p:float=0.2, # Dropout probability for hidden state between layers\n",
    "        input_p:float=0.6, # Dropout probability for LSTM stack input\n",
    "        embed_p:float=0.1, # Embedding layer dropout probabillity\n",
    "        weight_p:float=0.5, # Hidden-to-hidden wight dropout probability for LSTM layers\n",
    "        bidir:bool=False # If set to `True` uses bidirectional LSTM layers\n",
    "    ):\n",
    "        store_attr('emb_sz,n_hid,n_layers,pad_token')\n",
    "        self.bs = 1\n",
    "        self.n_dir = 2 if bidir else 1\n",
    "        self.encoder = nn.Embedding(vocab_sz, emb_sz, padding_idx=pad_token)\n",
    "        self.encoder_dp = EmbeddingDropout(self.encoder, embed_p)\n",
    "        self.rnns = nn.ModuleList([self._one_rnn(emb_sz if l == 0 else n_hid, (n_hid if l != n_layers - 1 else emb_sz)//self.n_dir,\n",
    "                                                 bidir, weight_p, l) for l in range(n_layers)])\n",
    "        self.encoder.weight.data.uniform_(-self.initrange, self.initrange)\n",
    "        self.input_dp = RNNDropout(input_p)\n",
    "        self.hidden_dps = nn.ModuleList([RNNDropout(hidden_p) for l in range(n_layers)])\n",
    "        self.reset()\n",
    "\n",
    "    def forward(self, inp:Tensor, from_embeds:bool=False):\n",
    "        bs,sl = inp.shape[:2] if from_embeds else inp.shape\n",
    "        if bs!=self.bs: self._change_hidden(bs)\n",
    "\n",
    "        output = self.input_dp(inp if from_embeds else self.encoder_dp(inp))\n",
    "        new_hidden = []\n",
    "        for l, (rnn,hid_dp) in enumerate(zip(self.rnns, self.hidden_dps)):\n",
    "            output, new_h = rnn(output, self.hidden[l])\n",
    "            new_hidden.append(new_h)\n",
    "            if l != self.n_layers - 1: output = hid_dp(output)\n",
    "        self.hidden = to_detach(new_hidden, cpu=False, gather=False)\n",
    "        return tensor(np.zeros((10240,1))),tensor(np.zeros((10240,1))),tensor(np.zeros((10240)))\n",
    "\n",
    "    def _change_hidden(self, bs):\n",
    "        self.hidden = [self._change_one_hidden(l, bs) for l in range(self.n_layers)]\n",
    "        self.bs = bs\n",
    "\n",
    "    def _one_rnn(self, n_in, n_out, bidir, weight_p, l):\n",
    "        \"Return one of the inner rnn\"\n",
    "        rnn = nn.LSTM(n_in, n_out, 1, batch_first=True, bidirectional=bidir)\n",
    "        return WeightDropout(rnn, weight_p)\n",
    "\n",
    "    def _one_hidden(self, l):\n",
    "        \"Return one hidden state\"\n",
    "        nh = (self.n_hid if l != self.n_layers - 1 else self.emb_sz) // self.n_dir\n",
    "        return (one_param(self).new_zeros(self.n_dir, self.bs, nh), one_param(self).new_zeros(self.n_dir, self.bs, nh))\n",
    "\n",
    "    def _change_one_hidden(self, l, bs):\n",
    "        if self.bs < bs:\n",
    "            nh = (self.n_hid if l != self.n_layers - 1 else self.emb_sz) // self.n_dir\n",
    "            return tuple(torch.cat([h, h.new_zeros(self.n_dir, bs-self.bs, nh)], dim=1) for h in self.hidden[l])\n",
    "        if self.bs > bs: return (self.hidden[l][0][:,:bs].contiguous(), self.hidden[l][1][:,:bs].contiguous())\n",
    "        return self.hidden[l]\n",
    "\n",
    "    def reset(self):\n",
    "        \"Reset the hidden states\"\n",
    "        [r.reset() for r in self.rnns if hasattr(r, 'reset')]\n",
    "        self.hidden = [self._one_hidden(l) for l in range(self.n_layers)]\n",
    "        \n",
    "class MyLLM4(Module):\n",
    "    def __init__(self, vocab_sz, n_hidden):\n",
    "        self.i_h = nn.Embedding(vocab_sz,n_hidden)\n",
    "        self.h_h = nn.Linear(n_hidden,n_hidden)\n",
    "        self.h_o = nn.Linear(n_hidden,vocab_sz)\n",
    "        self.h = 0\n",
    "    \n",
    "    def forward(self,x):\n",
    "        num_cols = x.shape[1]\n",
    "        outs = []\n",
    "        for i in range(num_cols):\n",
    "            self.h = self.h + self.i_h(x[:,i]) # Access the Emb vector for the respective column\n",
    "            self.h = self.h_h(self.h) # Connect to a Linear NN\n",
    "            self.h = F.relu(self.h) # Our Non - liearization\n",
    "            outs.append(self.h_o(self.h)) # Pass to the output layer\n",
    "        res = self.h\n",
    "        self.h = self.h.detach()\n",
    "        return torch.stack(outs, dim=1),res,outs\n",
    "    \n",
    "    def reset(self):\n",
    "        self.h = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 649,
   "id": "eb95e9fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0.,  ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 649,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor(np.zeros((100000)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 650,
   "id": "80197d9d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28480"
      ]
     },
     "execution_count": 650,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dls_lm.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 651,
   "id": "ee1ee6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "MyLSTMModel = MyLLM11(len(dls_lm.vocab),64,64,4)\n",
    "# MyLSTMModel = MyLLM4(len(dls_lm.vocab),64)\n",
    "# MyLSTMModel = MyLLM10(len(dls_lm.vocab),64,4,0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 658,
   "id": "8309dac3",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [658]\u001b[0m, in \u001b[0;36m<cell line: 7>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# learn = LMLearner(\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#     dls_lm, MyLSTMModel, \u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m#     loss_func=CrossEntropyLossFlat(),\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m#     metrics=[accuracy, Perplexity()]\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# )\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m learn \u001b[38;5;241m=\u001b[39m \u001b[43mlanguage_model_learner\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdls_lm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mAWD_LSTM\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdrop_mult\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43maccuracy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mPerplexity\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto_fp16()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\fastai\\text\\learner.py:244\u001b[0m, in \u001b[0;36mlanguage_model_learner\u001b[1;34m(dls, arch, config, drop_mult, backwards, pretrained, pretrained_fnames, **kwargs)\u001b[0m\n\u001b[0;32m    242\u001b[0m     warn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThere are no pretrained weights for that architecture yet!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    243\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m learn\n\u001b[1;32m--> 244\u001b[0m model_path \u001b[38;5;241m=\u001b[39m \u001b[43muntar_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmeta\u001b[49m\u001b[43m[\u001b[49m\u001b[43murl\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    245\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m: fnames \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mlist\u001b[39m(model_path\u001b[38;5;241m.\u001b[39mglob(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m*.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mext\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m))[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m ext \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpth\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpkl\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n\u001b[0;32m    246\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m: \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe model in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is incomplete, download again\u001b[39m\u001b[38;5;124m'\u001b[39m); \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\fastai\\data\\external.py:136\u001b[0m, in \u001b[0;36muntar_data\u001b[1;34m(url, archive, data, c_key, force_download, base)\u001b[0m\n\u001b[0;32m    134\u001b[0m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDownload `url` using `FastDownload.get`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    135\u001b[0m d \u001b[38;5;241m=\u001b[39m FastDownload(fastai_cfg(), module\u001b[38;5;241m=\u001b[39mfastai\u001b[38;5;241m.\u001b[39mdata, archive\u001b[38;5;241m=\u001b[39marchive, data\u001b[38;5;241m=\u001b[39mdata, base\u001b[38;5;241m=\u001b[39mbase)\n\u001b[1;32m--> 136\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43md\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforce\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextract_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mc_key\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\fastdownload\\core.py:117\u001b[0m, in \u001b[0;36mFastDownload.get\u001b[1;34m(self, url, extract_key, force)\u001b[0m\n\u001b[0;32m    115\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_path(extract_key, urldest(url, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39march_path()))\n\u001b[0;32m    116\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data\u001b[38;5;241m.\u001b[39mexists(): \u001b[38;5;28;01mreturn\u001b[39;00m data\n\u001b[1;32m--> 117\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownload\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforce\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mextract(url, extract_key\u001b[38;5;241m=\u001b[39mextract_key, force\u001b[38;5;241m=\u001b[39mforce)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\fastdownload\\core.py:92\u001b[0m, in \u001b[0;36mFastDownload.download\u001b[1;34m(self, url, force)\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDownload `url` to archive path, unless exists and `self.check` fails and not `force`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39march_path()\u001b[38;5;241m.\u001b[39mmkdir(exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, parents\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m---> 92\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdownload_and_check\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murldest\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43march_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforce\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\fastdownload\\core.py:61\u001b[0m, in \u001b[0;36mdownload_and_check\u001b[1;34m(url, fpath, fmod, force)\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m check(fmod, url, fpath): \u001b[38;5;28;01mreturn\u001b[39;00m fpath\n\u001b[0;32m     60\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m: \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDownloading a new version of this dataset...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 61\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mdownload_url\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m check(fmod, url, fpath): \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDownloaded file is corrupt or not latest version\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\fastdownload\\core.py:19\u001b[0m, in \u001b[0;36mdownload_url\u001b[1;34m(url, dest, timeout, show_progress)\u001b[0m\n\u001b[0;32m     17\u001b[0m     pbar\u001b[38;5;241m.\u001b[39mtotal \u001b[38;5;241m=\u001b[39m tsize\n\u001b[0;32m     18\u001b[0m     pbar\u001b[38;5;241m.\u001b[39mupdate(count\u001b[38;5;241m*\u001b[39mbsize)\n\u001b[1;32m---> 19\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43murlsave\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreporthook\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mshow_progress\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\fastcore\\net.py:184\u001b[0m, in \u001b[0;36murlsave\u001b[1;34m(url, dest, reporthook, headers, timeout)\u001b[0m\n\u001b[0;32m    182\u001b[0m dest \u001b[38;5;241m=\u001b[39m urldest(url, dest)\n\u001b[0;32m    183\u001b[0m dest\u001b[38;5;241m.\u001b[39mparent\u001b[38;5;241m.\u001b[39mmkdir(parents\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m--> 184\u001b[0m nm,msg \u001b[38;5;241m=\u001b[39m \u001b[43murlretrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreporthook\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m nm\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\fastcore\\net.py:149\u001b[0m, in \u001b[0;36murlretrieve\u001b[1;34m(url, filename, reporthook, data, headers, timeout)\u001b[0m\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21murlretrieve\u001b[39m(url, filename\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, reporthook\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, headers\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    148\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSame as `urllib.request.urlretrieve` but also works with `Request` objects\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 149\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m contextlib\u001b[38;5;241m.\u001b[39mclosing(\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m) \u001b[38;5;28;01mas\u001b[39;00m fp:\n\u001b[0;32m    150\u001b[0m         headers \u001b[38;5;241m=\u001b[39m fp\u001b[38;5;241m.\u001b[39minfo()\n\u001b[0;32m    151\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m filename: tfp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(filename, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\fastcore\\net.py:108\u001b[0m, in \u001b[0;36murlopen\u001b[1;34m(url, data, headers, timeout, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, (\u001b[38;5;28mstr\u001b[39m,\u001b[38;5;28mbytes\u001b[39m)): data \u001b[38;5;241m=\u001b[39m urlencode(data)\n\u001b[0;32m    107\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mbytes\u001b[39m): data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mencode(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mascii\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m--> 108\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m: \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43murlopener\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43murlwrap\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    109\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m HTTPError \u001b[38;5;28;01mas\u001b[39;00m e: \n\u001b[0;32m    110\u001b[0m     e\u001b[38;5;241m.\u001b[39mmsg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m====Error Body====\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;241m.\u001b[39mread()\u001b[38;5;241m.\u001b[39mdecode(errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\urllib\\request.py:517\u001b[0m, in \u001b[0;36mOpenerDirector.open\u001b[1;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[0;32m    514\u001b[0m     req \u001b[38;5;241m=\u001b[39m meth(req)\n\u001b[0;32m    516\u001b[0m sys\u001b[38;5;241m.\u001b[39maudit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124murllib.Request\u001b[39m\u001b[38;5;124m'\u001b[39m, req\u001b[38;5;241m.\u001b[39mfull_url, req\u001b[38;5;241m.\u001b[39mdata, req\u001b[38;5;241m.\u001b[39mheaders, req\u001b[38;5;241m.\u001b[39mget_method())\n\u001b[1;32m--> 517\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    519\u001b[0m \u001b[38;5;66;03m# post-process response\u001b[39;00m\n\u001b[0;32m    520\u001b[0m meth_name \u001b[38;5;241m=\u001b[39m protocol\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_response\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\urllib\\request.py:534\u001b[0m, in \u001b[0;36mOpenerDirector._open\u001b[1;34m(self, req, data)\u001b[0m\n\u001b[0;32m    531\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[0;32m    533\u001b[0m protocol \u001b[38;5;241m=\u001b[39m req\u001b[38;5;241m.\u001b[39mtype\n\u001b[1;32m--> 534\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_chain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_open\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\n\u001b[0;32m    535\u001b[0m \u001b[43m                          \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m_open\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    536\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result:\n\u001b[0;32m    537\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\urllib\\request.py:494\u001b[0m, in \u001b[0;36mOpenerDirector._call_chain\u001b[1;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[0;32m    492\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m handler \u001b[38;5;129;01min\u001b[39;00m handlers:\n\u001b[0;32m    493\u001b[0m     func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(handler, meth_name)\n\u001b[1;32m--> 494\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    495\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    496\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\urllib\\request.py:1389\u001b[0m, in \u001b[0;36mHTTPSHandler.https_open\u001b[1;34m(self, req)\u001b[0m\n\u001b[0;32m   1388\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhttps_open\u001b[39m(\u001b[38;5;28mself\u001b[39m, req):\n\u001b[1;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhttp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mHTTPSConnection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1390\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_context\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_hostname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_hostname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\urllib\\request.py:1346\u001b[0m, in \u001b[0;36mAbstractHTTPHandler.do_open\u001b[1;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[0;32m   1344\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1345\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1346\u001b[0m         \u001b[43mh\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselector\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1347\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhas_header\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTransfer-encoding\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1348\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err: \u001b[38;5;66;03m# timeout error\u001b[39;00m\n\u001b[0;32m   1349\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m URLError(err)\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\http\\client.py:1285\u001b[0m, in \u001b[0;36mHTTPConnection.request\u001b[1;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[0;32m   1282\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\u001b[38;5;28mself\u001b[39m, method, url, body\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, headers\u001b[38;5;241m=\u001b[39m{}, \u001b[38;5;241m*\u001b[39m,\n\u001b[0;32m   1283\u001b[0m             encode_chunked\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m   1284\u001b[0m     \u001b[38;5;124;03m\"\"\"Send a complete request to the server.\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1285\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\http\\client.py:1331\u001b[0m, in \u001b[0;36mHTTPConnection._send_request\u001b[1;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[0;32m   1327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(body, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m   1328\u001b[0m     \u001b[38;5;66;03m# RFC 2616 Section 3.7.1 says that text default has a\u001b[39;00m\n\u001b[0;32m   1329\u001b[0m     \u001b[38;5;66;03m# default charset of iso-8859-1.\u001b[39;00m\n\u001b[0;32m   1330\u001b[0m     body \u001b[38;5;241m=\u001b[39m _encode(body, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbody\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m-> 1331\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mendheaders\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencode_chunked\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\http\\client.py:1280\u001b[0m, in \u001b[0;36mHTTPConnection.endheaders\u001b[1;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[0;32m   1278\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1279\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CannotSendHeader()\n\u001b[1;32m-> 1280\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_output\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencode_chunked\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\http\\client.py:1040\u001b[0m, in \u001b[0;36mHTTPConnection._send_output\u001b[1;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[0;32m   1038\u001b[0m msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\r\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_buffer)\n\u001b[0;32m   1039\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_buffer[:]\n\u001b[1;32m-> 1040\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1042\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m message_body \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1043\u001b[0m \n\u001b[0;32m   1044\u001b[0m     \u001b[38;5;66;03m# create a consistent interface to message_body\u001b[39;00m\n\u001b[0;32m   1045\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(message_body, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mread\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m   1046\u001b[0m         \u001b[38;5;66;03m# Let file-like take precedence over byte-like.  This\u001b[39;00m\n\u001b[0;32m   1047\u001b[0m         \u001b[38;5;66;03m# is needed to allow the current position of mmap'ed\u001b[39;00m\n\u001b[0;32m   1048\u001b[0m         \u001b[38;5;66;03m# files to be taken into account.\u001b[39;00m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\http\\client.py:980\u001b[0m, in \u001b[0;36mHTTPConnection.send\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    978\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    979\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_open:\n\u001b[1;32m--> 980\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    981\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    982\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m NotConnected()\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\http\\client.py:1454\u001b[0m, in \u001b[0;36mHTTPSConnection.connect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1451\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1452\u001b[0m     server_hostname \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhost\n\u001b[1;32m-> 1454\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrap_socket\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msock\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1455\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mserver_hostname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\ssl.py:500\u001b[0m, in \u001b[0;36mSSLContext.wrap_socket\u001b[1;34m(self, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, session)\u001b[0m\n\u001b[0;32m    494\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrap_socket\u001b[39m(\u001b[38;5;28mself\u001b[39m, sock, server_side\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    495\u001b[0m                 do_handshake_on_connect\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    496\u001b[0m                 suppress_ragged_eofs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    497\u001b[0m                 server_hostname\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, session\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    498\u001b[0m     \u001b[38;5;66;03m# SSLSocket class handles server_hostname encoding before it calls\u001b[39;00m\n\u001b[0;32m    499\u001b[0m     \u001b[38;5;66;03m# ctx._wrap_socket()\u001b[39;00m\n\u001b[1;32m--> 500\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msslsocket_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43msock\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msock\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43mserver_side\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mserver_side\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdo_handshake_on_connect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdo_handshake_on_connect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43msuppress_ragged_eofs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msuppress_ragged_eofs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    505\u001b[0m \u001b[43m        \u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mserver_hostname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    506\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    507\u001b[0m \u001b[43m        \u001b[49m\u001b[43msession\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msession\u001b[49m\n\u001b[0;32m    508\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\ssl.py:1040\u001b[0m, in \u001b[0;36mSSLSocket._create\u001b[1;34m(cls, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, context, session)\u001b[0m\n\u001b[0;32m   1037\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0.0\u001b[39m:\n\u001b[0;32m   1038\u001b[0m             \u001b[38;5;66;03m# non-blocking\u001b[39;00m\n\u001b[0;32m   1039\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdo_handshake_on_connect should not be specified for non-blocking sockets\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1040\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_handshake\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1041\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mOSError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[0;32m   1042\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\ssl.py:1309\u001b[0m, in \u001b[0;36mSSLSocket.do_handshake\u001b[1;34m(self, block)\u001b[0m\n\u001b[0;32m   1307\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0.0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m block:\n\u001b[0;32m   1308\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msettimeout(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m-> 1309\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_handshake\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1310\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m   1311\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msettimeout(timeout)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# learn = LMLearner(\n",
    "#     dls_lm, MyLSTMModel, \n",
    "#     loss_func=CrossEntropyLossFlat(),\n",
    "#     metrics=[accuracy, Perplexity()]\n",
    "# )\n",
    "\n",
    "learn = language_model_learner(\n",
    "    dls_lm, AWD_LSTM, drop_mult=0.3, \n",
    "    metrics=[accuracy, Perplexity()]).to_fp16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f6fb14c",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(1, 2e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2cf1d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(1, 2e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "id": "9b357acd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>perplexity</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>4.760979</td>\n",
       "      <td>4.770746</td>\n",
       "      <td>0.267244</td>\n",
       "      <td>118.007217</td>\n",
       "      <td>26:32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(1, 2e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "id": "2dbbc49c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>perplexity</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>4.638702</td>\n",
       "      <td>4.681375</td>\n",
       "      <td>0.276487</td>\n",
       "      <td>107.918358</td>\n",
       "      <td>25:55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4.426968</td>\n",
       "      <td>4.558434</td>\n",
       "      <td>0.286272</td>\n",
       "      <td>95.433914</td>\n",
       "      <td>26:28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(2, 2e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df8c54e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f1661cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "id": "6f09c486",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "<class '__main__.MyLLM10'>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[1;32mIn [468]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m learn \u001b[38;5;241m=\u001b[39m \u001b[43mlanguage_model_learner\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdls_lm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mMyLLM10\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdrop_mult\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43maccuracy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mPerplexity\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto_fp16()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\fastai\\text\\learner.py:233\u001b[0m, in \u001b[0;36mlanguage_model_learner\u001b[1;34m(dls, arch, config, drop_mult, backwards, pretrained, pretrained_fnames, **kwargs)\u001b[0m\n\u001b[0;32m    231\u001b[0m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreate a `Learner` with a language model from `dls` and `arch`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    232\u001b[0m vocab \u001b[38;5;241m=\u001b[39m _get_text_vocab(dls)\n\u001b[1;32m--> 233\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mget_language_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43march\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mvocab\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdrop_mult\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdrop_mult\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    234\u001b[0m meta \u001b[38;5;241m=\u001b[39m _model_meta[arch]\n\u001b[0;32m    235\u001b[0m learn \u001b[38;5;241m=\u001b[39m LMLearner(dls, model, loss_func\u001b[38;5;241m=\u001b[39mCrossEntropyLossFlat(), splitter\u001b[38;5;241m=\u001b[39mmeta[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msplit_lm\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\fastai\\text\\models\\core.py:60\u001b[0m, in \u001b[0;36mget_language_model\u001b[1;34m(arch, vocab_sz, config, drop_mult)\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_language_model\u001b[39m(\n\u001b[0;32m     54\u001b[0m     arch, \u001b[38;5;66;03m# Function or class that can generate a language model architecture\u001b[39;00m\n\u001b[0;32m     55\u001b[0m     vocab_sz:\u001b[38;5;28mint\u001b[39m, \u001b[38;5;66;03m# Size of the vocabulary\u001b[39;00m\n\u001b[0;32m     56\u001b[0m     config:\u001b[38;5;28mdict\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;66;03m# Model configuration dictionary\u001b[39;00m\n\u001b[0;32m     57\u001b[0m     drop_mult:\u001b[38;5;28mfloat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.\u001b[39m \u001b[38;5;66;03m# Multiplicative factor to scale all dropout probabilities in `config`\u001b[39;00m\n\u001b[0;32m     58\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m SequentialRNN: \u001b[38;5;66;03m# Language model with `arch` encoder and linear decoder\u001b[39;00m\n\u001b[0;32m     59\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreate a language model from `arch` and its `config`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 60\u001b[0m     meta \u001b[38;5;241m=\u001b[39m \u001b[43m_model_meta\u001b[49m\u001b[43m[\u001b[49m\u001b[43march\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     61\u001b[0m     config \u001b[38;5;241m=\u001b[39m ifnone(config, meta[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconfig_lm\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m     62\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m config\u001b[38;5;241m.\u001b[39mkeys():\n",
      "\u001b[1;31mKeyError\u001b[0m: <class '__main__.MyLLM10'>"
     ]
    }
   ],
   "source": [
    "learn = language_model_learner(\n",
    "    dls_lm, MyLLM10, drop_mult=0.3, \n",
    "    metrics=[accuracy, Perplexity()]).to_fp16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ed1fb9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "b451de85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SERIKALI imesema haitakuwa tayari kuona amani na utulivu wa nchi inachezewa huku ikisisitiza uwepo w'"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = ' xbos '.join([l.strip() for l in txts[:200]])\n",
    "text[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "fa3c7775",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'sp_model': Path('tmp/spm.model')}"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Tokenize\n",
    "\n",
    "sp = SubwordTokenizer(vocab_sz=2000)\n",
    "# sp.setup(txts[:1])\n",
    "sp.setup(txts)\n",
    "\n",
    "# spacy = WordTokenizer()\n",
    "# tkn = Tokenizer(spacy)\n",
    "\n",
    "# tokens = tkn(text)\n",
    "# tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "1fc09e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = list(sp([text]))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "adaf3adb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#112814) [0,1,2,3,4,5,6,7,8,9...]"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## To Numericalize\n",
    "\n",
    "\n",
    "# num = Numericalize()\n",
    "# num.setup(tokens)\n",
    "\n",
    "# # Generate the vocab with unique tokens\n",
    "vocab = L(*tokens).unique()\n",
    "\n",
    "word2idx = {w:i for i, w in enumerate(vocab)}\n",
    "nums = L(word2idx[w] for w in tokens)\n",
    "nums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "45935efb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(112814, 1977)"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nums),len(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c4cecaa",
   "metadata": {},
   "source": [
    "## Build a language model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b38b52",
   "metadata": {},
   "source": [
    "### Predict each word based on the previous 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "99337a36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#37604) [(['▁SER', 'IKA', 'LI'], '▁ime'),(['▁ime', 'sema', '▁hai'], 'ta'),(['ta', 'kuwa', '▁tayari'], '▁kuona'),(['▁kuona', '▁amani', '▁na'], '▁u'),(['▁u', 'tu', 'li'], 'vu'),(['vu', '▁wa', '▁nchi'], '▁ina'),(['▁ina', 'che', 'ze'], 'wa'),(['wa', '▁huku', '▁iki'], 'sisitiza'),(['sisitiza', '▁uwepo', '▁wa'], '▁umoja'),(['▁umoja', '▁kati', '▁ya'], '▁wananchi')...]"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L((tokens[i:i+3],tokens[i+3]) for i in range(0,len(tokens)-4,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af04aaa4",
   "metadata": {},
   "source": [
    "The model can't use the above but the numericalized version of the above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "3689c7af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#37604) [(tensor([0, 1, 2]), 3),(tensor([3, 4, 5]), 6),(tensor([6, 7, 8]), 9),(tensor([ 9, 10, 11]), 12),(tensor([12, 13, 14]), 15),(tensor([15, 16, 17]), 18),(tensor([18, 19, 20]), 21),(tensor([21, 22, 23]), 24),(tensor([24, 25, 16]), 26),(tensor([26, 27, 28]), 29)...]"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seqs = L((tensor(nums[i:i+3]),nums[i+3]) for i in range(0,len(nums)-4,3))\n",
    "seqs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64a207cc",
   "metadata": {},
   "source": [
    "### Creating the DataLoader with a `batch_size` of 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "53fcfcbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 64\n",
    "cut = int(len(seqs) * 0.8)\n",
    "dls = DataLoaders.from_dsets(seqs[:cut],seqs[cut:],shuffle=False,bs=bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "539c5a03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([64, 3]), torch.Size([64]))"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x,y = dls.one_batch()\n",
    "x.shape,y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d187c50",
   "metadata": {},
   "source": [
    "## Our Language Model in PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "412a7658",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLLM1(Module):\n",
    "    def __init__(self, vocab_sz, n_hidden):\n",
    "        self.i_h = nn.Embedding(vocab_sz,n_hidden)\n",
    "        self.h_h = nn.Linear(n_hidden,n_hidden)\n",
    "        self.h_o = nn.Linear(n_hidden,vocab_sz)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        h = self.i_h(x[:,0]) # Access the Emb vector for the first column\n",
    "        h = self.h_h(h) # Connect to the first set of Linear NN\n",
    "        h = F.relu(h) # Our Non - liearization\n",
    "        \n",
    "        h = h + self.i_h(x[:,1]) # Add the Emb vector for the second column\n",
    "        h = self.h_h(h) # Pass to the Linear Network\n",
    "        h = F.relu(h) # Again the Non-linearization\n",
    "        \n",
    "        h = h + self.i_h(x[:,2]) # Add the Emb vector for the third column\n",
    "        h = self.h_h(h) # Pass to the Linear Network\n",
    "        h = F.relu(h) # Again the Non-linearization\n",
    "        \n",
    "        h = self.h_o(h) # Pass to the output layer\n",
    "        return h"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e8424fd",
   "metadata": {},
   "source": [
    "Rewriting it as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "82eb051d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLLM2(Module):\n",
    "    def __init__(self, vocab_sz, n_hidden):\n",
    "        self.i_h = nn.Embedding(vocab_sz,n_hidden)\n",
    "        self.h_h = nn.Linear(n_hidden,n_hidden)\n",
    "        self.h_o = nn.Linear(n_hidden,vocab_sz)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        h = 0\n",
    "        num_cols = x.shape[1]\n",
    "        for i in range(num_cols):\n",
    "            h = h + self.i_h(x[:,i]) # Access the Emb vector for the respective column\n",
    "            h = self.h_h(h) # Connect to a Linear NN\n",
    "            h = F.relu(h) # Our Non - liearization\n",
    "        h = self.h_o(h) # Pass to the output layer\n",
    "        return h"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25682cac",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "a6802725",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(35), ',', 0.03297433851881399)"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Baseline model of always predicting the mode of the tokens\n",
    "\n",
    "n,counts = 0,torch.zeros(len(vocab))\n",
    "for x,y in dls.valid:\n",
    "    n += y.shape[0]\n",
    "    for i in range_of(vocab): counts[i] += (y==i).long().sum()\n",
    "idx = torch.argmax(counts)\n",
    "idx, vocab[idx.item()], counts[idx].item()/n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "9c6fac10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>5.797340</td>\n",
       "      <td>5.822598</td>\n",
       "      <td>0.092142</td>\n",
       "      <td>00:57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4.115510</td>\n",
       "      <td>5.921351</td>\n",
       "      <td>0.111022</td>\n",
       "      <td>00:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.717089</td>\n",
       "      <td>6.425860</td>\n",
       "      <td>0.127643</td>\n",
       "      <td>00:56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.376848</td>\n",
       "      <td>6.855087</td>\n",
       "      <td>0.131100</td>\n",
       "      <td>00:54</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn = Learner(dls, MyLLM2(len(vocab), 1024), loss_func=F.cross_entropy, \n",
    "                metrics=accuracy)\n",
    "learn.fit_one_cycle(4, 1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "158ba4da",
   "metadata": {},
   "source": [
    "Slightly better"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d927c38b",
   "metadata": {},
   "source": [
    "### Maintaining the state of the RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "7172e830",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLLM3(Module):\n",
    "    def __init__(self, vocab_sz, n_hidden):\n",
    "        self.i_h = nn.Embedding(vocab_sz,n_hidden)\n",
    "        self.h_h = nn.Linear(n_hidden,n_hidden)\n",
    "        self.h_o = nn.Linear(n_hidden,vocab_sz)\n",
    "        self.h = 0\n",
    "    \n",
    "    def forward(self,x):\n",
    "        num_cols = x.shape[1]\n",
    "        for i in range(num_cols):\n",
    "            self.h = self.h + self.i_h(x[:,i]) # Access the Emb vector for the respective column\n",
    "            self.h = self.h_h(self.h) # Connect to a Linear NN\n",
    "            self.h = F.relu(self.h) # Our Non - liearization\n",
    "        out = self.h_o(self.h) # Pass to the output layer\n",
    "        \n",
    "        self.h = self.h.detach()\n",
    "        return out\n",
    "    \n",
    "    def reset(self):\n",
    "        self.h = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "ff073828",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(587, 64, 37604)"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = len(seqs)//bs\n",
    "m,bs,len(seqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "179d530a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_chunks(ds, bs):\n",
    "    m = len(ds) // bs\n",
    "    new_ds = L()\n",
    "    for i in range(m): new_ds += L(ds[i + m*j] for j in range(bs))\n",
    "    return new_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "62385db7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(tensor([0, 1, 2]), 3),\n",
       " (tensor([ 9, 10, 11]), 12),\n",
       " (tensor([18, 19, 20]), 21),\n",
       " (tensor([26, 27, 28]), 29),\n",
       " (tensor([28, 34, 35]), 36),\n",
       " (tensor([42, 43, 44]), 45),\n",
       " (tensor([3, 4, 5]), 6),\n",
       " (tensor([12, 13, 14]), 15),\n",
       " (tensor([21, 22, 23]), 24),\n",
       " (tensor([29, 30, 31]), 32),\n",
       " (tensor([36, 37, 38]), 39),\n",
       " (tensor([45, 46, 47]), 48),\n",
       " (tensor([6, 7, 8]), 9),\n",
       " (tensor([15, 16, 17]), 18),\n",
       " (tensor([24, 25, 16]), 26),\n",
       " (tensor([32, 14, 33]), 28),\n",
       " (tensor([39, 40, 41]), 42),\n",
       " (tensor([48, 21, 11]), 49)]"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(group_chunks(seqs[:20],6))#.reshape(4,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "6875050f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cut = int(len(seqs) * 0.8)\n",
    "dls = DataLoaders.from_dsets(\n",
    "    group_chunks(seqs[:cut], bs), \n",
    "    group_chunks(seqs[cut:], bs), \n",
    "    bs=bs, drop_last=True, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "168bd7dc",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4be830b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>5.910364</td>\n",
       "      <td>6.097558</td>\n",
       "      <td>0.172414</td>\n",
       "      <td>02:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4.002608</td>\n",
       "      <td>6.482233</td>\n",
       "      <td>0.191092</td>\n",
       "      <td>02:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.467951</td>\n",
       "      <td>7.328877</td>\n",
       "      <td>0.176904</td>\n",
       "      <td>02:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.519905</td>\n",
       "      <td>8.706957</td>\n",
       "      <td>0.170797</td>\n",
       "      <td>02:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.959000</td>\n",
       "      <td>10.245851</td>\n",
       "      <td>0.169540</td>\n",
       "      <td>02:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.610137</td>\n",
       "      <td>10.246753</td>\n",
       "      <td>0.168103</td>\n",
       "      <td>02:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.438787</td>\n",
       "      <td>10.063964</td>\n",
       "      <td>0.180316</td>\n",
       "      <td>02:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.312056</td>\n",
       "      <td>10.027181</td>\n",
       "      <td>0.188398</td>\n",
       "      <td>02:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.263799</td>\n",
       "      <td>9.995111</td>\n",
       "      <td>0.191092</td>\n",
       "      <td>02:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.336758</td>\n",
       "      <td>9.742608</td>\n",
       "      <td>0.195582</td>\n",
       "      <td>02:07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn = Learner(dls, MyLLM3(len(vocab), 1024), loss_func=F.cross_entropy, \n",
    "                metrics=accuracy,cbs=ModelResetter)\n",
    "learn.fit_one_cycle(10, 1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4135da5",
   "metadata": {},
   "source": [
    "### Creating more signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "49a6ded1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sl = 16\n",
    "seqs = L((tensor(nums[i:i+sl]), tensor(nums[i+1:i+sl+1]))\n",
    "         for i in range(0,len(nums)-sl-1,sl))\n",
    "cut = int(len(seqs) * 0.8)\n",
    "dls = DataLoaders.from_dsets(group_chunks(seqs[:cut], bs),\n",
    "                             group_chunks(seqs[cut:], bs),\n",
    "                             bs=bs, drop_last=True, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adb0e0df",
   "metadata": {},
   "source": [
    "Looking at the first element of `seqs`, we can see that it contains two lists of the same size. The second list is the same as the first, but offset by one element:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "44a75f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLLM4(Module):\n",
    "    def __init__(self, vocab_sz, n_hidden):\n",
    "        self.i_h = nn.Embedding(vocab_sz,n_hidden)\n",
    "        self.h_h = nn.Linear(n_hidden,n_hidden)\n",
    "        self.h_o = nn.Linear(n_hidden,vocab_sz)\n",
    "        self.h = 0\n",
    "    \n",
    "    def forward(self,x):\n",
    "        num_cols = x.shape[1]\n",
    "        outs = []\n",
    "        for i in range(num_cols):\n",
    "            self.h = self.h + self.i_h(x[:,i]) # Access the Emb vector for the respective column\n",
    "            self.h = self.h_h(self.h) # Connect to a Linear NN\n",
    "            self.h = F.relu(self.h) # Our Non - liearization\n",
    "            outs.append(self.h_o(self.h)) # Pass to the output layer\n",
    "        \n",
    "        self.h = self.h.detach()\n",
    "        return torch.stack(outs, dim=1)\n",
    "    \n",
    "    def reset(self):\n",
    "        self.h = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "3744a899",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_func(inp, targ):\n",
    "    return F.cross_entropy(inp.view(-1, len(vocab)), targ.view(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "05886877",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>6.220513</td>\n",
       "      <td>5.796507</td>\n",
       "      <td>0.094638</td>\n",
       "      <td>00:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>5.071121</td>\n",
       "      <td>5.185163</td>\n",
       "      <td>0.136586</td>\n",
       "      <td>00:46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>4.194140</td>\n",
       "      <td>5.053366</td>\n",
       "      <td>0.156294</td>\n",
       "      <td>00:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3.569609</td>\n",
       "      <td>5.116390</td>\n",
       "      <td>0.164728</td>\n",
       "      <td>00:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>3.181340</td>\n",
       "      <td>5.093949</td>\n",
       "      <td>0.169389</td>\n",
       "      <td>00:43</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn = Learner(dls, MyLLM4(len(vocab), 1024), loss_func=loss_func, \n",
    "                metrics=accuracy,cbs=ModelResetter)\n",
    "learn.fit_one_cycle(5, 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "d057e25b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_pred(length):\n",
    "    to_pred = nums[95:95+length]\n",
    "    ans = nums[95+1:95+length+1]\n",
    "    \n",
    "    result = learn.predict(tensor([to_pred]))[0].argmax(1)\n",
    "    print(result,ans)\n",
    "\n",
    "    prompt = \"\"\n",
    "    for i in range(len(to_pred)):\n",
    "        prompt += vocab[to_pred[i]] +' '\n",
    "#     print(prompt)\n",
    "    prompt += \" <>  \"\n",
    "\n",
    "    for i in range(len(result)):\n",
    "        prompt += vocab[result[i]] + ' '\n",
    "#     return prompt\n",
    "    print(prompt)\n",
    "    \n",
    "    prompt = ' '.join(prompt.split(' ')[:len(ans)])\n",
    "    prompt += \"  <>  \"\n",
    "\n",
    "    for i in range(len(ans)):\n",
    "        prompt += vocab[ans[i]] + ' '\n",
    "    print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "91db797b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 15, 194, 340,  85,  86,  38,  87, 113,  61, 222]) [82, 83, 84, 85, 86, 38, 87, 35, 88, 79]\n",
      "▁wa ▁taasisi ▁za ▁Ki i s la mu , ▁lengo  <>  vu ▁hiyo ▁umma i s la mu ▁nchini ▁ ▁la \n",
      "▁wa ▁taasisi ▁za ▁Ki i s la mu , ▁lengo  <>  ▁taasisi ▁za ▁Ki i s la mu , ▁lengo ▁ikiwa \n"
     ]
    }
   ],
   "source": [
    "sample_pred(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "893b92d4",
   "metadata": {},
   "source": [
    "I am actually very surprised. Like I am wowed already.\n",
    "\n",
    "The original text is \" of the Government of the Fifth Phase is to promote \"<br>\n",
    "The predicted text is \" of Tanzania's Fifth Phase under promotion \"\n",
    "\n",
    "<b>NB</b>: \n",
    "<li> Translation done via Google Translate </li>\n",
    "<li> This prediction was done on the training set (But it is still remarkable I believe) </li>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a07889fe",
   "metadata": {},
   "source": [
    "### Multi-Layer RNNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "355d3ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLLM5(Module):\n",
    "    def __init__(self, vocab_sz, n_hidden,n_layers):\n",
    "        self.i_h = nn.Embedding(vocab_sz,n_hidden)\n",
    "        \n",
    "        self.network = []\n",
    "        for i in range(n_layers):\n",
    "            self.network.append(nn.Linear(n_hidden,n_hidden))\n",
    "            self.network.append(nn.ReLU())\n",
    "        self.h_h = nn.Sequential(\n",
    "            *self.network[:-1]\n",
    "        )\n",
    "#         self.h_h = nn.Linear(n_hidden,n_hidden)\n",
    "        self.h_o = nn.Linear(n_hidden,vocab_sz)\n",
    "        self.h = 0\n",
    "    \n",
    "    def forward(self,x):\n",
    "        num_cols = x.shape[1]\n",
    "        outs = []\n",
    "        for i in range(num_cols):\n",
    "            self.h = self.h + self.i_h(x[:,i]) # Access the Emb vector for the respective column\n",
    "            self.h = self.h_h(self.h) # Connect to a Linear NN\n",
    "            self.h = F.relu(self.h) # Our Non - liearization\n",
    "            outs.append(self.h_o(self.h)) # Pass to the output layer\n",
    "        \n",
    "        self.h = self.h.detach()\n",
    "        return torch.stack(outs, dim=1)\n",
    "    \n",
    "    def reset(self):\n",
    "        self.h = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "434b3ece",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>7.832971</td>\n",
       "      <td>6.765987</td>\n",
       "      <td>0.044739</td>\n",
       "      <td>02:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>6.556630</td>\n",
       "      <td>6.272907</td>\n",
       "      <td>0.160278</td>\n",
       "      <td>02:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>5.952004</td>\n",
       "      <td>6.013952</td>\n",
       "      <td>0.190002</td>\n",
       "      <td>02:20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>5.511847</td>\n",
       "      <td>5.976256</td>\n",
       "      <td>0.211121</td>\n",
       "      <td>02:21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5.108160</td>\n",
       "      <td>6.024221</td>\n",
       "      <td>0.216064</td>\n",
       "      <td>02:21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>4.775147</td>\n",
       "      <td>6.203149</td>\n",
       "      <td>0.220398</td>\n",
       "      <td>02:20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>4.493296</td>\n",
       "      <td>6.327516</td>\n",
       "      <td>0.227173</td>\n",
       "      <td>02:21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>4.273300</td>\n",
       "      <td>6.438957</td>\n",
       "      <td>0.224670</td>\n",
       "      <td>02:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>4.130563</td>\n",
       "      <td>6.620975</td>\n",
       "      <td>0.222656</td>\n",
       "      <td>02:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>4.093142</td>\n",
       "      <td>6.345071</td>\n",
       "      <td>0.230530</td>\n",
       "      <td>02:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>4.145858</td>\n",
       "      <td>6.137928</td>\n",
       "      <td>0.234009</td>\n",
       "      <td>02:21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>4.079705</td>\n",
       "      <td>6.195321</td>\n",
       "      <td>0.238586</td>\n",
       "      <td>02:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>3.885146</td>\n",
       "      <td>6.415190</td>\n",
       "      <td>0.237671</td>\n",
       "      <td>02:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>3.736405</td>\n",
       "      <td>6.487379</td>\n",
       "      <td>0.238770</td>\n",
       "      <td>02:21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>3.652735</td>\n",
       "      <td>6.458499</td>\n",
       "      <td>0.237427</td>\n",
       "      <td>02:21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn = Learner(dls, MyLLM5(len(vocab), 1024,4), loss_func=loss_func, \n",
    "                metrics=accuracy,cbs=ModelResetter)\n",
    "learn.fit_one_cycle(15, 1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "691343e2",
   "metadata": {},
   "source": [
    "In other words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "bbac4ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLLM6(Module):\n",
    "    def __init__(self, vocab_sz, n_hidden,n_layers):\n",
    "        self.i_h = nn.Embedding(vocab_sz,n_hidden)\n",
    "        self.rnn = nn.RNN(n_hidden,n_hidden, n_layers, batch_first=True)\n",
    "        self.h_o = nn.Linear(n_hidden,vocab_sz)\n",
    "        self.h = torch.zeros(n_layers, bs, n_hidden) # Some changes here\n",
    "    \n",
    "    def forward(self,x):\n",
    "        res,h = self.rnn(self.i_h(x), self.h)\n",
    "        self.h = h.detach()\n",
    "        return self.h_o(res)\n",
    "    \n",
    "    def reset(self):\n",
    "        self.h.zero_ # Some changes here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "63396b97",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>9.124417</td>\n",
       "      <td>9.022078</td>\n",
       "      <td>0.122498</td>\n",
       "      <td>00:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>8.783082</td>\n",
       "      <td>8.455340</td>\n",
       "      <td>0.122498</td>\n",
       "      <td>00:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>8.109900</td>\n",
       "      <td>7.619846</td>\n",
       "      <td>0.122498</td>\n",
       "      <td>00:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>7.321177</td>\n",
       "      <td>6.941107</td>\n",
       "      <td>0.122498</td>\n",
       "      <td>00:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>6.744375</td>\n",
       "      <td>6.657060</td>\n",
       "      <td>0.122498</td>\n",
       "      <td>00:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>6.491624</td>\n",
       "      <td>6.652512</td>\n",
       "      <td>0.122498</td>\n",
       "      <td>00:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>6.415926</td>\n",
       "      <td>6.688025</td>\n",
       "      <td>0.122498</td>\n",
       "      <td>00:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>6.396910</td>\n",
       "      <td>6.725154</td>\n",
       "      <td>0.122498</td>\n",
       "      <td>00:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>6.393860</td>\n",
       "      <td>6.759254</td>\n",
       "      <td>0.122498</td>\n",
       "      <td>00:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>6.394257</td>\n",
       "      <td>6.788418</td>\n",
       "      <td>0.122498</td>\n",
       "      <td>00:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>6.394333</td>\n",
       "      <td>6.812048</td>\n",
       "      <td>0.122498</td>\n",
       "      <td>00:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>6.393624</td>\n",
       "      <td>6.824253</td>\n",
       "      <td>0.122498</td>\n",
       "      <td>00:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>6.392339</td>\n",
       "      <td>6.832657</td>\n",
       "      <td>0.122498</td>\n",
       "      <td>00:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>6.390764</td>\n",
       "      <td>6.841636</td>\n",
       "      <td>0.122498</td>\n",
       "      <td>00:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>6.346683</td>\n",
       "      <td>6.721310</td>\n",
       "      <td>0.122498</td>\n",
       "      <td>00:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>6.266083</td>\n",
       "      <td>6.618015</td>\n",
       "      <td>0.123596</td>\n",
       "      <td>00:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>6.158525</td>\n",
       "      <td>6.514336</td>\n",
       "      <td>0.123596</td>\n",
       "      <td>00:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>6.036198</td>\n",
       "      <td>6.416707</td>\n",
       "      <td>0.138245</td>\n",
       "      <td>00:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>5.929802</td>\n",
       "      <td>6.360248</td>\n",
       "      <td>0.141418</td>\n",
       "      <td>00:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>5.851442</td>\n",
       "      <td>6.331236</td>\n",
       "      <td>0.144470</td>\n",
       "      <td>00:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>5.791691</td>\n",
       "      <td>6.306434</td>\n",
       "      <td>0.147888</td>\n",
       "      <td>00:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>5.741911</td>\n",
       "      <td>6.286253</td>\n",
       "      <td>0.150024</td>\n",
       "      <td>00:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>5.698960</td>\n",
       "      <td>6.284177</td>\n",
       "      <td>0.148682</td>\n",
       "      <td>00:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>5.660240</td>\n",
       "      <td>6.266245</td>\n",
       "      <td>0.149963</td>\n",
       "      <td>00:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>5.626951</td>\n",
       "      <td>6.255959</td>\n",
       "      <td>0.150513</td>\n",
       "      <td>00:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>5.598859</td>\n",
       "      <td>6.243095</td>\n",
       "      <td>0.152039</td>\n",
       "      <td>00:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>5.574529</td>\n",
       "      <td>6.236372</td>\n",
       "      <td>0.152039</td>\n",
       "      <td>00:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>5.551696</td>\n",
       "      <td>6.224903</td>\n",
       "      <td>0.152344</td>\n",
       "      <td>00:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>5.531609</td>\n",
       "      <td>6.216406</td>\n",
       "      <td>0.152527</td>\n",
       "      <td>00:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>5.512884</td>\n",
       "      <td>6.210415</td>\n",
       "      <td>0.154724</td>\n",
       "      <td>00:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>5.496809</td>\n",
       "      <td>6.212370</td>\n",
       "      <td>0.152771</td>\n",
       "      <td>00:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>5.482694</td>\n",
       "      <td>6.207172</td>\n",
       "      <td>0.152588</td>\n",
       "      <td>00:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>5.472106</td>\n",
       "      <td>6.207968</td>\n",
       "      <td>0.151978</td>\n",
       "      <td>00:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>5.463983</td>\n",
       "      <td>6.210777</td>\n",
       "      <td>0.154114</td>\n",
       "      <td>00:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>5.456168</td>\n",
       "      <td>6.208627</td>\n",
       "      <td>0.155823</td>\n",
       "      <td>00:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>5.450153</td>\n",
       "      <td>6.207768</td>\n",
       "      <td>0.155762</td>\n",
       "      <td>00:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>5.445815</td>\n",
       "      <td>6.205801</td>\n",
       "      <td>0.155945</td>\n",
       "      <td>00:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>5.443156</td>\n",
       "      <td>6.202513</td>\n",
       "      <td>0.155579</td>\n",
       "      <td>00:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>5.441360</td>\n",
       "      <td>6.204483</td>\n",
       "      <td>0.155579</td>\n",
       "      <td>00:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>5.440326</td>\n",
       "      <td>6.204522</td>\n",
       "      <td>0.155762</td>\n",
       "      <td>00:18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn = Learner(dls, MyLLM6(len(vocab), 64,8), loss_func=loss_func, \n",
    "                metrics=accuracy,cbs=ModelResetter)\n",
    "learn.fit_one_cycle(40, 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "91a39bad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>7.200701</td>\n",
       "      <td>6.618497</td>\n",
       "      <td>0.123840</td>\n",
       "      <td>01:48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>6.362325</td>\n",
       "      <td>6.229457</td>\n",
       "      <td>0.166504</td>\n",
       "      <td>01:48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>5.823647</td>\n",
       "      <td>6.021464</td>\n",
       "      <td>0.202515</td>\n",
       "      <td>01:50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>5.363237</td>\n",
       "      <td>6.079515</td>\n",
       "      <td>0.210083</td>\n",
       "      <td>01:49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4.953303</td>\n",
       "      <td>6.177130</td>\n",
       "      <td>0.211670</td>\n",
       "      <td>01:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>4.613482</td>\n",
       "      <td>6.241570</td>\n",
       "      <td>0.214600</td>\n",
       "      <td>01:55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>4.299594</td>\n",
       "      <td>6.321890</td>\n",
       "      <td>0.216125</td>\n",
       "      <td>01:53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>4.032951</td>\n",
       "      <td>6.331525</td>\n",
       "      <td>0.215576</td>\n",
       "      <td>01:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>3.806790</td>\n",
       "      <td>6.365344</td>\n",
       "      <td>0.218506</td>\n",
       "      <td>01:51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>3.682621</td>\n",
       "      <td>6.379865</td>\n",
       "      <td>0.219299</td>\n",
       "      <td>01:46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>3.484605</td>\n",
       "      <td>6.340055</td>\n",
       "      <td>0.224670</td>\n",
       "      <td>01:52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>3.203477</td>\n",
       "      <td>6.352996</td>\n",
       "      <td>0.225525</td>\n",
       "      <td>01:49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>2.980508</td>\n",
       "      <td>6.361646</td>\n",
       "      <td>0.226685</td>\n",
       "      <td>01:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>2.787237</td>\n",
       "      <td>6.359298</td>\n",
       "      <td>0.230164</td>\n",
       "      <td>01:53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>2.650961</td>\n",
       "      <td>6.354051</td>\n",
       "      <td>0.229187</td>\n",
       "      <td>01:49</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn = Learner(dls, MyLLM6(len(vocab), 1024,4), loss_func=CrossEntropyLossFlat(), # Change in the loss function\n",
    "                metrics=accuracy,cbs=ModelResetter)\n",
    "learn.fit_one_cycle(15, 1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "111449f7",
   "metadata": {},
   "source": [
    "Due to the problems of exploding or diasappearing activations, We will consider the use of LSTMs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "735fd230",
   "metadata": {},
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "8c5561ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLLM7(Module):\n",
    "    def __init__(self, ni, h):\n",
    "        self.forget_gate = nn.Linear(ni + nh, nh)\n",
    "        self.input_gate = nn.Linear(ni + nh, nh)\n",
    "        self.cell_gate = nn.Linear(ni + nh, nh)\n",
    "        self.output_gate = nn.Linear(ni + nh, nh)\n",
    "    \n",
    "    def forward(self, x, state):\n",
    "        h,c = state\n",
    "        h = torch.cat([h, x], dim=1)\n",
    "        forget = torch.sigmoid(self.forget_gate(h))\n",
    "        c = c * forget\n",
    "        \n",
    "        inputer = torchinput_gateigmoid(self.input_gate(h)) * torch.tanh(self.cell_gate(h))\n",
    "        c = c + inputer\n",
    "        \n",
    "        outputer = torch.sigmoid(self.output_gate(h))\n",
    "        h = torch.tanh(c) * outputer\n",
    "        return h, (h,c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2179e945",
   "metadata": {},
   "source": [
    "Refactoring the above for increase in GPU performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "2bc2a0e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLLM8(Module):\n",
    "    def __init__(self, ni, h):\n",
    "        self.ih = nn.Linear(ni,4*nh)\n",
    "        self.hh = nn.Linear(nh,4*nh)\n",
    "    \n",
    "    def forward(self, x, state):\n",
    "        h,c = state\n",
    "        \n",
    "        gates = (self.ih(x) + self.hh(h)).chunk(4,1)\n",
    "        ingate, forgetgate, outgate = map(torch.sigmoid, gates[:3]) ## Note: order does not matter here\n",
    "        cellgate = torch.tanh(gates[3])\n",
    "\n",
    "        c = forgetgate*c + ingate*cellgate\n",
    "        h = outgate * torch.tanh(c)\n",
    "        return h, (h,c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7acce68d",
   "metadata": {},
   "source": [
    "Now the LTSM network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "f6bcf373",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLLM9(Module):\n",
    "    def __init__(self, vocab_sz, n_hidden,n_layers):\n",
    "        self.i_h = nn.Embedding(vocab_sz,n_hidden)\n",
    "        self.rnn = nn.LSTM(n_hidden,n_hidden, n_layers, batch_first=True)\n",
    "        self.h_o = nn.Linear(n_hidden,vocab_sz)\n",
    "        self.h = [torch.zeros(n_layers, bs, n_hidden) for _ in range(2)] # Some changes here\n",
    "    \n",
    "    def forward(self,x):\n",
    "        res,h = self.rnn(self.i_h(x), self.h)\n",
    "        self.h = [h_.detach() for h_ in h]\n",
    "        return self.h_o(res)\n",
    "    \n",
    "    def reset(self):\n",
    "        for h in self.h:\n",
    "            h.zero_ # Some changes here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cb38015a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>7.978433</td>\n",
       "      <td>6.681934</td>\n",
       "      <td>0.122498</td>\n",
       "      <td>03:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>6.850881</td>\n",
       "      <td>6.777476</td>\n",
       "      <td>0.122498</td>\n",
       "      <td>03:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>6.598370</td>\n",
       "      <td>6.803113</td>\n",
       "      <td>0.122498</td>\n",
       "      <td>03:51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>6.429319</td>\n",
       "      <td>6.598124</td>\n",
       "      <td>0.122498</td>\n",
       "      <td>03:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>6.079883</td>\n",
       "      <td>6.307435</td>\n",
       "      <td>0.150940</td>\n",
       "      <td>03:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>5.721493</td>\n",
       "      <td>6.203966</td>\n",
       "      <td>0.170410</td>\n",
       "      <td>03:51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>5.413800</td>\n",
       "      <td>6.209413</td>\n",
       "      <td>0.174133</td>\n",
       "      <td>04:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>5.146466</td>\n",
       "      <td>6.146118</td>\n",
       "      <td>0.186951</td>\n",
       "      <td>03:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>4.899539</td>\n",
       "      <td>6.264096</td>\n",
       "      <td>0.185486</td>\n",
       "      <td>03:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>4.717854</td>\n",
       "      <td>6.252806</td>\n",
       "      <td>0.184509</td>\n",
       "      <td>03:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>4.580995</td>\n",
       "      <td>6.264646</td>\n",
       "      <td>0.191895</td>\n",
       "      <td>03:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>4.431023</td>\n",
       "      <td>6.332827</td>\n",
       "      <td>0.187561</td>\n",
       "      <td>03:32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>4.287086</td>\n",
       "      <td>6.405629</td>\n",
       "      <td>0.189270</td>\n",
       "      <td>03:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>4.169223</td>\n",
       "      <td>6.431261</td>\n",
       "      <td>0.186279</td>\n",
       "      <td>03:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>4.104361</td>\n",
       "      <td>6.438369</td>\n",
       "      <td>0.186707</td>\n",
       "      <td>03:37</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn = Learner(dls, MyLLM9(len(vocab), 1024, 4), \n",
    "                loss_func=CrossEntropyLossFlat(), \n",
    "                metrics=accuracy, cbs=ModelResetter)\n",
    "learn.fit_one_cycle(15, 1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc5eae42",
   "metadata": {},
   "source": [
    "### Regularizing\n",
    "We will add the following methods as seen in the paper taught by Jeremy;\n",
    "<li> Dropout </li>\n",
    "<li> Activation Regularization (AR) and Temporal Activation Regularization (TAR) </li>\n",
    "<li> Weight Tying </li>\n",
    "\n",
    "The LSTM that uses these techniques are called AWD-LSTM according to the author."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "dfb1a4e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLLM10(Module):\n",
    "    def __init__(self, vocab_sz, n_hidden,n_layers,p):\n",
    "        self.i_h = nn.Embedding(vocab_sz,n_hidden)\n",
    "        self.rnn = nn.LSTM(n_hidden,n_hidden, n_layers, batch_first=True)\n",
    "        self.drop = nn.Dropout(p) # Dropout\n",
    "        self.h_o = nn.Linear(n_hidden,vocab_sz)\n",
    "        self.h_o.weight = self.i_h.weight # Weight Tying\n",
    "        self.h = [torch.zeros(n_layers, bs, n_hidden) for _ in range(2)] # Some changes here\n",
    "    \n",
    "    def forward(self,x):\n",
    "        res,h = self.rnn(self.i_h(x), self.h)\n",
    "        out = self.drop(res)\n",
    "        self.h = [h_.detach() for h_ in h]\n",
    "        return self.h_o(out),res,out\n",
    "    \n",
    "    def reset(self):\n",
    "        for h in self.h:\n",
    "            h.zero_ # Some changes here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "361073c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>6.744831</td>\n",
       "      <td>6.390353</td>\n",
       "      <td>0.052823</td>\n",
       "      <td>04:09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "learn = Learner(dls, MyLLM10(len(vocab), 1024, 4, 0.5), \n",
    "                loss_func=CrossEntropyLossFlat(), \n",
    "                metrics=accuracy, \n",
    "                cbs=[ModelResetter,RNNRegularizer(alpha=2,beta=1)]\n",
    "               )\n",
    "\n",
    "# OR\n",
    "learn = TextLearner(dls, MyLLM10(len(vocab), 1024, 4, 0.4),\n",
    "                   loss_func = CrossEntropyLossFlat(), metrics=accuracy)\n",
    "\n",
    "learn.fit_one_cycle(5, 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b90372",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "52d252e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>7.567925</td>\n",
       "      <td>7.175681</td>\n",
       "      <td>0.122925</td>\n",
       "      <td>03:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>7.111494</td>\n",
       "      <td>6.670097</td>\n",
       "      <td>0.150391</td>\n",
       "      <td>03:20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>6.544221</td>\n",
       "      <td>6.191212</td>\n",
       "      <td>0.207458</td>\n",
       "      <td>03:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>5.991594</td>\n",
       "      <td>6.060913</td>\n",
       "      <td>0.219971</td>\n",
       "      <td>03:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5.410181</td>\n",
       "      <td>6.122361</td>\n",
       "      <td>0.226318</td>\n",
       "      <td>03:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>4.774519</td>\n",
       "      <td>6.354394</td>\n",
       "      <td>0.225830</td>\n",
       "      <td>03:17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [42]\u001b[0m, in \u001b[0;36m<cell line: 11>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# OR\u001b[39;00m\n\u001b[0;32m      8\u001b[0m learn \u001b[38;5;241m=\u001b[39m TextLearner(dls, MyLLM10(\u001b[38;5;28mlen\u001b[39m(vocab), \u001b[38;5;241m1024\u001b[39m, \u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m0.4\u001b[39m),\n\u001b[0;32m      9\u001b[0m                    loss_func \u001b[38;5;241m=\u001b[39m CrossEntropyLossFlat(), metrics\u001b[38;5;241m=\u001b[39maccuracy)\n\u001b[1;32m---> 11\u001b[0m \u001b[43mlearn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_one_cycle\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m15\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1e-3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\fastai\\callback\\schedule.py:119\u001b[0m, in \u001b[0;36mfit_one_cycle\u001b[1;34m(self, n_epoch, lr_max, div, div_final, pct_start, wd, moms, cbs, reset_opt, start_epoch)\u001b[0m\n\u001b[0;32m    116\u001b[0m lr_max \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([h[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m h \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mopt\u001b[38;5;241m.\u001b[39mhypers])\n\u001b[0;32m    117\u001b[0m scheds \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m'\u001b[39m: combined_cos(pct_start, lr_max\u001b[38;5;241m/\u001b[39mdiv, lr_max, lr_max\u001b[38;5;241m/\u001b[39mdiv_final),\n\u001b[0;32m    118\u001b[0m           \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmom\u001b[39m\u001b[38;5;124m'\u001b[39m: combined_cos(pct_start, \u001b[38;5;241m*\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmoms \u001b[38;5;28;01mif\u001b[39;00m moms \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m moms))}\n\u001b[1;32m--> 119\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_epoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcbs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mParamScheduler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mscheds\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43mL\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcbs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset_opt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset_opt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstart_epoch\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\fastai\\learner.py:264\u001b[0m, in \u001b[0;36mLearner.fit\u001b[1;34m(self, n_epoch, lr, wd, cbs, reset_opt, start_epoch)\u001b[0m\n\u001b[0;32m    262\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mopt\u001b[38;5;241m.\u001b[39mset_hypers(lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlr \u001b[38;5;28;01mif\u001b[39;00m lr \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m lr)\n\u001b[0;32m    263\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_epoch \u001b[38;5;241m=\u001b[39m n_epoch\n\u001b[1;32m--> 264\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_with_events\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_fit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfit\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCancelFitException\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_end_cleanup\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\fastai\\learner.py:199\u001b[0m, in \u001b[0;36mLearner._with_events\u001b[1;34m(self, f, event_type, ex, final)\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_with_events\u001b[39m(\u001b[38;5;28mself\u001b[39m, f, event_type, ex, final\u001b[38;5;241m=\u001b[39mnoop):\n\u001b[1;32m--> 199\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m: \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbefore_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m);  \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    200\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m ex: \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter_cancel_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    201\u001b[0m     \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m);  final()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\fastai\\learner.py:253\u001b[0m, in \u001b[0;36mLearner._do_fit\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    251\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_epoch):\n\u001b[0;32m    252\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepoch\u001b[38;5;241m=\u001b[39mepoch\n\u001b[1;32m--> 253\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_with_events\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_epoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mepoch\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCancelEpochException\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\fastai\\learner.py:199\u001b[0m, in \u001b[0;36mLearner._with_events\u001b[1;34m(self, f, event_type, ex, final)\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_with_events\u001b[39m(\u001b[38;5;28mself\u001b[39m, f, event_type, ex, final\u001b[38;5;241m=\u001b[39mnoop):\n\u001b[1;32m--> 199\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m: \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbefore_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m);  \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    200\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m ex: \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter_cancel_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    201\u001b[0m     \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m);  final()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\fastai\\learner.py:247\u001b[0m, in \u001b[0;36mLearner._do_epoch\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    246\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_do_epoch\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 247\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_epoch_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    248\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_do_epoch_validate()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\fastai\\learner.py:239\u001b[0m, in \u001b[0;36mLearner._do_epoch_train\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    237\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_do_epoch_train\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    238\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdl \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdls\u001b[38;5;241m.\u001b[39mtrain\n\u001b[1;32m--> 239\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_with_events\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mall_batches\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCancelTrainException\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\fastai\\learner.py:199\u001b[0m, in \u001b[0;36mLearner._with_events\u001b[1;34m(self, f, event_type, ex, final)\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_with_events\u001b[39m(\u001b[38;5;28mself\u001b[39m, f, event_type, ex, final\u001b[38;5;241m=\u001b[39mnoop):\n\u001b[1;32m--> 199\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m: \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbefore_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m);  \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    200\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m ex: \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter_cancel_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    201\u001b[0m     \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m);  final()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\fastai\\learner.py:205\u001b[0m, in \u001b[0;36mLearner.all_batches\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    203\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mall_batches\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    204\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdl)\n\u001b[1;32m--> 205\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m o \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdl): \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mone_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mo\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\fastai\\learner.py:235\u001b[0m, in \u001b[0;36mLearner.one_batch\u001b[1;34m(self, i, b)\u001b[0m\n\u001b[0;32m    233\u001b[0m b \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_device(b)\n\u001b[0;32m    234\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_split(b)\n\u001b[1;32m--> 235\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_with_events\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_one_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbatch\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCancelBatchException\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\fastai\\learner.py:199\u001b[0m, in \u001b[0;36mLearner._with_events\u001b[1;34m(self, f, event_type, ex, final)\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_with_events\u001b[39m(\u001b[38;5;28mself\u001b[39m, f, event_type, ex, final\u001b[38;5;241m=\u001b[39mnoop):\n\u001b[1;32m--> 199\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m: \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbefore_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m);  \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    200\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m ex: \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter_cancel_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    201\u001b[0m     \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m);  final()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\fastai\\learner.py:216\u001b[0m, in \u001b[0;36mLearner._do_one_batch\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_do_one_batch\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 216\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mxb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter_pred\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39myb):\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Input \u001b[1;32mIn [39]\u001b[0m, in \u001b[0;36mMyLLM10.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m,x):\n\u001b[1;32m---> 11\u001b[0m     res,h \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrnn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mi_h\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mh\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdrop(res)\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mh \u001b[38;5;241m=\u001b[39m [h_\u001b[38;5;241m.\u001b[39mdetach() \u001b[38;5;28;01mfor\u001b[39;00m h_ \u001b[38;5;129;01min\u001b[39;00m h]\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\modules\\rnn.py:812\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m    810\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_forward_args(\u001b[38;5;28minput\u001b[39m, hx, batch_sizes)\n\u001b[0;32m    811\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_sizes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 812\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    813\u001b[0m \u001b[43m                      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbidirectional\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_first\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    814\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    815\u001b[0m     result \u001b[38;5;241m=\u001b[39m _VF\u001b[38;5;241m.\u001b[39mlstm(\u001b[38;5;28minput\u001b[39m, batch_sizes, hx, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_weights, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias,\n\u001b[0;32m    816\u001b[0m                       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbidirectional)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "learn = Learner(dls, MyLLM10(len(vocab), 1024, 4, 0.5), \n",
    "                loss_func=CrossEntropyLossFlat(), \n",
    "                metrics=accuracy, \n",
    "                cbs=[ModelResetter,RNNRegularizer(alpha=2,beta=1)]\n",
    "               )\n",
    "\n",
    "# OR\n",
    "learn = TextLearner(dls, MyLLM10(len(vocab), 1024, 4, 0.4),\n",
    "                   loss_func = CrossEntropyLossFlat(), metrics=accuracy)\n",
    "\n",
    "learn.fit_one_cycle(15, 1e-3, wd=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "61e41d8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor([58]*64).dim()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "7e3f2ac8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(83865, 83865)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokens), len(nums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "2f4539e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#12) ['xbos','xupp','serikali','imesema','haitakuwa','tayari','kuona','amani','na','utulivu'...]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L(tokens[:12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "c6b6140a",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_p_nums = nums[-994:-970]\n",
    "to_p_nums = list(dls.valid.dataset[0][0])# + list(dls.valid.dataset[1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "96889164",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▁na ▁ s na ▁wa na na na ▁ya . . . ▁ya ▁ya ▁ya "
     ]
    }
   ],
   "source": [
    "to_p = tensor([to_p_nums[:-1]]*64)\n",
    "\n",
    "prediction = learn.predict(to_p)#,[58]*64)])\n",
    "for p in prediction[0]:\n",
    "    print(vocab[p],end=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "501d7ee8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▁A th u ma n ▁Ki hamia ▁alisema ▁hayo ▁aki wasilisha ▁ma da ▁ya ▁U "
     ]
    }
   ],
   "source": [
    "for a in to_p_nums[1:]:\n",
    "    print(vocab[a],end= ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10aaf9ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
